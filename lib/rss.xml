<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Obsidian_main]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>Obsidian_main</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Fri, 28 Jun 2024 00:47:51 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Fri, 28 Jun 2024 00:47:49 GMT</pubDate><copyright><![CDATA[dustbox]]></copyright><ttl>60</ttl><dc:creator>dustbox</dc:creator><item><title><![CDATA[Drawing 2024-06-13 21.18.08]]></title><description><![CDATA[ 
 
  
  
  
    
    
  
  Application ProcessNetwork LayerTrasport LayerMessage]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.1-트랜스포트-계층-서비스-및-개요\attachments\drawing-2024-06-13-21.18.08.excalidraw.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.1 트랜스포트 계층 서비스 및 개요/attachments/Drawing 2024-06-13 21.18.08.excalidraw.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Fri, 28 Jun 2024 00:29:39 GMT</pubDate></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br>![![/#*filesView]]]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Fri, 28 Jun 2024 00:47:35 GMT</pubDate></item><item><title><![CDATA[참고 API source  사이트]]></title><description><![CDATA[ 
 <br><br>
<br>
기상청: <a rel="noopener" class="external-link" href="https://apihub.kma.go.kr/" target="_blank">https://apihub.kma.go.kr/</a>

<br>꽃가루 정보: 융합기상 -&gt; 생활안전 탭


<br>
OpenWeatherAPI: <a rel="noopener" class="external-link" href="https://openweathermap.org/" target="_blank">https://openweathermap.org/</a>

<br>대기오염 정보: <a rel="noopener" class="external-link" href="https://openweathermap.org/api/air-pollution" target="_blank">https://openweathermap.org/api/air-pollution</a> -&gt; Forecast air pollution data
<br><img alt="Pasted image 20240619153246.png" src="과외\임도연_과외\attachments\pasted-image-20240619153246.png">


<br><br><img alt="기상청_API허브_사용_방법_안내_page-0001.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0001.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0002.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0002.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0003.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0003.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0004.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0004.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0005.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0005.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0006.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0006.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0007.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0007.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0008.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0008.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0009.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0009.jpg"><br><img alt="기상청_API허브_사용_방법_안내_page-0010.jpg" src="과외\임도연_과외\attachments\기상청_api허브_사용_방법_안내_page-0010.jpg"><br><br>아래 사이트 참고<br>
<a rel="noopener" class="external-link" href="https://velog.io/@yje876/Java-OpenWeather-API-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0" target="_blank">https://velog.io/@yje876/Java-OpenWeather-API-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0</a><br><br>auth key 를 발급 받았다면 아래 코드를 활용할 수 있을 것.<br><br>
<br>wifi 정보와 authkey를 적절하게 꼭 넣어주자
<br>라이브러리 또한 실행 전에 꼭 다운로드 받아서 적용해주자
<br>#include &lt;WiFi.h&gt;
#include &lt;HTTPClient.h&gt;
#include &lt;NTPClient.h&gt;
#include &lt;WiFiUdp.h&gt;
#include &lt;ArduinoJson.h&gt;

// Wi-Fi 네트워크 정보
const char* ssid = "your_SSID";
const char* password = "your_PASSWORD";

// NTP 서버를 설정합니다.
WiFiUDP ntpUDP;
NTPClient timeClient(ntpUDP, "pool.ntp.org", 9 * 3600, 60000); // 한국 시간대는 UTC+9, 60초마다 업데이트

// API 정보
const char* serverNameBase1 = "https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getOakPollenRiskIdxV2";
const char* serverNameBase2 = "https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getPinePollenRiskIdxV2";
const char* serverNameBase3 = "https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getWeedsPollenRiskndxV2";

const char* serverNameBase4 = "http://api.openweathermap.org/data/2.5/air_pollution/forecast";

const char* authKey = "your_auth_key"; // 기상청 API 키
const char* apiKeyOpenWeather = "your_openweather_api_key";  // OpenWeatherMap API 키

const char* areaNo = "1100000000"; // 서울 지역코드(기상청api)

// 서울 위도, 경도(Openweathermap)
const char* lat = "37.5683";
const char* lon = "126.9778";


void setup() {
  // 시리얼 통신을 시작합니다.
  Serial.begin(115200);
  
  // Wi-Fi 연결을 시작합니다.
  WiFi.begin(ssid, password);
  
  // Wi-Fi가 연결될 때까지 기다립니다.
  while (WiFi.status() != WL_CONNECTED) {
    delay(1000);
    Serial.println("Connecting to WiFi...");
  }
  Serial.println("Connected to WiFi");
  
  // NTP 클라이언트를 시작합니다.
  timeClient.begin();
}

void loop() {
  // 네트워크 시간 업데이트
  timeClient.update();
  
  // 현재 시간을 얻습니다.
  unsigned long epochTime = timeClient.getEpochTime();
  struct tm *ptm = gmtime ((time_t *)&amp;epochTime);
  int year = ptm-&gt;tm_year + 1900;
  int month = ptm-&gt;tm_mon + 1;
  int day = ptm-&gt;tm_mday;
  int hour = ptm-&gt;tm_hour;

  // time 변수 형식 설정 (예: 2024061914)
  char timeBuffer[13];
  snprintf(timeBuffer, sizeof(timeBuffer), "%04d%02d%02d%02d", year, month, day, hour);

  // 각 API 호출 및 출력 함수
  callAndPrintAPI(serverNameBase1, "꽃가루농도위험지수(참나무)", timeBuffer);
  callAndPrintAPI(serverNameBase2, "꽃가루농도위험지수(소나무)", timeBuffer);
  callAndPrintAPI(serverNameBase3, "꽃가루농도위험지수(잡초)", timeBuffer);
  callAndPrintAirPollutionAPI(serverNameBase4, "공기 오염 지수", lat, lon, apiKeyOpenWeather);
  
  // 주기적으로 호출 (예: 1시간마다)
  delay(3600000); // 1시간 (3600초) 지연
}

void callAndPrintAPI(const char* serverNameBase, const char* apiName, const char* timeBuffer) {
  // 전체 서버 URL을 구성합니다.
  char serverName[512];
  snprintf(serverName, sizeof(serverName), "%s?numOfRows=10&amp;pageNo=1&amp;dataType=JSON&amp;areaNo=%s&amp;time=%s&amp;authKey=%s",
           serverNameBase, areaNo, timeBuffer, authKey);
  
  // HTTP 요청을 보냅니다.
  if (WiFi.status() == WL_CONNECTED) {
    HTTPClient http;
    
    // 요청 URL을 설정합니다.
    http.begin(serverName);
    
    // HTTP GET 요청을 보냅니다.
    int httpResponseCode = http.GET();
    
    if (httpResponseCode &gt; 0) {
      // 응답을 읽습니다.
      String payload = http.getString();
      Serial.println(httpResponseCode);
      Serial.println(payload);
      
      // JSON 파싱
      DynamicJsonDocument doc(4096);
      deserializeJson(doc, payload);

      // 출력 데이터
      Serial.printf("\nAPI: %s\n", apiName);
      Serial.println("출력 결과:");
      Serial.printf("numOfRows: %s (한 페이지 결과 수)\n", doc["response"]["body"]["numOfRows"].as&lt;String&gt;().c_str());
      Serial.printf("pageNo: %s (페이지 번호)\n", doc["response"]["body"]["pageNo"].as&lt;String&gt;().c_str());
      Serial.printf("totalCount: %s (데이터 총 개수)\n", doc["response"]["body"]["totalCount"].as&lt;String&gt;().c_str());
      Serial.printf("resultCode: %s (응답메시지 코드)\n", doc["response"]["header"]["resultCode"].as&lt;String&gt;().c_str());
      Serial.printf("resultMsg: %s (응답메시지 내용)\n", doc["response"]["header"]["resultMsg"].as&lt;String&gt;().c_str());
      Serial.printf("dataType: %s (데이터 타입)\n", doc["response"]["body"]["dataType"].as&lt;String&gt;().c_str());
      Serial.printf("areaNo: %s (지점코드)\n", doc["response"]["body"]["items"]["item"][0]["areaNo"].as&lt;String&gt;().c_str());
      Serial.printf("date: %s (발표시간)\n", doc["response"]["body"]["items"]["item"][0]["date"].as&lt;String&gt;().c_str());
      Serial.printf("today: %s (오늘 예측값)\n", doc["response"]["body"]["items"]["item"][0]["today"].as&lt;String&gt;().c_str());
      Serial.printf("tomorrow: %s (내일 예측값)\n", doc["response"]["body"]["items"]["item"][0]["tomorrow"].as&lt;String&gt;().c_str());
      Serial.printf("todayaftertomorrow: %s (모레 예측값)\n", doc["response"]["body"]["items"]["item"][0]["todayaftertomorrow"].as&lt;String&gt;().c_str());
      
    } else {
      Serial.print("Error on HTTP request: ");
      Serial.println(httpResponseCode);
    }
    
    // HTTP 연결을 종료합니다.
    http.end();
  } else {
    Serial.println("WiFi Disconnected");
  }
}

void callAndPrintAirPollutionAPI(const char* serverNameBase, const char* apiName, const char* lat, const char* lon, const char* apiKey) {
  // 전체 서버 URL을 구성합니다.
  char serverName[512];
  snprintf(serverName, sizeof(serverName), "%s?lat=%s&amp;lon=%s&amp;appid=%s",
           serverNameBase, lat, lon, apiKey);
  
  // HTTP 요청을 보냅니다.
  if (WiFi.status() == WL_CONNECTED) {
    HTTPClient http;
    
    // 요청 URL을 설정합니다.
    http.begin(serverName);
    
    // HTTP GET 요청을 보냅니다.
    int httpResponseCode = http.GET();
    
    if (httpResponseCode &gt; 0) {
      // 응답을 읽습니다.
      String payload = http.getString();
      Serial.println(httpResponseCode);
      Serial.println(payload);
      
      // JSON 파싱
      DynamicJsonDocument doc(4096);
      deserializeJson(doc, payload);

      // 출력 데이터
      Serial.printf("\nAPI: %s\n", apiName);
      Serial.println("출력 결과:");
      for (JsonObject obj : doc["list"].as&lt;JsonArray&gt;()) {
        unsigned long dt = obj["dt"];
        time_t t = dt;
        struct tm *timeinfo = localtime(&amp;t);
        char buffer[25];
        strftime(buffer, 25, "%Y-%m-%d %H:%M:%S", timeinfo);
        
        Serial.printf("Time: %s\n", buffer);
        Serial.printf("AQI: %s\n", getAQIExplanation(obj["main"]["aqi"].as&lt;int&gt;()));
        Serial.printf("CO: %.2f\n", obj["components"]["co"].as&lt;float&gt;());
        Serial.printf("NO: %.2f\n", obj["components"]["no"].as&lt;float&gt;());
        Serial.printf("NO2: %.2f\n", obj["components"]["no2"].as&lt;float&gt;());
        Serial.printf("O3: %.2f\n", obj["components"]["o3"].as&lt;float&gt;());
        Serial.printf("SO2: %.2f\n", obj["components"]["so2"].as&lt;float&gt;());
        Serial.printf("PM2.5: %.2f\n", obj["components"]["pm2_5"].as&lt;float&gt;());
        Serial.printf("PM10: %.2f\n", obj["components"]["pm10"].as&lt;float&gt;());
        Serial.printf("NH3: %.2f\n", obj["components"]["nh3"].as&lt;float&gt;());
        Serial.println();
      }
      
    } else {
      Serial.print("Error on HTTP request: ");
      Serial.println(httpResponseCode);
    }
    
    // HTTP 연결을 종료합니다.
    http.end();
  } else {
    Serial.println("WiFi Disconnected");
  }
}

const char* getAQIExplanation(int aqi) {
  switch (aqi) {
    case 1: return "Good";
    case 2: return "Fair";
    case 3: return "Moderate";
    case 4: return "Poor";
    case 5: return "Very Poor";
    default: return "Unknown";
  }
}
Run복사<br><br><br>
<br>URL: https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getOakPollenRiskIdxV2
<br>설명: 참나무 꽃가루 농도의 위험 지수를 제공합니다.
<br>필요한 파라미터:

<br>numOfRows: 한 페이지 결과 수
<br>pageNo: 페이지 번호
<br>dataType: 데이터 형식 (JSON)
<br>areaNo: 지역 코드
<br>time: 조회 시간 (형식: YYYYMMDDHH)
<br>authKey: 인증 키


<br><br>
<br>URL: https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getPinePollenRiskIdxV2
<br>설명: 소나무 꽃가루 농도의 위험 지수를 제공합니다.
<br>필요한 파라미터: 참나무와 동일
<br><br>
<br>URL: https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getWeedsPollenRiskndxV2
<br>설명: 잡초 꽃가루 농도의 위험 지수를 제공합니다.
<br>필요한 파라미터: 참나무와 동일
<br><br>
<br>URL: http://api.openweathermap.org/data/2.5/air_pollution/forecast
<br>설명: 특정 위치의 공기 오염 예측 데이터를 제공합니다.
<br>필요한 파라미터:

<br>lat: 위도
<br>lon: 경도
<br>appid: API 키


<br><br>아두이노 코드에서는 Wi-Fi, HTTPClient, NTPClient, ArduinoJson 라이브러리를 사용합니다. 각 API를 호출하고, JSON 응답 데이터를 파싱하여 시리얼 모니터에 출력합니다.<br><br>#include &lt;WiFi.h&gt;
#include &lt;HTTPClient.h&gt;
#include &lt;NTPClient.h&gt;
#include &lt;WiFiUdp.h&gt;
#include &lt;ArduinoJson.h&gt;
Run복사<br>Wi-Fi 연결을 위한 네트워크 정보와 NTP 서버 설정:<br>const char* ssid = "your_SSID";
const char* password = "your_PASSWORD";
WiFiUDP ntpUDP;
NTPClient timeClient(ntpUDP, "pool.ntp.org", 9 * 3600, 60000);
Run복사<br>API 요청에 필요한 기본 URL과 인증 키 설정:<br>const char* serverNameBase1 = "https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getOakPollenRiskIdxV2";
const char* serverNameBase2 = "https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getPinePollenRiskIdxV2";
const char* serverNameBase3 = "https://apihub.kma.go.kr/api/typ02/openApi/HealthWthrIdxServiceV2/getWeedsPollenRiskndxV2";
const char* serverNameBase4 = "http://api.openweathermap.org/data/2.5/air_pollution/forecast";
const char* authKey = "your_auth_key";
const char* apiKeyOpenWeather = "your_openweather_api_key";
const char* areaNo = "1100000000";
const char* lat = "37.5683";
const char* lon = "126.9778";
Run복사<br><br>void setup() {
  Serial.begin(115200);
  WiFi.begin(ssid, password);
  while (WiFi.status() != WL_CONNECTED) {
    delay(1000);
    Serial.println("Connecting to WiFi...");
  }
  Serial.println("Connected to WiFi");
  timeClient.begin();
}
Run복사<br>Wi-Fi에 연결된 후 NTP 클라이언트를 시작합니다.<br><br>loop() 함수에서 주기적으로 API를 호출합니다. 시간 형식을 설정하고, 각 API를 호출하여 응답을 파싱하고 출력합니다.<br>void loop() {
  timeClient.update();
  unsigned long epochTime = timeClient.getEpochTime();
  struct tm *ptm = gmtime ((time_t *)&amp;epochTime);
  int year = ptm-&gt;tm_year + 1900;
  int month = ptm-&gt;tm_mon + 1;
  int day = ptm-&gt;tm_mday;
  int hour = ptm-&gt;tm_hour;

  char timeBuffer[13];
  snprintf(timeBuffer, sizeof(timeBuffer), "%04d%02d%02d%02d", year, month, day, hour);

  callAndPrintAPI(serverNameBase1, "꽃가루농도위험지수(참나무)", timeBuffer);
  callAndPrintAPI(serverNameBase2, "꽃가루농도위험지수(소나무)", timeBuffer);
  callAndPrintAPI(serverNameBase3, "꽃가루농도위험지수(잡초)", timeBuffer);
  callAndPrintAirPollutionAPI(serverNameBase4, "공기 오염 지수", lat, lon, apiKeyOpenWeather);

  delay(3600000);
}
Run복사<br><br>각 API 호출과 JSON 응답 파싱을 위한 함수입니다.<br>void callAndPrintAPI(const char* serverNameBase, const char* apiName, const char* timeBuffer) {
  char serverName[512];
  snprintf(serverName, sizeof(serverName), "%s?numOfRows=10&amp;pageNo=1&amp;dataType=JSON&amp;areaNo=%s&amp;time=%s&amp;authKey=%s",
           serverNameBase, areaNo, timeBuffer, authKey);

  if (WiFi.status() == WL_CONNECTED) {
    HTTPClient http;
    http.begin(serverName);
    int httpResponseCode = http.GET();

    if (httpResponseCode &gt; 0) {
      String payload = http.getString();
      Serial.println(httpResponseCode);
      Serial.println(payload);

      DynamicJsonDocument doc(4096);
      deserializeJson(doc, payload);

      Serial.printf("\nAPI: %s\n", apiName);
      Serial.println("출력 결과:");
      Serial.printf("numOfRows: %s (한 페이지 결과 수)\n", doc["response"]["body"]["numOfRows"].as&lt;String&gt;().c_str());
      Serial.printf("pageNo: %s (페이지 번호)\n", doc["response"]["body"]["pageNo"].as&lt;String&gt;().c_str());
      Serial.printf("totalCount: %s (데이터 총 개수)\n", doc["response"]["body"]["totalCount"].as&lt;String&gt;().c_str());
      Serial.printf("resultCode: %s (응답메시지 코드)\n", doc["response"]["header"]["resultCode"].as&lt;String&gt;().c_str());
      Serial.printf("resultMsg: %s (응답메시지 내용)\n", doc["response"]["header"]["resultMsg"].as&lt;String&gt;().c_str());
      Serial.printf("dataType: %s (데이터 타입)\n", doc["response"]["body"]["dataType"].as&lt;String&gt;().c_str());
      Serial.printf("areaNo: %s (지점코드)\n", doc["response"]["body"]["items"]["item"][0]["areaNo"].as&lt;String&gt;().c_str());
      Serial.printf("date: %s (발표시간)\n", doc["response"]["body"]["items"]["item"][0]["date"].as&lt;String&gt;().c_str());
      Serial.printf("today: %s (오늘 예측값)\n", doc["response"]["body"]["items"]["item"][0]["today"].as&lt;String&gt;().c_str());
      Serial.printf("tomorrow: %s (내일 예측값)\n", doc["response"]["body"]["items"]["item"][0]["tomorrow"].as&lt;String&gt;().c_str());
      Serial.printf("todayaftertomorrow: %s (모레 예측값)\n", doc["response"]["body"]["items"]["item"][0]["todayaftertomorrow"].as&lt;String&gt;().c_str());
    } else {
      Serial.print("Error on HTTP request: ");
      Serial.println(httpResponseCode);
    }

    http.end();
  } else {
    Serial.println("WiFi Disconnected");
  }
}

void callAndPrintAirPollutionAPI(const char* serverNameBase, const char* apiName, const char* lat, const char* lon, const char* apiKey) {
  char serverName[512];
  snprintf(serverName, sizeof(serverName), "%s?lat=%s&amp;

lon=%s&amp;appid=%s",
           serverNameBase, lat, lon, apiKey);

  if (WiFi.status() == WL_CONNECTED) {
    HTTPClient http;
    http.begin(serverName);
    int httpResponseCode = http.GET();

    if (httpResponseCode &gt; 0) {
      String payload = http.getString();
      Serial.println(httpResponseCode);
      Serial.println(payload);

      DynamicJsonDocument doc(4096);
      deserializeJson(doc, payload);

      Serial.printf("\nAPI: %s\n", apiName);
      Serial.println("출력 결과:");
      for (JsonObject obj : doc["list"].as&lt;JsonArray&gt;()) {
        unsigned long dt = obj["dt"];
        time_t t = dt;
        struct tm *timeinfo = localtime(&amp;t);
        char buffer[25];
        strftime(buffer, 25, "%Y-%m-%d %H:%M:%S", timeinfo);

        Serial.printf("Time: %s\n", buffer);
        Serial.printf("AQI: %s\n", getAQIExplanation(obj["main"]["aqi"].as&lt;int&gt;()));
        Serial.printf("CO: %.2f\n", obj["components"]["co"].as&lt;float&gt;());
        Serial.printf("NO: %.2f\n", obj["components"]["no"].as&lt;float&gt;());
        Serial.printf("NO2: %.2f\n", obj["components"]["no2"].as&lt;float&gt;());
        Serial.printf("O3: %.2f\n", obj["components"]["o3"].as&lt;float&gt;());
        Serial.printf("SO2: %.2f\n", obj["components"]["so2"].as&lt;float&gt;());
        Serial.printf("PM2.5: %.2f\n", obj["components"]["pm2_5"].as&lt;float&gt;());
        Serial.printf("PM10: %.2f\n", obj["components"]["pm10"].as&lt;float&gt;());
        Serial.printf("NH3: %.2f\n", obj["components"]["nh3"].as&lt;float&gt;());
        Serial.println();
      }
    } else {
      Serial.print("Error on HTTP request: ");
      Serial.println(httpResponseCode);
    }

    http.end();
  } else {
    Serial.println("WiFi Disconnected");
  }
}

const char* getAQIExplanation(int aqi) {
  switch (aqi) {
    case 1: return "Good";
    case 2: return "Fair";
    case 3: return "Moderate";
    case 4: return "Poor";
    case 5: return "Very Poor";
    default: return "Unknown";
  }
}
Run복사]]></description><link>과외\임도연_과외\꽃가루,-황사-데이터-받아오기.html</link><guid isPermaLink="false">과외/임도연_과외/꽃가루, 황사 데이터 받아오기.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:53:55 GMT</pubDate><enclosure url="과외\임도연_과외\attachments\pasted-image-20240619153246.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="과외\임도연_과외\attachments\pasted-image-20240619153246.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[임도연_과외]]></title><description><![CDATA[ 
 ]]></description><link>과외\임도연_과외\임도연_과외.html</link><guid isPermaLink="false">과외/임도연_과외/임도연_과외.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:53:56 GMT</pubDate></item><item><title><![CDATA[1.1 인터넷이란 무엇인가?]]></title><description><![CDATA[ 
 <br><br>위의 질문을 답하기 위한 방법으로는 다음과 같이 두 가지로 존재한다.<br>
<br>인터넷을 구성하는 기본적인 하드웨어 &amp; 소프트웨어 구성요소에 대한 기술 (1.1.1)
<br>분산 애플리케이션에 서비스를 제공하는 네트워킹 인프라스트럭처 관점에서의 인터넷을 기술 (1.1.2)
<br><br><br><br><br>아래의 그림은 인터넷의 구성요소를 나타낸 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/210067671-04ad6d39-45fc-4ba9-a773-d964ec4cdc7c.png" alt="인터넷의 구성 요소" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br><br><br>
<br>Network of Network
<br>전 세계적으로 수십억 개의 컴퓨팅 장치를 연결하는 컴퓨터 네트워크
<br><br><br><br>
<br>컴퓨터 네트워크에 연결된 컴퓨팅 장치
<br>e.g., 서버 (데스크탑 PC, 리눅스 워크스테이션, 웹페이지 등), 인터넷에 연결된 모든 인터넷 ‘사물들’ (TV, 스마트 워치 등)
<br>통신 링크(communication link)와 패킷 스위치(packet switch)의 네트워크로 연결된다.
<br><br><br><br>
<br>다양한 전송률(transmission rate, 링크 대역폭 또는 bandwith)을 이용해 패킷(packet = 데이터)을 전송한다.
<br>전송률의 단위 : bps(bits per second, 초당 비트 수)
<br>동축케이블, 구리선, 광케이블, 라디오 스펙트럼을 포함한 다양한 물리 매체로 구성된다.
<br><br><br><br>
<br>송신 종단 시스템에서 수신 종단 시스템(목적지)으로 보내진다.
<br>송신 종단 시스템이 보내고자 하는 데이터를 세그먼트(segment)로 나누고, 각 세그먼트에 헤더(header)를 부착하여 수신 종단 시스템으로 전송한다.
<br>패킷은 목적지에서 원래의 데이터로 다시 조립된다.
<br><img src="https://user-images.githubusercontent.com/86337233/210068063-a8ef4bad-6b44-4d54-8975-7488c2b0acd6.png" alt="패킷" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br><br><br>
<br>입력 통신 링크 중 하나
<br>도착하는 패킷을 받아서 출력 통신 링크의 하나로 그 패킷을 전달한다. (최종 목적지 방향으로 패킷을 전달)
<br>대표적인 두 종류

<br>링크 계층 스위치(link-layer switch) : 보통 네트워크 코어에서 사용
<br>라우터(router) : 보통 접속 네트워크에서 사용


<br><br><br><br>
<br>패킷이 송신 종단 시스템에서 보내진 후 수신 종단 시스템에 도달하는 동안 거쳐온 일련의 통신 링크와 패킷 스위치를 말한다.
<br>패킷은 컴퓨터 네트워크를 통한 경로를 따른다.
<br><br><br><br>
<br>패킷 스위치와 통신 링크로 이루어진 네트워크
<br>종단 시스템에게 다양한 네트워크 접속을 제공한다. (가정용 초고속 접속, 고속 LAN 접속, 이동 무선 접속 등)
<br>CP(content provider)에게 인터넷 접속을 제공 → 웹 사이트나 비디오 서버를 인터넷에 직접 연결할 수 있게 된다.
<br>ISP들의 상호 연결

💡 인터넷은 종단 시스템을 서로 연결하는 것이므로 종단 시스템에 접속을 제공하는 ISP들도 서로 연결되어야만 한다.


<br>하위 계층 ISP는 국가 &amp; 국제 상위 계층 ISP를 통해 서로 연결한다. - 상위 계층 ISP들은 서로 직접 연결된다.
<br>각 ISP 네트워크는 따로 관리되고, IP 프로토콜을 수행하며, 네이밍(naming)과 주소배정 방식을 따른다.


<br><br><br><br>
<br>인터넷에서 정보의 송수신을 제어한다.
<br>가장 중요한 프로토콜 둘을 통칭하여 TCP/IP라고 한다.

<br>TCP(Transmission Control Protocol)
<br>IP(Internet Protocol) : 라우터와 종단 시스템 사이에서 송수신되는 패킷 포맷을 기술한다.


<br><br><br><br>
<br>IETF(Internet Engineering Task Force)

<br>국제 인터넷 표준화 기구
<br>RFC(Requests for Comment) : IETF 표준 문서
<br>TCP, IP, HTTP, SMTP 같은 프로토콜을 정의


<br>IEEE 802 LAN 표준위원회

<br>이더넷과 무선 와이파이 표준을 기술


<br><br><br><br><br><br>
<br>애플리케이션은 서로 데이터를 교환하는 많은 종단 시스템을 포함하고 있기 때문에 분산 애플리케이션(distributed application)이라고 부른다.
<br>인터넷 애플리케이션은 종단 시스템에서 수행되며, 네트워크 코어에 있는 패킷 교환기에서 수행되지 않는다.
<br>
💡 패킷 교환기는 종단 시스템 간의 데이터 교환을 쉽게 해주지만, 데이터의 시작과 끝인 애플리케이션에는 관심을 갖지 않는다.
<br><br><br><br>Q.
한 종단 시스템에서 수행되는 애플리케이션이 다른 종단 시스템에서 수행되고 있는 프로그램으로 데이터를 보내도록 하기 위해서는 인터넷에 어떻게 지시할 것인가?
복사<br>한 종단 시스템에서 수행되는 프로그램이 다른 종단 시스템에서 수행되는 특정 목적지 프로그램으로 데이터를 전달하도록<br>
어떻게 인터넷 인프라스트럭처에 요구하는지를 명시한 것을 소켓 인터페이스라고 한다.<br>→ 인터넷에 접속된 종단 시스템들은 소켓 인터페이스를 모두 가지고 있다.<br>
💡 소켓 인터페이스는 송신 프로그램이 따라야 하는 규칙의 집합이며, 인터넷은 이 규칙에 따라 데이터를 목적지 프로그램으로 전달하게 된다.
<br><br><br><br><br>둘 이상의 통신 개체(entity)가 어떤 일을 함께 수행하려면 이들이 다같이 인식하는 프로토콜 즉, 통신 규약이 필요하다.<br>아래의 그림은 사람 프로토콜과 컴퓨터 네트워크 프로토콜을 나타낸 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/210089593-aff053d6-b57c-45c4-ad06-f209a11a0e3a.png" alt="인터넷의 구성 요소" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;"><br>
<br>메세지의 송수신과 메시지를 송수신할 때 취하는 행동은 프로토콜의 중심에 있다.
<br>따라서 하나가 다른 프로토콜을 수행한다면 그 프로토콜은 다른 이들과 상호작용할 수 없으며, 원하는 작업을 수행할 수 없다.
<br><br><br><br>
<br>통신하는 둘 이상의 원격 개체가 포함된 인터넷에서의 모든 활동은 프로토콜이 제어한다.
<br>e.g.,

<br>혼잡 제어(congestion-control) 프로토콜 : 종단 시스템에 존재하며, 송수신자 간에 전송되는 패킷 전송률을 조절한다.
<br>라우터에서의 프로토콜 : 출발지(source)에서 목적지(destination)까지의 패킷 경로를 설정한다.


<br>
💡 프로토콜은 둘 이상의 통신 개체 간에 교환되는 메시지 포맷과 순서뿐만 아니라, 메시지의 송수신과 다른 이벤트에 따른 행동들을 정의한다.
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.1-인터넷이란-무엇인가_\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.1 인터넷이란 무엇인가_/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:53:57 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/210067671-04ad6d39-45fc-4ba9-a773-d964ec4cdc7c.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/210067671-04ad6d39-45fc-4ba9-a773-d964ec4cdc7c.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.2 접속 네트워크]]></title><description><![CDATA[ 
 <br><br>컴퓨터 네트워크(특히 인터넷)의 구성요소에 대하여 자세히 살펴보자.<br><br><br><br>
<br>인터넷에 연결되는 컴퓨터와 그 밖의 장치들
<br>인터넷의 가장 자리를 차지하고 있기 때문에 ‘종단’ 시스템이라고 부른다.
<br>종단 시스템은 애플리케이션을 수행하므로 호스트라고도 부르며, 호스트는 클라이언트(client)와 서버(server)로 구분된다.
<br><br><br>아래는 종단 시스템의 상호작용을 나타낸 그림이다.<br><img src="https://user-images.githubusercontent.com/86337233/210128184-301c72b1-c174-432e-b14d-8824c2a58cea.png" alt="종단 시스템 상호작용" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br><br><br><br><br>종단 시스템을 먼 거리에 위치한 다른 종단 시스템까지의 경로 상에 있는 첫 번째 라우터 즉, 가장 자리 라우터(edge router)에 연결하는 네트워크를 말한다.<br>아래 그림에서의 굵은 선들은 여러 종류의 접속 네트워크들을 나타낸 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/210129140-31bb75d0-c8f9-4a70-bb54-60c805b1fea8.png" alt="접속 네트워크" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;">
<br>
<br><br>네트워크 접속 기술들에 대하여 차례대로 알아보자.<br>
<br>가정 접속 : DSL, 케이블, FTTH, 5G 고정 무선 기술
<br>기업(그리고 가정) 접속 : 이더넷, 와이파이
<br>광역 무선 접속 : 3G, LTE 4G, 5G
<br><br><br><br>
<br>
오늘날(2020년) 가장 널리 보급된 광대역 가정 접속 유형들

<br>DSL : 지역 전화 회사(telco)의 기존 로컬 전화 인프라스트럭처를 이용
<br>케이블 : 케이블 TV 회사의 기존 케이블 TV 인프라스트럭처를 이용


<br>
FTTH : 위의 접속 유형들보다 빠른 속도를 제공하는 미래 기술

<br><br><br><br>가정은 유선 로컬 전화 서비스를 제공하는 같은 지역 전화 회사(telco)로부터 DSL 인터넷 접속 서비스를 받는다.<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/210128274-3b65a140-9c16-4b41-8f6d-5da5099f1a68.png" alt="DSL 인터넷 접속" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;">
<br>
<br><br>가정의 DSL 모뎀은 텔코의 지역 중앙국(Central Office, CO)에 위치한 DSLAM(Digital Subscriber Line Access Multiplexer)과 데이터를 교환하기 위해<br>
기존 전화 회선을 이용한다.<br>
<br>가정의 DSL 모뎀은 수신한 디지털 데이터를 전화선을 통해 CO로 전송하기 위해, 해당 데이터를 고주파 신호로 변환한다.
<br>여러 가정으로부터의 아날로그 신호는 DSLAM에서 디지털 포맷으로 다시 변환된다.
<br><br><br><br>이는 1.3.2절에서 자세히 다룰 예정이다.<br>
가정 전화 회선은 데이터와 전통적인 전화 신호를 동시에 전달하며, 이들은 다른 주파수 대역에서 인코딩된다.
<br><br><br>주파수 분할 다중화를 통해 단일 DSL 링크가 3개의 분리된 링크인 것처럼 보인다.<br>이를 통해서 하나의 전화 회선과 인터넷 연결이 동시에 DSL 링크를 공유할 수 있게 된다.<br>
<br>고속 다운스트림 채널 : 50 kHz ~ 1 MHz 대역
<br>중간 속도의 업스트림 채널 : 40 ~ 50 kHz 대역
<br>일반적인 양방향 전화 채널 : 0 ~ 4 kHZ 대역
<br><br><br><br>
<br>가정 쪽에 존재한다.
<br>역할

<br>가정에 도착하는 데이터와 전화 신호를 분리
<br>데이터 신호를 DSL 모뎀으로 전송


<br><br><br><br>
<br>수백 ~ 수천 개의 가정들이 DSLAM에 연결된다.
<br>역할

<br>데이터와 전화 신호를 분리
<br>데이터를 인터넷으로 송신


<br><br><br><br>
<br>DSL 표준은 여러 전송률을 정의하며, 이 전송률에는 업스트림과 다운스트림을 포함된다. (다운스트림 채널이 업스트림 채널보다 빠른 전송률이 할당됨)

<br>업스트림 속도 : 3.5 Mbps, 16 Mbps
<br>다운스트림 속도 : 24 Mbps, 52 Mbps


<br><br><br>
<br>최신 표준 : 업스트림과 다운스트림을 결합한 1 Gbps 속도를 정의 (ITU 2014)

<br>다운스트림과 업스트림의 속도가 다르기 때문에 이 접속 방식을 비대칭(asymmetric)이라고 한다.


<br><br><br><br>가정은 케이블 TV 서비스를 제공하는 같은 회사로부터 인터넷 접속 서비스를 받는다.<br>광케이블은 케이블 헤드엔드를 이웃 레벨 정션(junction)에 연결하며, 이로부터 가정들에 도달하는 데에는 전통적인 동축케이블이 사용된다.<br><img src="https://user-images.githubusercontent.com/86337233/210128378-c0754ede-9bca-4e37-9863-b3fb127a6679.png" alt="HFC 접속 네트워크" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;">
<br>
<br><br><br>
<br>(유선 TV의) 전파 (조정) 중계소, 중계국 / 주전송장치(분배센터)
<br>각 데이터 국으로부터 수신된 신호를 많은 세대가 시청할 수 있도록 신호를 가공, 증폭한 다음 분배해주는 시설
<br>유선 TV 방송을 위해 전파를 증폭, 조정, 변환, 투입차단 또는 혼합하여 선로로 송출하는 장치들과 신호를 간선 케이블로 송출하는 모든 설비를 말한다.
<br><br><br><br>
<br>케이블 인터넷 접속을 위한 모뎀
<br>이더넷 포트를 통해 가정 PC에 연결된다.
<br>케이블 헤드엔드에서 CMTS(Cable Modem Termination System)가 존재
<br>이는 HFC 네트워크를 다운스트림과 업스트림 채널 2개로 나눈다. (DSL과 똑같음!)

<br>비대칭 접속
<br>다운스트림 채널이 업스트림 채널보다 빠른 전송률이 할당된다.


<br><br><br><br>
<br>많은 다운스트림 가정에 있는 케이블 모뎀으로부터 송신된 아날로그 신호를 다시 디지털 포맷으로 변환하는 역할
<br>즉, 이는 DSL 네트워크의 DSLAM와 유사한 기능을 한다.
<br><br><br><br>
<br>헤드엔드가 보낸 모든 패킷은 / 모든 링크의 다운스트림 채널을 통해 / 모든 가정으로 전달된다.
<br>가정에서 보낸 모든 패킷은 / 업스트림 채널을 통해 / 헤드엔드로 전달한다.
<br><br><br>이에 다음과 같은 상황이 발생한다.<br>
<br>여러 사용자가 다운스트림 채널에서 다른 비디오 파일을 동시에 수신하고 있다면,<br>
각 사용자가 비디오 파일을 수신하는 실제 수신율은 다운스트림 전송률보다 작아진다.
<br>몇 명만 접속 중이며 모두가 웹을 탐색 중이라면, 각 사용자는 전체 다운스트림 전송률로 웹 페이지를 수신할 수도 있다.
<br>업스트림 채널도 공유가 되기 때문에, 분산 다중 접속 프로토콜은 전송을 조정하고 충돌을 피하기 위해 필요하다.<br><br><br><br>
<br>지역 중앙국(Central Office, CO)로부터 가정까지 직접 광섬유 경로를 제공한다.
<br>잠재적으로 Gbps의 인터넷 접속 속도를 제공할 수 있다.
<br>광신호 분배 기술 : CO로부터 가정까지 광신호를 분해하는 기술들을 말한다.
<br><br><br><br>
<br>가장 간단한 광신호 분배 네트워크
<br>CO에서 각 가정으로 하나의 광섬유를 제공
<br><br><br><br>스플리팅을 수행하는 두 가지 경쟁적인 광신호 분배 네트워크 구조들을 말한다.<br>스플리팅(splitting) : 일반적으로 CO에서 시작되는 각 광섬유는 여러 가정이 공유하기 때문에,<br>
가정에 가까운 곳까지 하나의 광섬유로 온 다음 고객별 광섬유로 분리하는 것<br>
<br>
AON : 근본적인 교환(switched) 이더넷

<br>
PON : 아래 그림 참고 (PON 분배 구조를 이용하는 FTTH 인터넷 접속)
<img src="https://user-images.githubusercontent.com/86337233/210128431-993b57ae-7275-4d65-a81e-2eb519a1c51f.png" alt="FTTH 인터넷 접속" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
이처럼 각 가정에서의 사용자는 홈 라우터를 ONT에 연결하고, 그를 통해 인터넷에 접속한다.<br><br><br>
인터넷 접속 절차는 아래와 같이 정리할 수 있다.

<br>각 가정은 ONT(Optical Network Terminator)를 가지고 있으며, 이는 지정된 광섬유로 이웃 스플리터에 연결된다.
<br>스플리터(Optical Splitter)는 여러 가정을 하나의 공유 광섬유로 결합, 이를 텔코의 CO에 있는 OLT(Optical Line Terminator)에 연결한다.
<br>OLT는 광신호와 전기 신호 간의 변환을 제공, 이는 텔코 라우터를 통해 인터넷에 연결된다.


<br><br><br><br>
<br>빔포밍(beam-forming) 기술을 이용하여 서비스 제공가의 기지국에서 가정 내의 모뎀으로 데이터를 무선으로 전송한다.
<br>와이파이(WiFi) 무선 라우터가 케이블 또는 DSL 모뎀에 연결되어 있듯, 5G-FW에서도 와이파이 무선 라우터가 모뎀에 연결되어 있다.
<br>5G 셀룰러(cellular) 네트워크 → 7장에서 설명
<br><br><br><br><br>
<br>종단 시스템을 가장자리 라우터에 연결하는 데 사용된다.
<br>여러 유형의 LAN 기술 중, 이더넷 기술이 기업, 대학, 홈 네트워크에서 가장 널리 사용되는 접속 기술
<br>아래는 전형적인 홈 네트워크를 나타낸 그림이다.<br><img src="https://user-images.githubusercontent.com/86337233/210128487-b8acdbb2-62e6-40c0-b74a-0bf173312dbc.png" alt="전형적인 홈 네트워크" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/210128501-ff9fe3a4-bd45-408d-83e8-9d43f730cbbe.png" alt="이더넷 인터넷 접속" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br>
<br>이더넷 스위치에 연결하기 위해 꼬임쌍선을 이용 (꼬임 쌍선은 1.2.2절에서 설명)
<br>이더넷 스위치 혹은 상호연결된 스위치들의 네트워크는 다시 더 큰 인터넷으로 연결된다.
<br><br><br><br>점차 사람들은 인터넷을 ‘사물(스마트폰, 태블릿 등)’에서 무선으로 접속하고 있다.<br>
<br>무선 랜 환경에서 무선 사용자들은 기업 네트워크에 연결된 AP(Access Point)로 패킷을 송•수신
<br>AP는 유선 네트워크에 다시 연결된다.
<br>와이파이(WiFi) : IEEE 802.11 기술에 기반한 무선 랜 접속
<br><br><br><br>
<br>무선 인프라스트럭처를 채택 (이동 전화망 사업자들이 운영하는 기지국을 통해 패킷을 송수신하는 데 사용하는 것과 같은 것임)
<br>수십 미터 반경 내에 있어야 하는 와이파이와 달리, 사용자는 기지국의 수십 킬로미터 반경 내에 있으면 된다.
<br><br><br><br><br>인터넷에서 공통적으로 사용하는 물리 매체들과 그 밖의 매체들에 대하여 살펴보자.<br><br><br><br>물리 매체를 정의하기 위해서는 비트에 대해 먼저 알아야 한다.<br><br><br>한 종단 시스템에서 여러 링크와 라우터를 거쳐 다른 종단 시스템으로 한 비트가 전달되는 상황을 생각해보자.
복사<br>
<br>이 비트는 여러 라우터를 거치게 된다. (첫 번째 라우터 : 비트를 수신 &amp; 전송 → 두 번째 라우터 : 비트를 수신 &amp; 전송 → 세 번째 라우터 : … )
<br>즉, 비트는 출발지에서 목적지로 전달될 때 여러 번 걸쳐 전송되며, 일련의 송신기-수신기 쌍을 거친다.
<br><br><br>
비트는 물리 매체(physical media)상에 전자파나 광 펄스를 전파하여 전송한다.
<br>
<br>물리 매체는 여러 형태이며, 경로상의 각 송신기-수신기 쌍에 대해 같은 유형일 필요는 없다.
<br>e.g., 꼬임쌍선, 동축케이블, 다중모드 광섬유 케이블, 지상파와 위성파 등
<br>두 가지 종류

<br>유도 매체(guided media) : 꼬임쌍선, 동축케이블, 광섬유 케이블과 같은 견고한 매체를 따라 파형을 유도
<br>비유도 매체(unguided media) : 무선 랜 혹은 디지털 위성 채널처럼 야외 공간으로 파형을 전파


<br><br><br><br>
<br>가장 싸고 가장 많이 이용하는 전송 매체 (전화기에서 전화국 스위치까지 유선 연결의 99% 이상이 이를 이용)
<br>구성

<br>2개의 절연 구리선, 각각은 약 1mm 굵기로 규칙적인 나선 형태로 배열된다.
<br>이웃하는 쌍들 간에 전기 간섭을 줄이기 위해 선들이 꼬여 있는 것이며, 이러한 한 쌍의 선이 하나의 통신 링크를 구성한다.


<br>데이터 전송률 : 전송선의 두께, 송신기와 수신기 사이의 거리에 따라 다르다.
<br>사용 : UTF(Unshielded Twisted Pair) - 빌딩의 컴퓨터 네트워크, LAN에서 가장 많이 이용하는 매체
<br><br><br><br>
<br>구조 : 꼬임쌍선처럼 2개의 구리선으로 되어 있으나, 두 구리선이 평행하지 않고 동심원 형태를 이룬다.
<br>데이터 전송률 : 동심원 형태의 구조와 특수 절연 및 차폐를 가지고 있어 꼬임쌍선보다 더 높은 데이터 전송률을 얻을 수 있다.
<br>사용 : 케이블 TV 시스템
<br>특징

<br>유도 공유 매체(shared medium)으로 사용할 수 있다.
<br>여러 종단 시스템은 케이블에 직접 연결할 수 있고, 모든 종단 시스템은 다른 종단 시스템이 전송하는 모든 것을 수신한다.


<br><br><br><br>
<br>비트를 나타내는 빛의 파동을 전하는 가늘고 유연한 매체
<br>초당 10~100기가비트에 이르는 높은 비트율을 지원한다.
<br>광 장비는 고가이므로 근거리 전송(LAN, 가정)에는 이용하기 어렵다.
<br>특징

<br>전자기성 간섭에 영향을 받지 않는다.
<br>100 km까지는 신호 감쇠 현상이 매우 적다.
<br>태핑(tapping, 도청)하기가 어렵다.


<br>사용 : 해저 링크, 광역 전화 네트워크
<br><br><br><br>
<br>전자기 스펙트럼으로 신호를 전달한다.
<br>특징

<br>물리 선로를 설치할 필요가 없다.
<br>벽을 관통할 수 있다.
<br>이동 사용자에게 연결성을 제공하며, 먼 거리까지 신호 전달이 가능하다
<br>전파 환경과 신호가 전달되는 거리에 많은 영향을 받는다.

<br>주변 환경을 결정하는 요소

<br>경로손실(path loss)
<br>섀도 페이딩(shadow fading) : 신호가 먼 거리를 지나감에 따라 / 방해 물질을 돌아가거나 통과함에 따라 신호 강도가 약해지는 현상
<br>다중경로 페이딩 : 간섭 물체의 신호 반사 때문에 발생
<br>간섭 : 다른 라디오 채널이나 전자기 신호 때문에 발생






<br>크게 3개의 그룹으로 분류

<br>1~2 m의 매우 짧은 거리에서 동작하는 채널 (무선 헤드셋, 키보드 등)
<br>로컬 라디오 채널 : 십~수백 미터에 걸쳐 근거리 네트워크로 동작하는 채널 (무선 랜 기술)
<br>광역 라디오 채널 : 수십 킬로미터에 걸쳐 광역에서 작동하는 채널 (셀룰러 접속 기술)


<br><br><br><br>
<br>지상 스테이션이라는 둘 이상의 지상 기반 마이크로파 송신기/수신기를 연결한다.
<br>과정

<br>한 주파수 대역으로 전송 신호를 수신
<br>리피터(repeater)를 통해 그 신호를 재생
<br>그 신호를 다른 주파수 대역으로 전송


<br>전송률 : 초당 기가비트
<br>두 가지 종류

<br>정지 위성(geostationary satellite) : 지상 36,000 km에 쏘아올려져 일정 위치에 영원히 머무름
<br>저궤도 위성(low-earth orbiting(LEO) satellite) : 지구를 공전하며 지상국뿐만 아니라 서로 통신할 수 있음<br>
→ 미래의 인터넷 접속에 이용될 수도?


]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.2-네트워크의-가장자리\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.2 네트워크의 가장자리/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:53:58 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/210128184-301c72b1-c174-432e-b14d-8824c2a58cea.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/210128184-301c72b1-c174-432e-b14d-8824c2a58cea.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.3 네트워크 코어]]></title><description><![CDATA[ 
 <br><br>1.2절의 종단 시스템을 연결하는 패킷 스위치와 링크의 그물망(mesh)에 대하여 살펴보도록 하자.<br>아래 그림에서의 굵은 선들은 네트워크 코어를 나타낸 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/210137238-bf8d10d3-ef09-4263-9339-7fedbb2d619e.png" alt="네트워크 코어" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br><br>링크와 스위치의 네트워크를 통해 데이터를 이동시키는 두 가지 기본 방식<br>
<br>패킷 교환(packet switching) : 보장되지 않는 (e.g., 인터넷)
<br>회선 교환(circuit switching) : 자원을 예약 → 보장된
<br><br>
<br>
<br><br><br>종단 시스템들은 서로 메시지(message)를 교환한다. (출발지 종단 시스템에서 목적지 종단 시스템으로 메시지를 보냄)<br><br><br>
<br>
송신 시스템은 메시지를 패킷(packet)이라고 하는 작은 데이터 덩어리로 분할한다.

<br>
각 패킷은 통신 링크(communication link)와 패킷 스위치(packet switch)를 거치게 된다.

<br>패킷 스위치에는 라우터(router)와 링크 계층 스위치(link-layer switch)의 두 가지 유형이 존재한다.


<br>
패킷은 링크의 최대 전송률과 같은 속도로 각각의 통신 링크에서 전송된다.

<br>출발지 종단 시스템 혹은 패킷 스위치가 R bps(bits per second)의 속도로 링크에서 L 비트의 패킷을 송신한다면,<br>
그 패킷을 전송하는 데 걸리는 시간은 L/R 초


<br><br>
<br><br><br>
💡 스위치가 패킷의 첫 비트를 출력 링크로 전송하기 전에 전체 패킷을 받아야 한다.
<br>저장-후-전달 전송 방식은 대부분의 패킷 스위치가 이용하는 방식이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/210137289-63c6e459-0892-4ee6-8a91-d35fe4f9fb51.png" alt="저장-후-전달 패킷 교환" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>위는 하나의 라우터로 연결되고 2개의 종단 시스템으로 구성된 매우 간단한 네트워크 예시이다.<br>
<br>출발지는 목적지로 전송할 3개의 패킷(1, 2, 3)을 가지고 있으며, 각각의 패킷은 L 비트로 구성되어 있다.
<br>출발지는 링크에서 L 비트의 패킷을 R bps(bits per second)의 속도로 송신하고 있다.
<br><br><br>그림에서 보이는 것처럼 출발지는 패킷 1의 일부분을 전송했고, 그 부분이 라우터에 도착해있는 상황을 생각해보자.<br>이때 라우터는 저장-후-전달 방식을 채택하고 있기 때문에 수신한 비트를 전송할 수 없다. 그 대신, 아래의 과정이 진행된다.<br>
<br>패킷의 비트를 먼저 저장(buffer, 즉 ‘store’)한다.
<br>라우터가 패킷의 모든 비트를 수신하였다면 그제서야 출력 링크로 그 패킷을 전송(transmit, 즉 ‘forward’)하기 시작한다.
<br><br><br><br>1-1. 출발지에서 패킷 1을 송신하기 시작해서 패킷 1의 전체를 목적지에서 수신할 때까지의 경과 시간을 계산해보자.
복사<br>여기서 전파 지연(propagation delay)은 무시하도록 하자. 이는 비트가 빛의 속도에 가까운 속도로 통신선을 거쳐가는 데에 걸리는 시간을 말한다.<br>
→ 1.4절에서 논의<br>
<br>0 초 : 출발지가 패킷 1을 전송하기 시작
<br>L/R 초

<br>출발지는 패킷 1의 전체 데이터를 전송 완료했으며, 전체가 라우터에 수신되고 저장되었다. (전파 지연이 없기 때문)
<br>라우터가 전체 패킷을 수신했기 때문에 라우터는 목적지를 향해 그 패킷을 출력 링크로 전송하기 시작한다.


<br>2L/R 초 : 라우터는 전체 패킷을 전송했으며, 목적지는 패킷 1 전체를 수신 완료한다. (전파 지연이 없기 때문)
<br><br><br>따라서 저장-후-전달 전송 방식을 채택한다면 전체 지연은 2L/R이며,<br>
이 방식 없이 스위치에 비트가 도착하자마자 곧바로 전달을 하게 된다면 전체 지연은 L/R이 된다.<br>하지만 라우터는 전달하기에 앞서 전체 패킷을 수신, 저장, 처리할 필요가 있다. (이것도 1.4절에서 자세히 논의한다.)<br><br><br>1-2. 출발지가 패킷 1을 송신하기 시작한 순간부터 목적지 노드가 3개의 모든 패킷(1, 2, 3)을 수신할 때까지 경과된 전체 시간을 계산해보자.
복사<br>
<br>0 초 : 출발지가 패킷 1을 전송하기 시작
<br>L/R 초

<br>라우터는 패킷 1을 수신 완료, 이를 전송하기 시작
<br>출발지는 패킷 2를 전송하기 시작


<br>2L/R 초

<br>라우터는 패킷 2를 수신 완료, 이를 전송하기 시작
<br>목적지는 패킷 1 전체를 수신 완료
<br>출발지는 패킷 3을 전송하기 시작


<br>3L/R 초

<br>라우터는 패킷 3를 수신 완료, 이를 전송하기 시작
<br>목적지는 패킷 2 전체를 수신 완료


<br>4L/R 초 : 목적지는 패킷 3 전체를 수신 완료
<br><br><br>따라서 저장-후-전달 전송 방식을 채택한다면 목적지는 4L/R 초에 3개의 모든 패킷을 수신하게 된다.<br><br><br><br>2. 출발지로부터 목적지 노드까지 N개의 링크로 구성되고 각각은 전송률이 R인 경로를 통해 하나의 패킷을 전송하는 경우를 생각해보자.
복사<br>즉, 출발지와 목적지 사이에 N-1개의 라우터가 존재한다는 것이다.<br>실제로 라우터는 보통 여러 개의 링크를 갖는데, 그 이유는 라우터의 기능이 입력되는 패킷을 출력 링크로 교환하는 것이기 때문이다.<br><br><br>1-1, 1-2와 같은 논리를 적용한다면 종단 간 지연은 다음과 같음을 알 수 있다.<br><img src="https://user-images.githubusercontent.com/86337233/210137330-0534c802-b6cd-41e4-915d-d8a3dac5d07a.png" alt="종단 간 지연" referrerpolicy="no-referrer" style="width: 250px; max-width: 100%;"><br><br>
<br>
<br><br><br>
<br>각 패킷 스위치는 접속된 여러 링크를 가지고 있으며, 패킷 스위치는 각 링크에 대해 출력 버퍼를 가지고 있다.
<br>출력 버퍼(output buffer)는 출력 큐(output queue)로도 불리며, 그 링크로 송신하려고 하는 패킷을 저장하고 있다.<br>
이는 패킷 교환에서 중요한 역할을 한다.
<br>패킷이 겪는 지연은 앞에서 보았던 저장-후-전달 지연만 존재하는 것이 아니다.<br><br><br>도착하는 패킷은 한 링크로 전송되어야 한다. 하지만 만약 그 링크가 다른 패킷을 전송하고 있는 중이라면 어떻게 해야 하는가?
복사<br>→ 도착하는 패킷은 출력 버퍼에서 대기해야 한다. = 큐잉 지연<br>
<br>큐잉 지연은 가변적이며, 네트워크의 혼잡 정도에 따른다.
<br>버퍼 공간의 크기는 유한하기 때문에 패킷 손실(packet loss)이 발생할 수 있다.
<br>즉, 버퍼가 전송을 위해 대기 중인 다른 패킷들로 꽉 차 있는 경우라면 도착하는 패킷 또는 큐에 대기 중인 패킷을 폐기(drop)하는 것이다.
<br><br><br>아래의 예시를 보자.<br><img src="https://user-images.githubusercontent.com/86337233/210137348-9f7c303f-5261-4e62-8885-36e36eeb4dea.png" alt="패킷 교환" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>여기서 라우터는 수신한 패킷을 15 Mbps의 링크로 전달하고 있다.<br>만약 짧은 기간 동안 라우터에 도착하는 패킷의 전송률이 15 Mbps를 초과하게 된다면, 링크의 출력 버퍼에 패킷들이 큐잉될 것이다.<br><br>
<br><br><br>
라우터는 접속된 통신 링크 중 하나로 도착하는 패킷을 받아, 접속된 통신 링크 중 다른 링크로 그 패킷을 전달한다.
<br>그렇다면 라우터는 그 패킷을 어느 링크로 전달해야 하는지를 어떻게 결정할까?<br>패킷 전달은 실제 여러 유형의 컴퓨터 네트워크에서 다른 방식으로 실행되는데, 여기서는 라우팅이 인터넷에서 어떻게 실행되는지를 간단히 설명한다.<br><br><br><br>
<br>인터넷에서 모든 종단 시스템은 IP 주소를 가지며, 이 주소는 계층적 구조를 갖는다.
<br>출발지 종단 시스템이 목적이 종단 시스템으로 패킷을 보내고자 할 때 출발지는 패킷의 헤더에 목적지의 IP 주소를 포함한다.
<br><br><br><br>각 라우터는 목적지 주소 또는 목적지 주소의 일부를 라우터의 출력 링크로 매핑하는 포워딩 테이블을 가지고 있다.<br>따라서 라우터가 수신한 패킷을 어느 링크로 전달해야 하는지를 결정하는 과정은 다음과 같다.<br>
<br>패킷이 라우터에 도착한다.
<br>라우터는 패킷의 IP 주소를 조사한다.
<br>해당 목적지 주소를 이용하여 포워딩 테이블을 검색한다.
<br>그 패킷을 출력 링크로 보낸다.
<br><br><br><br>그렇다면 포워딩 테이블은 어떻게 설정되는 것일까? (5장에서 자세히 논의)<br>인터넷은 자동으로 포워딩 테이블을 설정하는 데 이용되는 여러 특별한 라우팅 프로토콜을 가지고 있다.<br>e.g., 각 라우터로부터 각 목적지까지 최단 경로를 결정 → 라우터에 포워팅 테이블을 설정하는 데에는 이 최단 경로 결과를 이용한다.<br><br>
<br>
<br><br><br>
<br>회선 교환 네트워크에서는 종단 시스템 간에 통신을 제공하기 위해<br>
경로상에서 필요한 자원(버퍼, 링크 전송률)은 통신 세션(session) 동안에 확보 또는 예약(reserve)된다. (↔︎ 패킷 교환 네트워크)
<br>세션 메시지는 온디맨드(on-demand) 방식으로 자원을 요청하여 사용한다.
<br>따라서 통신 링크에 대한 접속을 위해 큐에서 대기해야 할 수도 있다.
<br><br><br>
<br>연결 = 회선(circuit) : 송신자와 수신자 간의 경로에 있는 스위치들이 해당 연결 상태를 유지해야 한다.
<br>
<br>송신자가 정보를 보내기 전, 네트워크는 송신자와 수신자 간의 연결을 설정해야 한다.
<br>네트워크가 회선을 설정할 때, 그 연결이 이루어지는 동안 네트워크 링크에 일정한 전송률을 예약한다.
<br>주어진 전송률이 송신자-수신자 연결을 위해 예약되기 때문에, 송신자는 수신자에게 보장된(guaranteed) 일정 전송률로 데이터를 보낼 수 있다.
<br><br><br><br>아래는 4개의 스위치와 4개의 링크로 구성된 회선 교환 네트워크를 나타낸 그림이다.<br>이들 각 링크는 4개의 회선을 가지므로 각 링크는 4개의 동시 연결을 지원할 수 있다.<br><img src="https://user-images.githubusercontent.com/86337233/210137402-59bd4469-e343-430c-96df-9f5c6c072005.png" alt="회선 교환 네트워크" referrerpolicy="no-referrer" style="width: 470px; max-width: 100%;"><br><br>
<br><br>만약 두 호스트가 통신하고 싶을 때, 네트워크는 두 호스트 사이에 지정된 종단 간 연결을 설정한다.<br>즉, 호스트 A가 호스트 B와 통신하기 위해서 네트워크는 먼저 A의 링크와 B의 링크 각각에서 한 회선씩을 예약한다.<br>
(위 그림에서는 링크(0, 0)의 두 번째 회선, 링크(1, 1)의 두 번째 회선)<br>각 링크에 대하여 연결이 지속되는 동안 해당 연결은 링크 전체 전송 용량의 1/4를 얻는다. (각 링크는 4개의 회선을 가지고 있기 때문)<br><br><br><br><br><br>반대로, 한 호스트가 인터넷 같은 패킷 교환 네트워크를 통해 다른 호스트로 패킷을 보내고자 하는 경우에는 어떤 일이 발생할까?
복사<br>회선 교환과 마찬가지로 패킷은 일련의 통신 링크를 통해 전송된다.<br>하지만 회선 교환과는 다르게, 패킷 교환은 링크 자원을 예약하지 않고 네트워크로 보내진다.<br><br><br>
💡 패킷 교환 네트워크는 일정한 시간 내에 데이터를 전달하는 것을 보장하지 않는다.
<br><br>
<br><br><br>링크 내 한 회선이 구현되는 방법<br>
<br>주파수 분할 다중화(Frequency-Division Multiplexing, FDM) : 각 회선은 지속적으로 대역폭의 일부를 얻는다.
<br>시분할 다중화(Time-Division Multiplexing, TDM) : 각 회선은 주기적으로(짧은 시간 즉, 슬롯 동안) 전체 대역폭을 얻는다.
<br><br><br><br>
<br>링크를 통해 설정된 연결은 그 링크의 주파수 스펙트럼을 공유한다.
<br>그 링크는 연결되는 동안 각 연결에 대해 주파수 대역을 고정 제공한다. = 대역폭(bandwidth)
<br><img src="https://user-images.githubusercontent.com/86337233/210137431-63860cea-2921-47f8-89f4-19656ee81de5.png" alt="FDM" referrerpolicy="no-referrer" style="width: 300px; max-width: 100%;"><br><br>
<br><br><br>
<br>TDM 링크는 시간을 일정 주기의 프레임으로 구분하고, 각 프레임은 고정된 수의 시간 슬롯으로 나뉜다.
<br>네트워크가 링크를 통해 하나의 연결을 설정할 때, 네트워크는 모든 프레임에서 시간 슬롯 1개를 그 연결에 할당한다.
<br>전송률 : 한 슬롯 안의 비트 수 × 프레임 전송률
<br><img src="https://user-images.githubusercontent.com/86337233/210137432-426fd263-6cac-45ab-8262-a82bf772e1cc.png" alt="TDM" referrerpolicy="no-referrer" style="width: 350px; max-width: 100%;"><br><br>
<br><br><br>[ 패킷 교환 옹호자 ]<br>
<br>주장

<br>패킷 교환이 회선 교환보다 전송 용량의 공유에서 더 효율적이다.
<br>패킷 교환이 회선 교환보다 더 간단하고 효율적이며, 구현 비용이 적다.


<br>근거

<br>회선 교환에서 통신을 위해서는 자원이 항상 각각의 사용자에게 예약되어야만 한다.
<br>할당된 회선이 비활용 기간(silent period)에는 자원을 점유한 채로 놀게 되기 때문에 자원 이용률이 감소한다.
<br>즉, 회선 교환에서는 사용되지 않는 네트워크 자원(연결 경로상의 링크 주파수 대역이나 슬롯)은 다른 진행 중인 연결이 대신해서 사용할 수 없기 때문에<br>
패킷 교환이 더 효율적이다.


<br><br><br>[ 패킷 교환 반대자 ]<br>
<br>주장 : 패킷 교환은 실시간 서비스에는 적당하지 않다.
<br>근거 : 주로 큐잉 지연에서 발생하는 종단 간의 지연 (불규칙적이고 예측할 수 없음)
<br><br><br>과연 패킷 교환 반대자의 주장은 옳을까?<br>이를 확인해보기 위해서 간단한 예 두 가지를 살펴보자.<br><br><br><br><br><br>1. 사용자가 1 Mbps 링크를 공유한다고 가정하고, 각 사용자들은 활동 시간과 비활동 시간을 반복한다고 하자.
사용자는 전체 시간에서 10%만 활동하며 나머지 90% 시간에는 활동하지 않는다.
복사<br>
<br>활동 시간 : 100 kbps의 일정 속도로 데이터를 생산할 때
<br>비활동 시간 : 데이터를 생산하지 않을 때
<br><br><br>✅ 회선 교환의 경우, 100 kbps가 항상 각각의 사용자에게 예약되어야 한다.<br>
TDM 회선 교환을 예시로, 초 프레임이 100 ms마다 10개 시간 슬롯으로 나뉜다고 한다면 각 사용자에게는 한 프레임에 한 번의 시간 슬롯이 할당된다.<br>
따라서 회선 교환 링크는 동시에 10명(= 1 Mbps / 100 kbps)만 지원할 수 있다.<br><br><br>✅ 패킷 교환의 경우, 한 특정 사용자가 활동을 하고 있을 확률은 10%이다.<br>
만약 10명 이하의 동시 사용자가 있다면 그 확률은 99.96%, 데이터의 통합 도착률은 1 Mbps(링크의 출력률)보다 작거나 같다.<br>
따라서 10명 이상의 동시 사용자가 있다면 패킷의 통합 도착률이 링크의 출력 용량을 초과하기 때문에 출력 큐가 커지기 시작한다.<br>
(이 큐는 통합 입력률이 1 Mbps 이하로 떨어질 때까지 커질 것이고, 이후에는 큐 길이가 줄어들기 시작할 것)<br><br><br>10명 이상의 동시 사용자가 있을 확률은 0.04%로 굉장히 작으므로,<br>
패킷 교환은 거의 항상 회선 교환과 대등한 지연 성능을 가지면서도 거의 3배 이상의 사용자 수를 허용한다.<br><br><br><br><br><br>2. 10명의 사용자가 있다고 가정하자. 1번과 동일하게, 사용자는 1 Mbps 링크를 공유한다.
한 사용자가 한번에 1,000비트 패킷을 1,000개 생성하고 다른 사용자는 패킷을 생성하지 않는다.
복사<br><br><br>✅ 회선 교환의 경우를 먼저 보자.<br>
TDM 회선 교환을 예시로, 한 프레임은 10개 슬롯으로 구성되고 각 슬롯은 1,000비트로 구성되었다면<br>
사용자는 데이터 전송을 위해 한 프레임당 1개의 시간 슬롯만 사용할 수 있다. 반면에 각 프레임에 남겨진 9개의 시간 슬롯은 쉬는 상태가 된다.<br>
따라서 사용자의 데이터 100만 비트를 모두 전송하려면 10초가 걸린다.<br><br><br>✅ 패킷 교환의 경우,<br>
패킷을 생성하는 다른 사용자가 없기 때문에 다중화가 요구되지 않고, 사용자는 1 Mbps의 링크가 가득 찰 때까지 패킷을 계속 보낼 수 있다.<br>
따라서 사용자의 데이터 100만 비트는 1초 만에 모두 전송된다.<br><br><br><br><br><br>앞의 두 가지 예에서 명확하게 볼 수 있듯, 패킷 교환이 회선 교환보다 성능이 우수하다.<br>따라서 오늘날의 전기통신 네트워크의 추세는 패킷 교환으로 전환되고 있다.<br><br><br>링크 전송률을 공유하는 두 방식의 가장 큰 차이점은 아래와 같이 정리할 수 있다.<br>
<br>회선 교환 방식 : 요구에 관계없이 미리 전송 링크의 사용을 할당한다.
<br>패킷 교환 방식 : 요구할 때만 링크의 사용을 할당한다.
<br><br>
<br>
<br><br><br><br>
<br>
ISP(Internet Service Provider) : 패킷 스위치와 통신 링크로 이루어진 네트워크

<br>종단 시스템에게 다양한 네트워크 접속을 제공한다. (e.g., 가정용 초고속 접속, 고속 LAN 접속, 이동 무선 접속 등)
<br>CP(content provider)에게 인터넷 접속을 제공 → 웹 사이트나 비디오 서버를 인터넷에 직접 연결할 수 있게 된다.


<br>
종단 시스템(PC, 스마트폰, 웹 서버 등)은 접속 ISP를 통해 인터넷에 연결된다.

<br>
접속 ISP는 다양한 접속 기술(DSL, 케이블, FTTH, 와이파이, 셀룰러(이동 통신) 등)을 이용하여 유선 또는 무선 연결을 제공한다.

<br><br><br>접속 ISP는 텔코 혹은 케이블 회사일 필요가 없다.<br>
e.g., 대학교 - 학생, 직원, 교수에게 인터넷 접속을 제공, 회사 - 직원에게 인터넷 접속을 제공<br>그러나 종단 사용자들과 콘텐츠 제공자들을 모두 접속 ISP로 연결하는 것은 말도 안 된다.<br>이를 위해서는 접속 ISP들이 서로 연결되어야만 하기 때문에 네트워크의 네트워크(network of network)가 탄생하게 되었다.<br><br><br>
💡 목표 : 모든 종단 시스템이 서로에게 패킷을 보낼 수 있도록 접속 ISP를 연결하는 것
<br>가장 간단한 방법은 각 접속 ISP를 직접 서로 다른 ISP와 연결하는 것이다.<br>하지만 각 접속 ISP가 전 세계적으로 다른 접속 ISP와 수십만 개의 개별적인 통신 링크를 유지해야 하기 때문에,<br>
이런 그물망 설계는 접속 ISP에게 너무 많은 비용을 발생시킨다.<br><br><br>오늘날의 인터넷 네트워크 구조를 이해하기 위해 점진적으로 일련의 네트워크 구조를 만들어보자.<br><br><br><br>
모든 접속 ISP를 하나의 글로벌 통과(transit) ISP와 연결한다.
<br>
<br>글로벌 통과 ISP : 라우터 + 전 세계에 이르고, 적어도 수십만 개의 접속 ISP와 가까운 곳에 있는 라우터를 갖는 통신 링크의 네트워크
<br>글로벌 ISP가 이러한 확장된 네트워크를 구축하는 데는 매우 많은 비용이 든다.
<br>글로벌 ISP는 이익을 얻기 위해 각각의 접속 ISP에 연결을 위한 과금을 부과한다.

<br>접속 ISP는 고객(customer)
<br>글로벌 ISP는 제공자(provider)


<br><br>
<br><br><br>어느 회사가 수익을 내는 글로벌 ISP를 구축하고 운영한다면, 다른 회사가 자신의 글로벌 ISP를 구축하여 경쟁하는 것은 자연스러운 일이다.<br>이것이 네트워크 구조 2로 진화한다.<br><br><br>
수십만 개의 접속 ISP와 다중의 글로벌 ISP
<br>
<br>2계층구조

<br>상위층 : 글로벌 ISP 서비스 제공자가 존재
<br>하위층 : 접속 ISP가 존재


<br>글로벌 ISP들은 서로 연결해야만 한다.
<br>서로 연결되지 않는다면 하나의 글로벌 ISP와 연결된 접속 ISP는 다른 글로벌 통과 서비스 제공자에 연결된 접속 ISP와 통신할 수 없다.
<br><br><br><br>현실적으로 전 세계의 모든 도시에 존재하는 ISP는 없다.<br>대신, 어느 주어진 지역에서 그 지역에 있는 접속 ISP들이 연결하는 지역(regional) ISP가 존재하며, 각 지역 ISP는 1계층(tier-1) ISP들과 연결된다.<br>
(실제로 존재하는 1계층 ISP는 전 세계적으로 모든 도시에 존재하지는 않는다.)<br><br>
<br><br><br>
다중계층구조(접속 ISP, 지역 ISP, 1계층 ISP) → 오늘날의 인터넷과 대략적으로 유사
<br>여러 경쟁적인 1계층 ISP들이 존재하며, 한 지역에 여러 경쟁적인 지역 ISP들이 존재할 수 있다.<br>더 복잡한 경우, 작은 지역 ISP들이 연결하는 좀 더 큰 지역 ISP들이 있을 수 있다.<br><br><br>이런 계층구조에서의 과금은 크게 다음과 같이 진행된다.<br>고객 ISP는 글로벌 인터넷 연결성(interconnectivity)을 얻기 위해 서비스 제공 ISP에게 요금을 지불하기 때문에<br>
"각 레벨에는 고객-제공자 관계가 존재한다"고 할 수 있다.<br>
<br>각각의 접속 ISP는 자신이 연결하는 지역 ISP에게 요금을 지불한다.
<br>각 지역 ISP는 자신이 연결하는 1계층 ISP에게 요금을 지불한다.
<br>1계층 ISP는 계층구조의 최상위에 있기 때문에 아무에게도 요금을 지불하지 않는다.
<br><br>
<br><br><br>
다중계층구조(접속 ISP, 지역 ISP, 1계층 ISP) + PoP + 멀티홈 + 피어링 + IXP
<br><br><br>오늘날의 인터넷과 좀 더 유사한 네트워크를 구축하기 위해서는 네트워크 구조 3에 아래 4가지 항목들을 포함해야 한다.<br>
<br>
PoP(Points of Presence)

<br>단지 제공자의 네트워크 내에 있는(같은 위치에 존재하는) 하나 혹은 그 이상의 라우터 그룹
<br>최하위(접속 ISP) 계층을 제외한 모든 계층에 존재하며, 고객 ISP가 제공자 ISP에 연결될 수 있다.
<br>고객 네트워크가 제공자의 PoP에 연결되기 위해,<br>
고객은 자신의 라우터 중 하나를 PoP에 있는 라우터에 직접 연결하도록 고속 링크를 제3자(third-party) 통신 서비스 제공자로부터 임대할 수 있다.


<br>
멀티홈(multi-homing)

<br>둘 혹은 그 이상의 제공자 ISP에 연결하는 것
<br>e.g., 한 접속 ISP가 2개의 ISP에 연결, 2개의 지역 ISP와 함께 하나의 1계층 ISP에 연결
<br>1계층 ISP를 제외한 모든 ISP는 멀티홈을 선택할 수 있다.
<br>한 ISP가 멀티홈을 하면 서비스 제공자 중 하나가 연결되지 않더라도 인터넷으로 패킷을 계속 송수신할 수 있게 된다.


<br>
피어링(peering)

<br>고객 ISP가 서비스 제공 ISP에게 지불하는 요금을 줄이기 위해 인터넷 계층구조의 같은 계층에 있는 가까운 ISP들은 피어링할 수 있다.<br>
(두 ISP가 피어링하면 일반적으로 서로 요금을 지불하지 않음)
<br>즉, 이들 간에 송수신되는 모든 트래픽을 상위 계층 ISP를 통하지 않고 직접 송수신할 수 있도록 자신들의 네트워크를 서로 직접 연결하는 것이다.
<br>1계층 ISP들도 서로 피어링할 수 있다.


<br>
IXP(Internet Exchange Point)

<br>다중의 ISP들이 서로 피어링할 수 있는 만남의 장소
<br>일반적으로 교환기를 갖춘 독자적인 빌딩에 존재한다.


<br><br>
<br><br><br>
다중계층구조(접속 ISP, 지역 ISP, 1계층 ISP) + PoP + 멀티홈 + 피어링 + IXP + 콘텐츠 제공 네트워크
<br><br><br>이는 2012년의 인터넷을 기술하며, 구글이 이러한 콘텐츠 제공자 네트워크 주도하는 한 예이다.<br>
<br>구글 데이터 센터는 모두 구글의 사설 TCP/IP 네트워크를 통해 연결되어 있으며, 이 네트워크는 전 세계를 연결하며 공중 인터넷과는 분리되어 있다.
<br>구글 사설 네트워크는 구글 서버로 오가는 트래픽만 전달한다.
<br>즉, 하위 계층 ISP들과 피어링을 함으로써(그들과 직접 연결하거나 IXP에서 그들과 연결함으로써) 인터넷의 상위 계층을 ‘우회(bypass)’하고 있다.<br>
(아래 그림 참고)
<br><br><br>
<br>많은 접속 ISP는 여전히 1계층 네트워크를 통해서만 도달할 수 있기 때문에<br>
구글 네트워크도 1계층 ISP들과 연결하고 그들과 교환하는 트래픽에 대해 이 ISP들에게 요금을 지불한다.
<br>콘텐츠 제공자들이 자신의 네트워크를 구축함으로써 얻는 이점

<br>상위 계층 ISP들에게 지불하는 요금을 줄일 수 있다.
<br>최종 사용자들에게 자신들의 서비스가 궁극적으로 어떻게 전달되는지에 대한 더 많은 통제권을 가질 수 있다.


<br><br><br><img src="https://user-images.githubusercontent.com/86337233/210137433-fd5cf02e-5e56-4acc-94c1-d3bdb4697b13.png" alt="ISP의 연결" referrerpolicy="no-referrer" style="width: 580px; max-width: 100%;"><br><br>
<br><br><br><br><br>최종 정리하자면 다음과 같다.<br>
💡 오늘날의 인터넷(네트워크의 네트워크)는 12개 정도의 1계층 ISP들과 수십만 개의 하위 계층 ISP들로 구성되어 있다.
<br>
<br>하위 계층 ISP들은 상위 계층 ISP들과 연결하고, 상위 계층 ISP들은 서로 연결한다.
<br>사용자와 콘텐츠 제공자는 하위 계층 ISP 고객이고, 하위 계층 ISP들은 상위 계층 ISP들이 고객이다.
<br>최근에 주요 콘텐츠 제공자도 자신의 네트워크를 구축했고 가능한 곳에서 하위 계층 ISP들과 직접 연결한다.
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.3-네트워크-코어\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.3 네트워크 코어/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 06:51:39 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/210137238-bf8d10d3-ef09-4263-9339-7fedbb2d619e.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/210137238-bf8d10d3-ef09-4263-9339-7fedbb2d619e.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.4 패킷 교환 네트워크에서의 지연, 손실과 처리율]]></title><description><![CDATA[ 
 <br><br>
인터넷은 종단 시스템에서 수행되는 분산 애플리케이션에게 서비스를 제공하는 인프라스트럭처이다. (1.1절)
<br>이상적으로는 인터넷 서비스가 데이터의 손실 없이 즉시 두 종단 시스템 간에 원하는 만큼의 데이터를 이동시키기를 원한다.<br>하지만 현실에서 이는 어려우며, 컴퓨터 네트워크는 두 종단 시스템 간에 전달될 수 있는 초당 데이터의 양, 즉 처리율을 제한한다.<br>이로 인해 종단 시스템 간에 지연이 발생하며, 패킷을 잃어버리게 되기도 한다.<br><br>
<br>
<br><br><br>패킷은 한 호스트(출발지)에서 시작하고 일련의 라우터들을 통과하며 다른 호스트(목적지)에 도달한다.<br>패킷이 경로를 따라 한 노드에서 다음 노드로 전달될 때 패킷은 경로상의 각 노드에서 다양한 지연을 겪게 되며,<br>
이들은 쌓여서 전체 노드 지연(total nodal delay)을 일으킨다.<br>
<br>노드 처리 지연(nodal processing delay)
<br>큐잉 지연(queuing delay)
<br>전송 지연(transmission delay)
<br>전파 지연(propagation delay)
<br><br><br>아래의 그림을 보며 큰 그림을 그려보자. 이는 라우터 A에서의 노드 지연을 나타낸 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/210216460-d4e1eacc-cde9-4185-aca8-661e78a20427.png" alt="노드 지연" referrerpolicy="no-referrer" style="width: 470px; max-width: 100%;"><br><br>
<br><br>출발지와 목적지 사이 종단 간 경로의 일부로서, 한 패킷이 업스트림 노드로부터 라우터 A를 통해 라우터 B로 보내진다.<br>
<br>업스트림(upstream) : 클라이언트에서 서버로 전송되는 데이터의 흐름
<br>다운스트림(downstream) : 서버에서 클라이언트로 전송되는 데이터의 흐름, 일반적으로 다운스트림 트래픽은 업스트림 트래픽보다 더 많은 볼륨이 있다.
<br><br><br>라우터 A는 라우터 B에 이르는 하나의 출력(outgoing) 링크를 가지며, 이 링크 앞에 큐(queue, 버퍼(buffer))가 존재한다.<br>
<br>패킷이 업스트림 노드로부터 라우터 A에 도착한다.
<br>라우터 A는 그 패킷에 대한 적당한 출력 링크를 결정하기 위해 패킷 헤더를 조사한다.
<br>라우터 A는 선택된 링크로 그 패킷을 보낸다. (그림에서 선택된 링크 = 라우터 B에 이르는 링크)
<br><br><br>만약 라우터 B에 이르는 링크에 현재 전송되는 다른 패킷이 존재하거나, 큐에 자신보다 앞선 다른 패킷들이 존재한다면 어떻게 되는가?
복사<br>새로 도착하는 패킷은 그 링크를 이용하기 위해 큐에 들어갈 것이다.<br><br><br>이 모든 과정에서 여러 지연이 발생한다.<br><br><br><br>
💡 패킷 헤더를 조사하고 그 패킷을 어디로 보낼지 결정하는 시간
<br>
<br>라우터 A로 패킷의 비트를 전송할 때 업스트림 노드에서 발생하는 패킷의 비트 레벨 오류를 조사하는 데 필요한 시간과 같은 요소를 포함할 수도 있다.
<br>라우터는 이 노드 처리 후, 그 패킷을 라우터 B에 이르는 링크에 앞선 큐에 보낸다.
<br>고속 라우터의 처리 지연은 일반적으로 수 마이크로초이다.
<br><br><br><br>
💡 패킷이 큐에서 링크로 전송되기를 기다리는 시간
<br>
<br>특정 패킷의 큐잉 지연 길이는 큐에 저장되어 링크로 전송되기를 기다리는, 앞서 도착한 다른 패킷의 수에 의해 결정된다.
<br>주어진 패킷의 지연은 패킷마다 상당히 다르다.

<br>큐가 비어있고 다른 패킷이 전송 중인 상태가 아니라면 패킷의 큐잉 지연 → 0
<br>트래픽이 많고 다른 많은 패킷이 전송 대기 중이라면 패킷의 큐잉 지연 → 매우 길어진다.


<br>수 마이크로초 ~ 수 밀리초
<br><br><br><br>
💡 패킷의 모든 비트를 링크로 밀어내는 데(또는 전송하는 데) 필요한 시간
<br>패킷이 선입선출(FIFO) 방식으로 전송된다고 가정해보자. (앞서 도착한 다른 모든 패킷이 전송된 다음에 전송)<br>패킷의 길이는 L 비트, 라우터 A에서 라우터 B까지 링크의 전송률은 R bps라고 해보자. (R는 라우터 B로 가는 링크의 전송률에 의해 결정됨)<br>이때 전송 지연은 L/R이다. (수 마이크로초 ~ 수 밀리초)<br><br><br><br>
💡 비트가 라우터 A 상에서의 링크에서 라우터 B까지의 전파에 필요한 시간
<br>
<br>비트는 링크의 전파 속도로 전파된다.
<br>전파 속도는 링크의 물리 매체(광섬유, 꼬임쌍선 등)에 따라 다르며, 범위는 2×(10^8)미터/초 ~ 3×(10^8)미터/초이다.<br>
→ 빛의 속도와 같거나 약간 작다.
<br>라우터 A와 B 사이의 거리를 d, 링크의 전파 속도를 s라고 한다면 전파 지연은 d/s이다. (일반적으로 수 밀리초)<br><br><br><br><br>
<br>라우터가 패킷을 내보내는 데 필요한 시간
<br>패킷 길이와 링크 전송률의 함수 → 두 라우터 사이의 거리와는 관계가 없다.
<br><br>
<br>비트가 한 라우터에서 다음 라우터로 전파되는 데 걸리는 시간
<br>두 라우터 사이의 거리에 대한 함수 → 패킷 길이나 링크 전송률과는 관계가 없다.
<br><br>
<br><br><br>
💡 전체 노드 지연 = 처리 지연 + 큐잉 지연 + 전송 지연 + 전파 지연
<br><br><br>각각 지연 요소의 기여도에는 상당한 차이가 존재한다.<br><br>
<br>내부의 두 라우터를 연결하는 링크에서는 2마이크로초 정도 → 무시 가능
<br>정지 위성 링크로 연결된 두 라우터의 경우 수백 밀리초 → 전체 노드 지연의 주요 요소가 된다.
<br><br>
<br>LAN처럼 10 Mbps 이상의 전송률인 경우 → 무시 가능
<br>저속 다이얼업 모뎀 링크에서 보내지는 인터넷 패킷은 수백 밀리초에 이를 수 있다.
<br><br>
<br>이는 보통 전체 노드 지연에서는 무시될 수 있다.
<br>하지만 라우터가 패킷을 전달할 수 있는 최대율(최대 속도)에는 상당한 영향을 준다.
<br><br>
<br>
<br><br><br>노드 지연(한 라우터에서의 지연)에 대하여 알아보자.<br>다른 세 가지 지연과 다르게, 큐잉 지연은 패킷마다 다를 수 있다.<br><br><br>e.g., 10개의 패킷이 동시에 비어 있는 큐에 도착한다면?<br>
<br>전송된 첫 패킷은 큐잉 지연을 겪지 않는다.
<br>마지막으로 전송되는 패킷은 많은 큐잉 지연을 겪게 된다. (다른 9개 패킷이 전송되기를 기다림)
<br>따라서 큐잉 지연의 특성 묘사는 평균 큐잉 지연, 큐잉 지연의 분산, 큐잉 지연이 어느 특정 값을 넘을 확률 같은 통계 측정을 일반적으로 이용한다.<br><br><br><br>
<br>트래픽이 큐에 도착하는 비율
<br>링크의 전송률
<br>도착하는 트래픽의 특성 (트래픽이 주기에 맞춰서 또는 버스트(burst)하게 도착하는가?)
<br><br><br><br><br><br>아래의 상황을 가정해보자.<br>패킷이 큐에 도착하는 평균율 : a 패킷/초
전송률(패킷이 큐에서 밀려나는 비율) : R 비트/초
모든 패킷은 L 비트
큐가 매우 커서 무한대 비트를 저장할 수 있음
복사<br>이때 트래픽 강도(traffic intensity, 비트가 큐에 도착하는 평균율)은 La 비트/초다.<br>
(트래픽 강도는 큐잉 지연의 정도를 측정하는 데에 매우 중요)<br><br><br>✅ La/R &gt; 1이라면 비트가 큐에 도착하는 평균율이 비트가 큐에서 전송되는 비율을 초과한다는 것을 의미한다.<br>따라서 큐는 끝없이 증가, 큐잉 지연은 무한대에 도달한다. → 트래픽 강도가 1보다 크지 않게 시스템을 설계해야 한다.<br><br><br>✅ La/R ≤ 1인 경우에는 도착 트래픽의 특성이 큐잉 지연에 영향을 미친다.<br>
<br>하나의 패킷이 L/R 초마다 주기적으로 도착한다면 모든 패킷은 빈 큐에 도착 → 큐잉 지연은 없을 것이다.
<br>패킷이 몰려서(burst) 도착한다면 상당한 평균 큐잉 지연이 발생할 것이다.
<br><br><br><br><br><br>일반적으로 패킷의 도착에는 고정된 패턴이 없고, 임의의 시간만큼 떨어져서 도착하게 된다. (random)<br>아래 그래프는 트래픽 강도에 대한 평균 큐잉 지연의 질적 의존도를 나타낸다.<br><img src="https://user-images.githubusercontent.com/86337233/210216463-79992219-167f-4340-ab30-31383deac4d3.png" alt="평균 큐잉 지연의 트래픽 강도 의존성" referrerpolicy="no-referrer" style="width: 320px; max-width: 100%;"><br><br>
<br><br>
💡 트래픽 강도가 1에 접근할수록 평균 큐잉 지연이 급속히 증가한다.
<br>
<br>
트래픽 강도가 0에 가까울 경우

<br>패킷 도착이 드물고 간격이 멀어서 다음에 도착하는 패킷이 큐에서 다른 패킷을 발견하는 경우가 없다.
<br>따라서 평균 큐잉 지연은 0에 가까워진다.


<br>
트래픽 강도가 1에 가까울 경우

<br>패킷 도착이 전송용량을 초과하여 큐가 생성될 것이다.
<br>도착률이 전송률보다 작아질 때 큐의 길이가 줄어든다.


<br><br><br><br>앞에서는 큐가 무한대 패킷을 가질 수 있다고 가정했으나, 실제로는 유한 용량을 가지며 스위치 설계와 비용에 크게 의존한다.<br>즉, 트래픽 강도가 1에 접근함에 따라 패킷 지연이 무한대가 되진 않으며, 대신 큐가 꽉 차게 된다.<br><br><br>
💡 큐가 꽉 차서 패킷을 저장할 수 없는 경우에 라우터는 그 패킷을 버린다(drop).
<br>
<br>손실 패킷의 비율은 트래픽 강도가 클수록 증가한다.
<br>모든 데이터가 궁극적으로 목적지까지 전달되었음을 보장하기 위해 손실 패킷은 종단 간에 재전송될 수 있다.
<br><br><br><br><br><br>정리하자면, 노드에서의 성능 측정 요소는 다음의 두 가지이다.<br>
<br>지연 정도
<br>패킷 손실 확률
<br><br>
<br>
<br><br><br>출발지에서 목적지까지의 지연에 대하여 알아보기 위해, 다음의 상황을 생각해보자.<br>출발지 호스트와 목적지 호스트 사이에 N-1개의 라우터가 있다.
네트워크가 혼잡하지 않아 큐잉 지연을 무시할 수 있다.
각 호스트와 출발지 호스트에서의 전송률은 R 비트/초이다.
패킷의 크기는 L 비트이다.
복사<br>
종단 간 지연 = N(처리 지연 + 전송 지연(L/R) + 전파 지연)
<br><br><br>이는 1.3절에서 언급한, 처리와 전파 지연을 고려하지 않은 종단 간 지연 식을 일반화한 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/210137330-0534c802-b6cd-41e4-915d-d8a3dac5d07a.png" alt="종단 간 지연" referrerpolicy="no-referrer" style="width: 250px; max-width: 100%;"><br><br>
<br>
<br>
<br><br><br>컴퓨터 네트워크에서의 주요한 성능 수단은 다음의 세 가지이다.<br>
<br>지연 정도
<br>패킷 손실 확률
<br>종단 간 처리율(throughput)
<br><br><br>컴퓨터 네트워크를 통해 호스트 A에서 호스트 B로 커다란 파일을 전송하는 상황을 생각해보자.<br>해당 파일은 F 비트로 구성되며, 호스트 B가 파일의 모든 F 비트를 수신하는 데 T초가 걸린다고 한다면,<br>
<br>어느 한 순간에서의 순간적인 처리율(instantaneous throughput) = 호스트 B가 파일을 수신하는 비율(비트/초)
<br>평균 처리율(average throughtput) = F/T 비트/초
<br><br><br>인터넷 전화 같은 애플리케이션의 경우, 낮은 지연과 순간적인 처리율이 지속적으로 어떤 임계값(threshold)을 넘는 것이 바람직하다.<br>파일 전송을 포함하는 다른 애플리케이션의 경우, 지연은 심각하지 않으나 가능한 한 높은 처리율을 가지는 것이 바람직하다.<br><br><br><br><br><br>서버로부터 클라이언트로의 파일 전송에 대한 처리율을 생각해보기 위해 두 가지 예시를 보자.<br><img src="https://user-images.githubusercontent.com/86337233/210216470-eff94fd0-1b04-4efd-aa60-85f7bad15507.png" alt="파일 전송 처리율" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>그림 a는 2개의 통신 링크와 라우터로 연결된 하나의 서버와 하나의 클라이언트를 나타낸다.
(전체 네트워크로 보내지는 비트는 서버에서 클라이언트로만 보내지는 비트라고 가정)

Rs : 서버와 라우터 간의 링크 속도
Rc : 라우터와 클라이언트 간의 링크 속도
복사<br>이때 서버-클라이언트 처리율은 얼마인가? (비트는 유체(fluid), 통신 링크는 파이프(pipe)로 생각해보자)<br><br><br>서버는 Rs bps보다 빠른 속도로 링크상으로 비트를 내보낼 수 없고, 라우터는 Rc bps보다 빠른 속도로 비트를 전달할 수 없다.<br>
<br>Rs &lt; Rc인 경우 : Rs bps
<br>Rc &lt; Rs인 경우 : Rc bps

<br>라우터는 자신이 수신하는 비트만큼 빠르게 그 비트들을 전달할 수 없다.
<br>클라이언트로의 전송을 위해 기다리는 라우터의 비트들은 계속해서 증가할 것이다.


<br>
처리율 = min{Rc, Rs} = 병목 링크(bottleneck link)의 전송률
<br><br>
<br><br>그림 b는 서버와 클라이언트 간에 N개의 링크를 가진 네트워크를 보여주고 있다.
N개 링크의 전송률 : R1, R2, ... , RN
복사<br>이때의 서버-클라이언트 처리율은 그림 a에서와 마찬가지이다.<br>
처리율 = min{R1, R2, … , RN} = 서버와 클라이언트 간 경로상에서의 병목 링크(bottleneck link)의 전송률
<br><br><br><br><br><br>아래는 오늘날의 인터넷에서 살펴볼 수 있는 다른 두 가지 예시이다.<br><img src="https://user-images.githubusercontent.com/86337233/210216466-21232719-49ba-41e4-a6f9-af5491b6ffd2.png" alt="종단 간 처리율" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br><br>
<br><br>그림 a는 컴퓨터 네트워크로 연결된 2개의 종단 시스템을 나타낸다.
(전체 네트워크로 보내지는 비트는 서버에서 클라이언트로만 보내지는 비트라고 가정)

Rs : 서버가 네트워크에 연결되어 있는 접속 링크 속도
Rc : 클라이언트가 네트워크에 연결되어 있는 접속 링크 속도

통신 네트워크의 코어에 있는 모든 링크가 Rs와 Rc보다 매우 높은 전송률을 가지고 있다.
(실제로도 그렇다. → 오늘날 인터넷의 코어는 작은 혼잡을 경험)
복사<br>이때도 마찬가지로, 출발지에서 목적지로 흐를 수 있는 비트 속도는 Rs와 Rc의 최솟값과 같다.<br>
처리율 = min{Rc, Rs}
<br><br><br>
💡 오늘날의 인터넷에서의 처리율에 대한 제한 요소는 전형적으로 접속 네트워크다.
<br><br>
<br><br>그림 b는 컴퓨터 네트워크의 코어에 연결된 10개의 서버와 10개의 클라이언트를 나타내며,
10개의 동시적인 다운로드가 일어나고 있다. (10개의 클라이언트-서버 쌍)
(현 시각, 이러한 10개의 다운로드가 네트워크에서의 유일한 트래픽이라고 가정)

10개의 다운로드가 통과하는 코어에 하나의 링크 R가 존재한다.

R : 링크 R의 전송률
Rs : 모든 서버 접속 링크가 가지고 있는 속도
Rc : 모든 클라이언트 접속 링크가 가지고 있는 속도

코어에서의 모든 링크의 전송률(속도 R인 하나의 공통 링크는 예외)은 Rs, Rc, R보다 크다고 가정한다.
복사<br>이때 다운로드의 처리율은 얼마인가?<br>공통 링크 R의 속도가 크다면 각 다운로드에 대한 처리율은 min{Rs, Rc}이 될 것이다.<br><br><br>하지만 공통 링크 R의 속도가 Rs, Rc와 같은 수준이라면 어떻게 되는가?<br>e.g., Rs = 2 Mbps, Rc = 1 Mbps, R = 5 Mbps<br>
→ 공유 링크는 각 다운로드에 500 kbps의 처리율을 제공하기에, 각 다운로드에 대한 종단 간 처리율은 500 kbps로 줄어든다.<br>즉, 코어에서의 공유 링크가 각 다운로드에 대한 병목이 된다.<br><br><br><br><br><br>위의 예시들을 한 줄로 정리하자면 다음과 같다.<br>
💡 처리율은 데이터가 흐르는 링크의 전송률에 의존할 뿐만 아니라 간섭 트래픽에도 의존한다.
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.4-패킷-교환-네트워크에서의-지연,-손실과-처리율\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.4 패킷 교환 네트워크에서의 지연, 손실과 처리율/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:00 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/210216460-d4e1eacc-cde9-4185-aca8-661e78a20427.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/210216460-d4e1eacc-cde9-4185-aca8-661e78a20427.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.5 프로토콜 계층과 서비스 모델]]></title><description><![CDATA[ 
 <br><br><br><br><br>계층구조는 크고 복잡한 시스템의 잘 정의된 특정 부분을 논의할 수 있게 해주며, 이러한 단순화는 매우 중요하다.<br><br><br>시스템이 계층구조를 가질 때, 그 계층이 제공하는 서비스의 구현을 변경하는 것도 매우 쉽다.<br>어떤 한 계층의 구현이 변하더라도 시스템의 나머지 부분은 변하지 않는다는 것이다.<br><br><br>
💡 계층구조의 각 계층은 (1) 그 계층에서 어떤 동작을 취하고 (2) 그 계층 바로 아래 계층 서비스를 사용함으로써 서비스를 제공한다.
<br><br>
<br><br><br>네트워크 프로토콜의 설계 구조를 제공하기 위해,<br>
네트워크 설계자는 프로토콜(프로토콜을 구현하는 네트워크 하드웨어와 소프트웨어)을 계층(layer)으로 조직한다.<br>즉, 각각의 프로토콜은 한 계층에 속하며, 프로토콜 계층은 소프트웨어, 하드웨어 또는 둘의 통합으로 구현할 수 있다.<br><br><br>
<br>한 계층은 상위 계층에 제공하는 서비스(service)에 관심을 갖고, 이것을 계층의 서비스 모델(service model)이라고 한다.
<br>각 계층은 그 계층 내부에서 어떤 동작을 수행하거나, 직접 하위 계층의 서비스를 사용한다.
<br><br><br>다양한 계층의 프로토콜을 합하여 프로토콜 스택(protocol stack)이라고 한다.<br><br>
<br><br><br>인터넷 프로토콜 스택은 5개 계층으로 구성된다.<br>
물리, 링크, 네트워크, 트랜스포트, 애플리케이션 계층
<br>아래부터 1계층 ~ 5계층<br><img src="https://user-images.githubusercontent.com/86337233/210246859-07f4ba1e-d653-425b-8b3f-94fa6ab9ed04.png" alt="인터넷 프로토콜 스택" referrerpolicy="no-referrer" style="width: 140px; max-width: 100%;"><br><br>
<br><br><br>
💡 네트워크 애플리케이션과 애플리케이션 계층 프로토콜이 있는 곳이다.
<br>
<br>인터넷의 애플리케이션 계층이 포함하는 대표적 프로토콜은 다음과 같다.

<br>HTTP : 웹 문서 요청과 전송 제공
<br>SMTP : 전자메일 전송 제공
<br>FTP : 두 종단 시스템 간의 파일 전송 제공


<br>도메인 네임 서버(domain name server, DNS)는 이 애플리케이션 계층에 존재한다.
<br>애플리케이션 계층 프로토콜은 여러 종단 시스템에 분산되어 있어서<br>
한 종단 시스템에 있는 애플리케이션이 다른 종단 시스템에 있는 애플리케이션과 정보 패킷(메시지, message)을 교환하는 데 이 프로토콜을 사용한다.
<br><br><br><br>
💡 클라이언트와 서버 간에 애플리케이션 계층 메시지를 전송하는 서비스를 제공한다.
<br>
<br>트랜스포트 계층 패킷 = 세그먼트(segment)
<br>트랜스포트 프로토콜의 두 가지 종류로는 다음과 같으며, 이들은 애플리케이션 계층 메시지를 전달한다.

<br>TCP

<br>애플리케이션에게 연결 지향형 서비스를 제공한다.
<br>목적지로의 애플리케이션 계층 메시지 전달 보장과 흐름 제어(송신자/수신자의 속도 일치)를 포함한다.
<br>긴 메시지를 짧은 메시지로 나누고, 혼잡 제어 기능을 제공한다. (네트워크가 혼잡할 때 출발지의 전송률을 줄임)


<br>UDP

<br>애플리케이션에게 비연결형 서비스를 제공한다.
<br>신뢰성, 흐름 제어, 혼잡 제어를 제공하지 않는다.




<br><br><br><br>
💡 한 호스트에서 다른 호스트로 데이터그램(datagram, IP의 전송 단위)을 라우팅하는 책임을 진다.
<br>즉, 출발지와 목적지 간 일련의 패킷 스위치(인터넷에서는 라우터)를 통해 데이터그램을 라우트한다.<br>
<br>출발지 호스트에서 인터넷 트랜스포트 계층 프로토콜(TCP 또는 UDP)은 트랜스포트 계층 세그먼트와 목적지 주소를 네트워크 계층으로 전달한다.
<br>네트워크 계층은 목적지 호스트의 트랜스포트 계층으로 세그먼트를 운반하는 서비스를 제공한다.
<br><br><br>
네트워크 계층은 IP 데이터그램의 필드를 정의하며<br>
종단 시스템과 라우터가 이 필드에 어떻게 동작하는지를 정의하는 프로토콜, IP 프로토콜을 가지고 있다.
<br>
<br>오직 하나의 IP 프로토콜이 존재한다.
<br>네트워크 계층을 가진 모든 인터넷 요소는 IP 프로토콜을 수행해야만 한다.
<br><br><br>
인터넷 네트워크 계층은 라우팅 프로토콜을 포함한다.
<br>
<br>라우팅 프로토콜은 출발지와 목적지 사이에서 데이터그램이 이동하는 경로를 결정한다.
<br>인터넷은 네트워크의 네트워크이며, 한 네트워크 내부에서 네트워크 운용자는 원하는 어떠한 라우팅 프로토콜이라도 수행할 수 있다.
<br><br><br><br>
💡 전체 프레임을 한 네트워크 요소에서 이웃 네트워크 요소로 이동시킨다.
<br>링크 계층 패킷 = 프레임(frame)<br><br><br>
경로상의 한 노드(호스트 혹은 패킷 스위치)에서 다른 노드로 패킷을 이동하기 위해 네트워크 계층은 링크 계층 서비스에 의존해야 한다.
<br>
<br>각 노드에서 네트워크 계층은 데이터그램을 아래 링크 계층으로 보내고<br>
링크 계층은 그 데이터그램을 경로상의 다음 노드에 전달한다.
<br>다음 노드에서 링크 계층은 그 데이터그램을 상위 네트워크 계층으로 보낸다.
<br><br><br>링크 계층에서 제공하는 서비스는 그 링크에서 채용된 특정 링크 계층 프로토콜에 의해 결정된다.<br>e.g., 어떤 프로토콜은 송신 노드로부터 하나의 링크를 통해 반대편에 있는 수신 노드까지 신뢰적인 전송을 제공한다. (이는 TCP의 신뢰적인 전달 서비스와는 다름)<br>데이터그램은 출발지에서 목적지로 가는데 여러 링크를 거치므로, 데이터그램은 경로상의 각기 다른 링크에서 다른 링크 계층 프로토콜에 의해 처리될 수 있다.<br><br><br><br>
💡 프레임 내부의 각 비트를 한 노드에서 다음 노드로 이동시킨다.
<br>이 계층의 프로토콜들은 링크에 의존하고, 더 나아가 링크의 실제 전송 매체(꼬임쌍선, 단일 모드 광케이블 등)에 의존한다.<br><br>
<br>
<br><br><br>그림은 아래 과정의 물리적 경로를 보여준다.<br>
<br>송신 종단 시스템의 프로토콜 스택 아래로 데이터를 보내며
<br>중간의 링크 계층 스위치와 라우터의 프로토콜 스택을 위아래로 거치고
<br>수신 종단 시스템의 프로토콜 스택 상위로 보낸다.
<br><img src="https://user-images.githubusercontent.com/86337233/210246864-ce756378-bd52-4618-9a24-fefe4cc85465.png" alt="캡슐화" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br><br><br>
<br>이들은 둘 다 패킷 교환기다.
<br>종단 시스템과 비슷하게, 라우터와 링크 계층 스위치는 네트워킹 하드웨어와 소프트웨어를 계층으로 구성한다.
<br>그러나 모든 계층을 구현하지는 않고, 일반적으로 하위 계층을 구현한다.<br>
(그림에서는 링크 계층 스위치가 1, 2 계층을 구현하고 라우터는 1~3 계층을 구현)
<br>즉, 인터넷 라우터들은 IP 프로토콜(3계층 프로토콜)을 구현할 수 있지만, 링크 계층 스위치는 불가하다.
<br><br><br><br>이는 다섯 계층 모두를 구현한다.<br>
💡 인터넷 구조가 네트워크의 ‘가장자리’에서 그 복잡성을 유지한다.
<br><br>
<br><br><br>
💡 각 계층에서 패킷은 헤더 필드와 페이로드 필드(payload field)라는 두 가지 형태의 필드를 갖는다.
<br>페이로드(payload)는 일반적으로 그 계층 상위로부터의 패킷을 말한다.<br><br><br><br>
<br>송신 호스트에서 애플리케이션 계층 메시지(application-layer message, 위 그림에서의 M)는 트랜스포트 계층으로 보내진다.
<br>가장 간단한 경우, 트랜스포트 계층은 메시지에 수신 측 트랜스포트 계층에서 사용될 추가 정보인 트랜스포트 계층 헤더 정보(Ht)를 더한다.
<br><br><br>
트랜스포트 계층 세그먼트(transport-layer segment) = 애플리케이션 계층 메시지 + 트랜스포트 계층 헤더 정보
<br>
<br>트랜스포트 계층 세그먼트는 애플리케이션 계층 메시지를 캡슐화한다.
<br>트랜스포트 계층 헤더 정보가 포함하는 내용은 다음과 같다.

<br>수신 측의 트랜스포트 계층이 그 메시지를 적절한 애플리케이션으로 보내도록 하는 정보들
<br>메시지의 비트들이 변경되었는지 아닌지를 수신자가 결정하게 하는 오류 검출 비트


<br><br><br>
<br>트랜스포트 계층은 세그먼트를 네트워크 계층으로 보낸다.
<br>네트워크 계층은 출발지와 목적지 종단 시스템 주소와 동일한 헤더 정보(Hn)를 추가하여 네트워크 계층 데이터그램(network-layer datagram)을 만든다.
<br><br><br>
<br>데이터그램은 링크 계층으로 전달된다.
<br>링크 계층도 자신의 헤더 정보를 추가하여 링크 계층 프레임(link-layer frame)을 만든다.
<br><br><br><br><br><br>캡슐화 과정은 위에서 말한 것보다 더 복잡할 수 있다.<br>큰 메시지는 여러 개의 트랜스포트 계층 세그먼트로 분할될 수 있으며, 그들 각각은 여러 개의 네트워크 계층 데이터그램으로 분할될 수 있다.<br>그러고 나서 수신 측에서 각 세그먼트는 분할된 데이터그램들로 재구성되어야 한다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.5-프로토콜-계층과-서비스-모델\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.5 프로토콜 계층과 서비스 모델/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 06:51:23 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/210246859-07f4ba1e-d653-425b-8b3f-94fa6ab9ed04.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/210246859-07f4ba1e-d653-425b-8b3f-94fa6ab9ed04.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.6 공격받는 네트워크]]></title><description><![CDATA[ 
 <br><br>인터넷의 모든 유용성과 역동성 뒤에,<br>
‘나쁜 친구들’이 인터넷에 연결된 컴퓨터에 해를 끼리고, 사생활을 침해하고, 우리가 의존하는 인터넷 서비스를 동작하지 못하게 함으로써<br>
일상생활을 망가트리려고 하는 어두운 면이 있다.<br>네트워크 보안 분야는 나쁜 친구들이 어떻게 컴퓨터 네트워크를 공격할 수 있는가와<br>
그러한 공격으로부터 네트워크를 방어할 수 있는가, 혹은 아예 그러한 공격에 영향을 받지 않는 새로운 구조의 설계 등을 다루는 분야다.<br><br><br><br><br>우리는 인터넷에서 데이터를 수신/송신하기를 원하기 때문에 장치를 인터넷에 연결한다.<br>불행하게도 우리에게 전달되는 데이터들 중 해로운 것들도 포함되는데, 이들을 멀웨어(malware)라고 한다.<br>
멀웨어는 우리들의 장치에 들어가서 나쁜 영향을 미친다.<br>e.g., 파일 삭제, 주민번호, 비밀번호, 키스트로크(keystroke, 키보드를 누르는 것) 등의 사적인 정보를 모으는 스파이웨어를 설치<br>
→ 이러한 정보를 모아 나쁜 친구들에게 인터넷을 통해 다시 보낸다.<br><br><br>면역되지 않은 호스트는 수천의 비슷한 면역되지 않은 장치들로 구성된 네트워크, 즉 봇넷(botnet)에 등록될 수 있다.<br>
나쁜 친구들은 목표로 하는 호스트에 대해 스팸 전자메일 분해 혹은 분산 DoS(Denial of Service) 공격을 위해 이 봇넷을 제어하고 이용한다.<br><br><br>오늘날 널리 퍼져 있는 많은 멀웨어는 자기복제(self-replicating)를 한다.<br>
자기복제 멀웨어는 아래의 방법을 통해 기하급수적으로 퍼질 수 있다.<br>
<br>한 호스트에 영향을 미치면, 그 호스트에서 인터넷을 통해 다른 호스트로의 엔트리를 찾는다.
<br>새롭게 영향을 받은 호스트로부터 또 다른 많은 호스트로의 엔트리를 찾는다.
<br><br><br><br><br><br>
네트워크, 호스트 혹은 다른 인프라스트럭처의요소들을 정상적인 사용자가 사용할 수 없게 하는 것
<br>웹 서버, 전자메일 서버, DNS 서버, 기관 네트워크는 DoS 공격을 받을 가능성이 있다.<br><br><br><br><br>만약 올바른 순서의 패킷을 공격받기 쉬운 애플리케이션 혹은 운영체제에 보내면(교묘한 메시지를 보내는 것을 포함)<br>
그 서비스는 중단되거나, 호스트가 동작을 멈출 수도 있다.<br><br><br><br>목표 호스트의 접속 링크가 동작하지 못하도록 많은 패킷을 보내서 정당한 패킷들이 그 서버에 도달하지 못하게 한다.<br><br><br>1.4.2절의 지연과 손실 분석 논의를 기억해보자.<br>만약 서버가 R bps의 접속 속도를 갖고 있다면, 공격자는 피해를 주기 위해 대략적으로 R bps의 속도로 트래픽을 전송하면 된다.<br><br><br>만약 R가 매우 크다면 단일 공격 소스는 서버에 나쁜 영향을 줄 수 있는 충분한 트래픽을 발생시킬 수 없다.<br>더 나아가, 모든 트래픽이 하나의 소스에서 방사된다면 업스트림 라우터는 그 공격을 발견할 수 있고<br>
트래픽이 서버에 가까이 가기 전에 그 소스로부터 모든 트래픽을 차단(block)할 수 있다.<br><br><br>아래 그림처럼 분산 DoS(DDoS) 공격에서 공격자는 다중의 소스를 제어하고 각 소스는 목표에 트래픽을 보낸다.<br><img src="https://user-images.githubusercontent.com/86337233/210257676-334e4e5b-c06b-4b0b-9043-0fe4c2fab7d4.png" alt="운산 DoS 공격" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;"><br>이런 방법으로 모든 제어 소스에 걸친 통합 트래픽 속도가 서비스를 무능력하게 하기 위해서는 전송률이 약 R이어야 한다.<br>수천개의 호스트로 구성된 봇넷을 이용하는 DDoS 공격은 오늘날 매우 흔하다.<br><br><br><br>목표 호스트에 반열림(half-open) 혹은 전열림(fully open)된 TCP 연결을 설정한다.<br>호스트는 가짜 연결을 처리하느라 바빠서 정상적인 연결을 받아들이는 것을 중단하게 된다.<br><br><br><br><br><br>
컴퓨터 네트워크 설계자는 DoS 공격을 방어하기 위해 무엇을 할 수 있는가?
<br>→ 세 가지 유형의 DoS 공격에는 각기 다른 방어가 필요하다.<br><br><br><br><br>유비쿼터스(ubiquitous) 인터넷 접속은 매우 편리하고 이동 사용자를 위한 애플리케이션이 가능하지만, 인터넷 접속은 주요한 보안 취약성을 창출했다.<br>무선 전송장치의 근처에 수동적인 수신자 즉, 패킷 스니퍼(packet sniffer)를 위치시킴으로써 그 수신자는 전송되고 있는 모든 패킷의 사본을 얻을 수 있다.<br>스니퍼는 무선 뿐만 아니라, 유선 환경에서도 배치될 수 있다.<br>
(이더넷 LAN, 케이블 접속 기술, 인터넷에 연결되는 기관의 접속 라우터 혹은 접속 링크 등)<br>나쁜 친구들은 이렇게 가로챈 패킷을 오프라인으로 분석하여 비밀번호, 주민등록번호, 영업 비밀 등 모든 종류의 민감한 정보를 얻을 수 있다.<br><br><br>패킷 스니퍼는 수동적이기 때문에, 즉 스니퍼는 채널에 패킷을 삽입하지 않기 때문에 이를 탐지하기가 어렵다.<br>그래서 무선 채널로 패킷을 보낼 때 어떤 나쁜 친구가 우리 패킷의 사본을 기록하고 있을 수 있다는 가능성을 받아들여야 한다.<br><br><br>패킷 스니핑을 방지하기 위한 가장 좋은 방어는 암호화를 포함하는 것이다. (8장에서 다룸)<br><br><br><br><br>임의의 출발지 주소, 패킷 내용, 목적지 주소를 갖는 패킷을 생성하고 이 패킷을 인터넷으로 보내는 것은 매우 쉽다.<br>가짜 출발지 주소를 가진 패킷을 인터넷으로 보내는 능력을 IP 스푸핑(spoofing)이라고 하며,<br>
한 사용자가 다른 사용자인 것처럼 행동하는 여러 가지 방법 중 하나다.<br><br><br>이 문제를 해결하기 위해서는 종단 인증(end-point authentication),<br>
즉 메시지가 실제로 와야 할 곳으로부터 온 것인지 확신할 수 있는 방법이 필요하다.<br>네트워크 애플리케이션과 프로토콜의 경우 어떻게 이것을 할 수 있을까? (8장에서 다룸)<br><br><br><br><br><br>인터넷은 처음에 어떻게 보안 문제에 직면하게 되었을까?<br><br><br>
인터넷은 원래 ‘투명한 네트워크에 연결된 상호 신뢰할 수 있는 사용자 그룹’ 모델,<br>
즉 보안이 필요 없는 모델에 기반을 둔 방식으로 설계되었다. [Blumenthal 2001]
<br>따라서 원래 인터넷 구조의 많은 특성은 이러한 상호 신뢰를 반영하고 있다.<br>
e.g., 한 사용자가 패킷을 다른 사용자에게 보내는 능력은 default, 사용자 식별은 default로 인증해야 하는 것보다는 선언된 액면 그대로 믿는 것이다.<br><br><br>그러나 오늘날 인터넷은 ‘상호 신뢰하는 사용자’를 분명히 포함하지 않는다.<br>그럼에도 불구하고 오늘날의 사용자들은 서로를 꼭 신뢰하지는 않을 때, 익명으로 통신하기를 원할 때,<br>
제3자를 통해 간접적으로 통신할 때(이동 지원 에이전트, mobility-assisting agent) 등 이러한 상황에서도 여전히 통신이 필요하다.<br><br><br>아직 우리 앞에는 많은 보안 관련 해결 과제가 존재한다.<br>우리는 스니핑, 종단 위장(end-point masquerading), 중간자 공격, DDoS 공격, 멀웨어 등에 방어하는 방법을 찾아야 한다.<br>
💡 상호 신뢰하는 사용자 간의 통신은 일반적인 것이 아니라 예외적인 것임을 명심해야 한다.
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.6-공격받는-네트워크\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.6 공격받는 네트워크/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 06:51:56 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/210257676-334e4e5b-c06b-4b0b-9043-0fe4c2fab7d4.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/210257676-334e4e5b-c06b-4b0b-9043-0fe4c2fab7d4.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.7 컴퓨터 네트워킹과 인터넷의 역사]]></title><description><![CDATA[ 
 <br><br><br>1960년대 초의 세계 주요 통신 네트워크는 전화망이었다.<br>전화망이 송신자에게서 수신자로 정보를 전송하는 데 회선 교환을 사용하였다. (음성이 송수신자 간에 일정한 속도로 전송된다면 이는 적절한 선택)<br><br><br>각 사용자가 만드는 트래픽은 집중적(bursty)이었다.<br>즉, 원격 컴퓨터에 명령을 내리는 활동과 응답을 기다리고 응답을 검토하는 비활동 사이의 기간이 일정하지 않았다.<br><br><br>세계적으로 3개의 연구 그룹이 회선 교환을 대신할 수 있는 효율적이고 견실한 방법으로서 패킷 교환의 개념을 창안하였다.<br>
<br>1967년, 로렌스 로버츠(Lawrence Roberts)는 ARPAnet에 대한 대략의 계획을 발간하였다.<br>
→ 첫 번째 패킷 교환 컴퓨터 네트워크이자 오늘날 공중 인터넷의 직계 원조
<br>1969년, 첫 번째 패킷 스위치가 UCLA에 설치되었다.
<br>1972년, ARPAnet은 약 15개의 노드로 커졌다.<br>
ARPAnet 종단 시스템 간에 NCP(Network-Control Protocol)라고 하는 첫 번째 호스트 간(host-to-host) 프로토콜이 완성되었다. [RFC 001]
<br><br><br>종간 간에서 프로토콜을 사용할 수 있게 되자, 애플리케이션을 개발할 수 있게 되었다.<br>
<br>1972년, 레이 톰린슨(Ray Tomlinson)이 최초의 전자메일 프로그램을 만들었다.
<br><br><br><br><br>초기 ARPAnet은 단일 폐쇄 네트워크였다.<br>즉, ARPAnet 호스트와 통신하기 위해서는 다른 ARPAnet IMP에 실제로 접속해야 했다.<br><br><br>1970년대 중반 초, ARPAnet과 별개의 패킷 교환 네트워크들이 생겨났다.<br>
<br>DARPA의 패킷 위성 [RFC 829]
<br>패킷 라디오 네트워크 [Kahn 1978]
<br>ALOHAnet : 하와이에 위치하는 대학들을 함께 연결하는 마이크로파 네트워크 [Abramson 1970]
<br>Cyclades : 루이 푸장(Louis Pouzin)이 이끈 프랑스 패킷 교환 네트워크 [Think 2012]
<br>시분할 네트워크 : 1960년대 후반에서 1970년대 초반의 네트워크 [Schwartz 1977]<br>
e.g., Tymnet, GE Information Services 네트워크
<br><br><br>네트워크 수가 증가함에 따라<br>
네트워크를 연결하는 포괄 구조(상호연결 네트워크, 네트워크의 네트워크)의 개발 시기가 점차 다가왔다.<br><br><br>이러한 구조 원리는 TCP 프로토콜로 구체화되었다.<br>이는 아래의 두 가지를 결합한 것이며, 오늘날의 TCP와는 매우 다르다.<br>
<br>종단 시스템의 재전송을 통한 데이터의 신뢰적인 전송 (오늘날 TCP의 일부분으로 남겨짐)
<br>전달 기능 (오늘날 IP가 수행함)
<br><br><br>패킷 음성 같은 애플리케이션을 위한 비신뢰적이고 흐름 제어가 없는 종단 간의 전송 서비스의 중요성에 대한 인식과 결합하여<br>
TCP에 대한 초기 실험은 TCP에서 IP를 분리하도록 했고, UDP 프로토콜을 개발하였다.<br>
TCP, UDP, IP 같은 주요 인터넷 프로토콜은 1970년대 후반에 그 개념이 자리 잡았다.
<br><br><br>ALOHA 프로토콜[Abramson 1970]은 지리상 분산된 사용자를 하나의 방송통신매체(라디오 주파수)를 공유하게 하는<br>
최초의 다중 접속(multiple access) 프로토콜이다.<br>다중 접속 프로토콜에 대한 에이브럼슨의 연구는<br>
유선 기반 공유 브로드캐스트 네트워크를 위한 이더넷 프로토콜[Metcalfe 1976] 개발에서 멧칼프(Metcalfe)와 보그스(Boggs)에 의해 발전되었다.<br>즉, PC 혁명과 네트워크 폭발이 있기 훨씬 전인 25년 전, 이들은 오늘날의 PC LAN의 기초를 닦고 있었다.<br><br><br><br><br>
<br>1970년대 말까지 약 200개의 호스트가 ARPAnet에 연결되었다.
<br>1980년대 말까지 공중 인터넷(네트워크 연합)에 연결된 호스트 수는 십만 개에 이르렀다.
<br><br><br>이처럼 1980년대는 거대한 성장 시대였는데, 이러한 성장의 주요인은 대학들을 연결하는 컴퓨터 네트워크를 만드는 여러 노력이었다.<br>
<br>CSNET(Computer Science Network) : ARPAnet에 접속하지 않고 대학 연구자들을 연결하기 위해 만들어졌다.
<br>1986년, NSFNET(National Science Foundation Network)이 NSF이 지원하는 슈퍼컴퓨터센터에 접속 가능하도록 만들어졌다.
<br>56 kbps의 초기 백본으로 시작하여 NSFNET의 백본은 1980년대 말에 1.5 Mbps로 동작하게 되었으며, 지역 네트워크를 연결하는 주요 백본이 되었다.
<br><br><br>ARPAnet 커뮤니티에서 오늘날 인터넷 구조의 많은 구성요소가 등장했다.<br>
<br>1983년 1월 1일, APRAnet의 새로운 표준 호스트 프로토콜인 TCP/IP가 공식 설치되었다. (NCP 프로토콜을 대체)
<br>NCP에서 TCP/IP로의 전환[RFC 801]은 플래그 데이(flag day) 형태의 사건이었다. 즉, 모든 호스트는 같은 날 동시에 TCP로 전환해야 했다!
<br><br><br>1980년대 후반에 호스트 기반의 혼잡 제어를 구축하기 위해 TCP에 중요한 확장이 이루어졌다. [Jacobson 1988]<br>
<br>도메인 네임 시스템(domain name system, DNS)의 개발 [RFC 1034]
<br>이는 도메인(사람이 읽을 수 있는 인터넷 이름, e.g., jw.edu, euna.com)과 32비트 IP 주소 간의 매핑에 사용된다.
<br><br><br>1980년대 초 프랑스에서는 데이터 네트워킹을 모든 가정으로 보급하려는 미니텔(Minitel) 프로젝트를 시작했다.<br>
<br>공중 패킷 교환 네트워크 (가상 회선 방식을 사용하는 X.25 프로토콜 스택에 기반을 둠)
<br>미니텔 서버와 내장형 저속 모뎀을 포함하는 값싼 터미널로 구성되었다.
<br>1984년, 프랑스 정부가 원하는 모든 가정에 무상으로 미니텔 단말기를 제공하고 큰 성공을 거두었다.
<br>미니텔 사이트는 전화번호 사이트 같은 무료 사이트와 사용자가 사용량에 따라 요금을 받는 사설 사이트를 포함했다.
<br><br><br><br><br>1990년대는 인터넷의 지속 발전화 상업화를 상징하는 두 사건으로 대변된다.<br>
<br>인터넷이 원조인 ARPAnet이 더 이상 존재하지 않게 되었다.<br>
(1991년에 NSFNET 상업화 제한을 풀었음)
<br>월드와이드웹(World Wide Web, WWW)이 출현하였다.
<br><br><br>웹은 검색, 인터넷 상거래, 소셜 네트워크 등을 포함하는 수백 가지의 새 애플리케이션을 만들고 보급하는 플랫폼으로 등장했다.<br>
<br>1989~1991년, 팀 버너스 리(Tim Berners-Lee)가 CERN에서 처음으로 만들었다. [Berners-Lee 1989]
<br>웹의 네 가지 주요소(HTML, HTTP, 웹 서버, 브라우저)의 초기 버전을 개발하였다.
<br>이는 1940년대의 바내바르 부시(Vannevar Bush)와 1960년대 이후의 테드 넬슨(Ted Nelson)이 개발한<br>
하이퍼텍스트에 관한 초기 연구의 아이디어를 바탕으로 하였다.
<br>1993년 말에 약 200개의 웹 서버가 동작 중이었다.
<br><br><br>이 시기, 여러 연구자가 GUI 인터페이스형 웹 브라우저를 개발하고 있었으며,<br>
크고 작은 회사가 웹 서버를 운영했고 웹을 통한 상거래를 시작했다.<br><br><br>1990년대 후반은 인터넷의 큰 성장과 혁신의 시대이다.<br>세기가 끝나는 시점에서 인터넷은 다음 4개의 킬러 애플리케이션을 포함해서 수백 개의 인기 있는 애플리케이션을 지원하게 된다.<br>
<br>첨부물과 웹 접속 전자메일을 포함하는 전자메일
<br>웹 브라우징과 인터넷 상거래를 포함하는 웹
<br>대화상대 목록을 가진 인스턴트 메시징
<br>냅스터(Napster)가 개척한 P2P를 통한 MP3 파일 공유
<br><br><br><br><br>21세기 첫 20년 동안에 인터넷에 연결된 스마트폰과 함께 인터넷보다 사회를 더 변화시킨 기술은 없었다.<br>그리고 컴퓨터 네트워킹에서의 혁신은 빠른 속도로 계속되어 있다.<br><br><br>그러나 다음의 개발들은 특별한 관심을 끌고 있다.<br><br><br>
<br>가정에 광대역 인터넷 접속의 공격적인 구축을 목격하고 있다.<br>
(케이블 모뎀과 DSL뿐만 아니라 그리고 이제는 5G 무선 서비스 포함)
<br><br><br>
<br>고속 무선 인터넷 접속의 빠른 보급

<br>이를 통해 네트워크에 지속적으로 접속할 수 있을 뿐만 아니라, 엘프(Yelp), 틴더(Tinder), 와즈(Waz) 같은<br>
새로운 위치 기반 애플리케이션이 가능해졌다.
<br>인터넷에 연결되는 무선 장치 수는 2011년에 유선 장치의 수를 초과하였다.


<br><br><br>
<br>페이스북, 인스타그램, 트위터 등 온라인 소셜 네트워크는 인터넷상에 거대한 사람들의 네트워크를 생성했다.

<br>API를 통해 온라인 소셜 네트워크는 모바일 결제를 포함하는 새로운 네트워크 애플리케이션과 분산 게임용 플랫폼을 생성한다.


<br><br><br>
<br>1.3.3절에서 논의한 바와 같이 구글와 마이크로스프트 같은 온라인 서비스 제공자는 자신의 커다란 사설 네트워크를 구축하였다.

<br>이는 전 세계적으로 분산된 자신들의 데이터 센터를 연결할 뿐만 아니라<br>
하위 계층 ISP와 직접 연결(peering)함으로써 가능한 한 많은 인터넷을 우회하는 데 사용된다.
<br>그 결과 구글의 데이터 센터가 마치 사용자의 컴퓨터 내에서 동작하는 것처럼, 구글은 거의 즉각적으로 검색 결과와 전자메일 접속을 제공한다.


<br><br><br>
<br>클라우드 회사는 애플리케이션에 확장 가능한 컴퓨팅과 저장 환경을 제공할 뿐만 아니라, 고성능 사설 네트워크 접속도 제공한다.

<br>많은 인터넷 상거래 회사는 ‘클라우드’에서 자신의 애플리케이션을 수행하고 있다. (아마존의 EC2, 마이크로소프트의 Azure, 알리바바 클라우드)
<br>많은 회사와 대학도 그들의 인터넷 애플리케이션(e.g., 전자메일과 웹 호스팅)을 클라우드로 이동했다.


]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_1\1.7-컴퓨터-네트워킹과-인터넷의-역사\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_1/1.7 컴퓨터 네트워킹과 인터넷의 역사/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:02 GMT</pubDate></item><item><title><![CDATA[2.1 네트워크 애플리케이션의 원리]]></title><description><![CDATA[ 
 <br><br>네트워크 애플리케이션 개발의 중심은 다른 위치의 종단 시스템에서 동작하고 네트워크를 통해 서로 통신하는 프로그램을 작성하는 것이다.<br>예를 들어, 웹 애플리케이션에는 서로 통신하는 서버(웹 서버 프로그램)와 클라이언트(사용자 호스트에서 실행되는 브라우저 프로그램)로 구별되는<br>
두 가지 프로그램이 있다.<br>중요한 것은 우리가 라우터나 링크 계층 스위치처럼 네트워크 코어 장비에서 실행되는 소프트웨어까지 작성할 필요는 없다는 점이다.<br>
(그렇게 하고 싶더라도 네트워크 코어 장비는 애플리케이션 계층에서 기능하지 않기 때문에 그렇게 할 수 없다.)<br><br>
<br>
<br><br><br>애플리케이션 구조는 네트워크 구조와 분명히 다르다.<br>애플리케이션 개발자 관점에서 네트워크 구조는 고정되어 있고, 해당 애플리케이션의 특정 서비스 집합을 제공한다.<br>반면, 애플리케이션 구조는 애플리케이션 개발자가 설계하며, 애플리케이션이 여러 종단 시스템에서 어떻게 조직되어야 하는지를 알려준다.<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210484607-f2096b44-08ec-4e8d-b75d-4e3df863f35d.png" alt="애플리케이션 구조" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><br>
<br>항상 동작하고 있는 서버가 존재하고, 클라이언트라는 다른 호스트들로부터 서비스 요청을 받는다.
<br>클라이언트는 서로 직접적으로 통신하지 않는다.
<br>서버는 잘 알려진 고정 IP 주소를 갖는다.
<br>서버가 클라이언트로부터 오는 모든 요청에 더 응답하는 것이 불가능할 때,<br>
많은 수의 호스트를 갖춘 데이터 센터가 강력한 가상의 서버를 생성하는 역할로 사용된다. 보통, 10만개 정도의 서버를 갖추고 있다.
<br><br><br><br>
<br>항상 켜져있는 인프라스트럭처 서버에 최소로 의존한다. (혹은 의존하지 않는다.)
<br>대신에 애플리케이션은 peer라는 간헐적으로 연결된 호스트 쌍이 서로 직접 통신하게 한다.
<br>peer는 흔히 알려진 클라이언트(개인 데스크톱과 랩톱 등등)이다.
<br>자가 확장성을 가진다. 예를 들어, 파일 공유 애플리케이션에서는 각 피어들이 파일을 요구하여 작업 부하가 생기지만<br>
각 피어들은 파일을 다른 피어들에게 분배하여 시스템에 서비스 능력을 갖춘다.
<br>데이터 센터 등이 필요 없으므로 비용 효율적이다.
<br><br>
<br>
<br><br><br>
실제 통신하는 것은 프로그램이 아니라, 실행되고 있는 프로그램인 프로세스이다.
<br>2개의 종단 시스템에서 프로세스는 컴퓨터 네트워크를 통한 메시지 교환으로 서로 통신한다.<br>송신 프로세스는 메시지를 만들어서 보내고 수신 프로세스는 메시지를 받고 역으로 메시지를 보냄으로써 응답한다.<br><br>
<br><br><br>네트워크 애플리케이션은 네트워크에서 서로 메시지를 보내는 두 프로세스로 구성된다.<br><br><br>클라이언트와 서버 프로세스를 다음과 같이 정의한다.<br>
💡 두 프로세스 간의 통신 세션에서<br>
통신을 초기화(다른 프로세스와 세션을 시작하려고 접속을 초기화)하는 프로세스를 클라이언트(client)라 하고,<br>
세션을 시작하기 위해 접속을 기다리는 프로세스를 서버(server)라고 한다.
<br><br><br>간단히 말하면, 요청을 보내는 쪽의 프로세스를 보통 클라이언트라고 하고, 요청을 받는 쪽을 서버라고 한다.<br>당연히 P2P 구조에서 봤듯이, 클라이언트도 서버 프로세스가 될 수 있고, 서버도 클라이언트 프로세스가 될 수 있다.<br><br>
<br><br><br>
프로세스는 소켓(socket)을 통해 네트워크로 메시지를 보내고 받는다.
<br>네트워크에서 프로세스를 집이라 한다면, 소켓은 마치 문과 같은 존재이다.<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210484602-4feb26bd-c1bf-43dd-aa19-14fcac26b146.png" alt="소켓" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br>위 그림에 보이듯이, 소켓은 호스트의 애플리케이션 계층과 트랜스포트 계층간의 인터페이스다.<br>네트워크 애플리케이션이 인터넷에 만든 프로그래밍 인터페이스이므로, 애플리케이션과 네트워크 사이의 API라고도 한다.<br><br><br>애플리케이션 개발자는 소켓의 애플리케이션 계층에 대한 모든 통제권을 갖지만, 소켓의 트랜스포트 계층에 대한 통제권은 거의 갖지 못한다.<br>애플리케이션 개발자의 트랜스포트 계층에 대한 통제<br>
<br>트랜스포트 프로토콜을 선택
<br>최대 버퍼와 최대 세크먼트 크기 같은 약간의 매개변수 설정
<br><br>
<br><br><br>프로세스가 다른 수행되고 있는 다른 패킷으로 프로세스를 보내기 위해서는 수신 프로세스가 주소를 갖고 있어야 한다.<br>수신 프로세스를 식별하기 위해서는 두 가지 정보가 필요하다.<br>
<br>호스트의 주소 즉, IP 주소가 필요하다.
<br>호스트 내의 수신 프로세스를 명시하는 식별자 즉, port 번호가 필요하다. 더 자세한 내용은 3장에서 다룬다.
<br><br>
<br>
<br><br><br>
송신 측의 애플리케이션은 소켓을 통해 메시지를 보내고,<br>
트랜스포트 프로토콜은 네트워크를 통해 그 메시지를 수신 프로세스의 소켓으로 이동시킬 책임이 있다.
<br><br><br>인터넷을 포함한 많은 네트워크는 트랜스포트 프로토콜을 하나 이상 제공한다.<br>트랜스포트 프로토콜이 그것을 이용하는 애플리케이션에게 제공할 수 있는 4가지 서비스를 알아보자.<br>
<br>신뢰적 데이터 전송(data integrity)
<br>처리율(throughput)
<br>시간(timing)
<br>보안(security)
<br><br>
<br><br><br>1장에서 보았듯이, 패킷들은 컴퓨터 네트워크 내에서 손실될 수 있다.<br>이러한 데이터 손실은 위험한 결과를 초래할 수 있다.<br><br><br>만약 프로토콜이 보장된 데이터 전송 서비스를 제공한다면 신뢰적 데이터 전송이라고 한다.<br>트랜스포트 프로토콜이 이 서비스를 제공할 때, 송신 프로세스는 데이터를 소켓으로 보내고 그 데이터가 오류 없이 수신 프로세스에 도착할 것이라는 확신을 갖는다.<br><br><br>트랜스포트 프로토콜이 이 서비스를 제공하지 않을 때 송신 프로세스가 보낸 데이터는 전혀 도착하지 않을 수 있다.<br>이러한 애플리케이션을 손실 허용 애플리케이션(실시간 비디오/오디오 애플리케이션 등이 대표적)이라고 한다.<br><br><br><br>다른 세션들이 네트워크 경로를 따라 대역폭을 공유하고, 이 세션들이 생겼다 없어졌다 하기 때문에 가용한 처리율은 시간에 따라 변한다.<br>트랜스포트 프로토콜은 어느 명시된 속도에서 보장된 가용 처리율을 제공한다.<br><br><br>처리율 요구사항을 갖는 애플리케이션은 대역폭 민감 애플리케이션이라 하고, 현존하는 많은 멀티미디어 애플리케이션은 대역폭에 민감하다.<br>
(너무 처리율이 낮으면 전화같은 서비스가 불가능하다.)<br>반대로 요구사항이 없는 애플리케이션을 탄력적 애플리케이션(elastic apps)이라고 한다.<br><br><br><br>트랜스포트 프로토콜은 시간 보장을 제공할 수 있다.<br>예를 들어, 송신자가 소켓으로 내보내는 모든 비트가 수신자의 소켓에 100ms 내에 도착하게 할 수 있다.<br>실시간 애플리케이션에 주로 사용된다.<br><br><br><br>송신 호스트에서 트랜스포트 프로토콜은 모든 데이터를 암호화할 수 있고, 수신 호스트에서 트랜스포트 프로토콜은 모두 해독할 수 있다.<br>보통 TCP를 애플리케이션 계층에서 강화하여 TLS로 보안 서비스를 제공한다. (자세한 내용은 8장에서 다룬다.)<br><br>
<br>
<br><br><br><br><br><br>TCP 전송 프로토콜은 다음 세 가지 서비스를 제공한다.<br><br><br><br>애플리케이션 계층 메시지를 전송하기 전에 TCP는 클라이언트와 서버가 서로 전송 제어 정보를 교환하게 한다.<br>이 핸드 셰이킹(handshaking) 과정이 클라이언트와 서버에 패킷이 곧 도달할테니 준비하라고 알려주는 역할을 한다.<br><br><br>핸드셰이킹 단계를 지나면, TCP 연결이 두 프로세스의 소켓 사이에 존재한다고 말한다.<br>이 연결은 두 프로세스가 서로에게 동시에 메시지를 보낼 수 있기에 전이중 연결이라고 한다. (3장에서 더 자세히 다룬다.)<br><br><br><br>통신 프로세스는 모든 데이터를 오류 없이 올바른 순서로 전달하기 위해 TCP에 의존한다.<br>TCP는 애플리케이션의 한 쪽이 바이트 스트림을 소켓으로 전달하면, 그 바이트 스트림이 손실되거나 중복되지 않게 수신 소켓으로 전달한다.<br><br><br><br>네트워크가 혼잡 상태에 이르면 프로세스의 속도를 낮추는 방법 (또한, 3장에서 자세히 다룬다.)<br><br>
<br><br><br>UDP는 최소의 서비스 모델을 가진 간단한 전송 프로토콜이다.<br>UDP는 비연결형으로 핸드셰이킹 과정이 없고, 비신뢰적인 데이터 전송 서비스를 제공하여 데이터가 전달되는 것을 보장하지 않는다.<br><br><br>UDP는 또한 혼잡 제어 방식을 포함하지 않아 프로세스의 속도 저하 없이 네트워크를 이용할 수 있다.<br>그러나 혼잡으로 인해 종단 간 처리율이 낮아져서 속도가 오히려 더 낮아질 수 있다.<br><br>
<br><br><br>TCP와 UDP는 처리율 혹은 시간 보장 서비스를 제공하지 않는다.<br>시간 민감 애플리케이션 같은 경우에는 이러한 처리율 및 시간 지연에 잘 대처할 수 있도록 설계되어 있다.<br>그러나 지연이 과도할 때는 보장이 없기 때문에 한계가 있다.<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210484597-debfaad5-bc3b-4c64-ba00-fef7502dab75.png" alt="하위 트랜스포트 프로토콜" referrerpolicy="no-referrer" style="width: 800px; max-width: 100%;"><br><br>
<br>
<br>
<br><br><br>
💡 애플리케이션 계층 프로토콜은 다른 종단 시스템에서 실행되는 애플리케이션의 프로세스가 서로 메시지를 보내는 방법을 정의한다.
<br><br><br>이는 다음과 같은 내용을 정의한다.<br>
<br>교환 메시지의 타입
<br>여러 메시지 타입의 문법(syntax)
<br>필드의 의미, 즉 필드에 있는 정보의 의미(semantics)
<br>언제, 어떻게 프로세스가 메시지를 전송하고 메시지에 응답하는지를 결정하는 규칙
<br><br><br>여러 애플리케이션 계층 프로토콜은 RFC에 명시되어 있어 공중 도메인에서 찾을 수 있다.<br>예를 들어, 만약 브라우저 개발자가 HTTP 규칙을 따른다면, HTTP 규칙을 따른 어떠한 웹 서버로부터도 웹페이지를 가져올 수 있다.<br>다른 많은 애플리케이션 계층 프로토콜은 독점이며 공중 도메인에서 찾을 수 없다.<br><br><br>애플리케이션 계층 프로토콜은 네트워크 애플리케이션의 한 요소일 뿐이다.<br>예를 들어, 웹 애플리케이션은 문서 포맷 표준, 웹 브라우저, 웹 서버, 웹 애플리케이션 계층 프로토콜(HTTP)을 포함하는 여러 요소들로 구성된다.<br><br>
<br>
<br><br><br>이 책에서는 중요하고 인기 있는 5개의 애플리케이션 분야에 초점을 맞춘다.<br>
<br>웹
<br>전자메일
<br>디렉터리 서비스
<br>비디오 스트리밍
<br>P2P 애플리케이션
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.1-네트워크-애플리케이션의-원리\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.1 네트워크 애플리케이션의 원리/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:03 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210484607-f2096b44-08ec-4e8d-b75d-4e3df863f35d.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210484607-f2096b44-08ec-4e8d-b75d-4e3df863f35d.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2 웹과 HTTP]]></title><description><![CDATA[ 
 <br><br>웹은 온디맨드(on-demand) 방식으로 사용자가 원할 때 원하는 것을 수신한다.<br>개인은 또한, 웹 상에서 많은 정보를 얻고 상호작용할 수 있다.<br><br>
<br>
<br><br><br>웹 애플리케이션 계층 프로토콜은 웹의 중심이다.<br>RFC 1945, RFC 7230, RFC 7540에 정의되어 있다.<br>HTTP는 메시지의 구조 및 클라이언트와 서버가 메시지를 어떻게 교환하는지에 대해 정의하고 있다.<br>자세히 설명하기 전에 웹 전문 용어들을 알아보자.<br><br>
<br><br><br>
웹 페이지들은 객체(object)로 구성된다.
<br>객체는 단순히 단일 URL로 지정할 수 있는 하나의 파일(HTML, JPEG 이미지, 자바스크립트 등)이다.<br><br><br>대부분의 웹 페이지는 기본 HTML 파일과 여러 참조 객체로 구성된다.<br>예를 들어, 웹 페이지가 HTML 텍스트와 5개의 JPEG 이미지로 구성되어 있으면, 이 웹페이지는 6개의 객체를 갖는다.<br><br><br>기본 HTML 파일은 페이지 내부의 다른 객체를 그 객체의 URL로 참조한다.<br>URL은 객체를 갖고 있는 서버의 호스트 이름과 객체의 경로 이름을 갖고 있다.<br>e.g.,<br>http://www.school.edu/picture.gif 
복사<br>
<br>호스트의 이름 : www.school.edu
<br>경로 이름 : picture.gif
<br><br>
<br><br><br>웹 브라우저(Web browser)는 HTTP의 클라이언트 측을 구현하기 때문에, 웹의 관점에서 브라우저와 클라이언트(client)라는 용어를 혼용하여 사용한다.<br>브라우저는 요구한 웹 페이지를 보여주고 여러가지 인터넷 항해와 구성 특성을 제공한다.<br><br><br>웹 서버(Web server)는 URL로 각각을 지정할 수 있는 웹 객체를 갖고 있다.<br>일반적으로, 사용자가 웹 페이지를 요청할 때<br>
(1) 브라우저는 페이지 내부의 객체에 대한 HTTP 요청 메세지를 서버에게 보내고,<br>
(2) 서버는 요청을 수신하고 객체를 포함하는 HTTP 응답 메시지로 응답한다.<br><img src="https://user-images.githubusercontent.com/76640167/210488592-53e2960a-2ec3-4ecf-8408-8d51a3ebb968.png" alt="웹서버와 브라우저" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br>
<br><br><br>
HTTP는 TCP를 전송 프로토콜로 사용한다.
<br><br><br>
<br>
HTTP 클라이언트는 먼저 서버에 TCP 연결을 시작한다.

<br>
연결이 이루어지면, 브라우저와 서버 프로세스는 각각의 소켓 인터페이스를 통해 TCP로 접속한다.

<br>
클라이언트는 HTTP 요청 메시지를 소켓 인터페이스로 보내고, 소켓 인터페이스로부터 HTTP 응답 메시지를 받는다.<br>
마찬가지로, HTTP 서버는 소켓 인터페이스로부터 요청 메시지를 받고 응답 메시지를 소켓 인터페이스로 보낸다.

<br><br><br>이렇게 TCP를 통해 메시지를 보내면 TCP는 신뢰적인 데이터 전송 서비스를 제공하므로<br>
모든 HTTP 요청 메시지가 궁극적으로 서버에 도착한다. (서버에서 보낸 메시지도 마찬가지다.)<br>HTTP는 TCP가 어떻게 손실 데이터를 복구하고, 올바른 순서로 데이터를 배열하는지 전혀 걱정할 필요가 없어 계층 구조의 장점이 드러난다.<br><br>
<br><br><br>특정 클라이언트가 몇 초 후에 같은 객체를 두 번 요청해도 서버는 전에 보냈다고 알려주지 않고 객체를 또 보낸다.<br>HTTP 서버는 클라이언트에 대한 정보를 유지하지 않으므로, 비상태(stateless) 프로토콜이라고 부른다.<br><br>
<br>
<br><br><br><br>
💡 클라이언트-서버 상호작용이 TCP 상에서 발생할 때 각 요구/응답 쌍이 분리된 TCP 연결을 통해 보내지는 것을 말한다.
<br><br><br>웹 페이지를 서버에서 클라이언트로 전송하는 단계를 살펴보자.<br>페이지가 기본 HTML 파일과 10개의 이미지로 구성되고, 이 11개의 객체가 같은 서버에 있다고 가정하자.<br><br><br>연결 수행 과정은 다음과 같다.<br>
<br>
HTTP 클라이언트는 HTTP 기본 포트 80을 통해 서버로 TCP 연결을 시도한다. TCP 연결과 관련하여 클라이언트와 서버에 각각 소켓이 있게 된다.

<br>
HTTP 클라이언트는 설정된 TCP 연결 소켓을 통해 서버로 HTTP 요청 메시지를 보낸다. 이 요청에 객체 경로도 포함된다.

<br>
HTTP 서버는 TCP 연결 소켓을 통해 요청 메시지를 받는다. 저장 장치로부터 경로의 객체를 추출한다.<br>
HTTP 응답 메시지에 그 객체를 캡슐화 하여 소켓을 통해 클라이언트로 보낸다.

<br>
HTTP 서버는 TCP에게 연결을 끊으라고 한다. (그러나 실제로 클라이언트가 응답 메시지를 올바로 받을 때까지 끊지 않는다.)

<br>
HTTP 클라이언트가 응답 메시지를 받으면, TCP 연결이 중단된다. 메시지는 캡슐화된 객체가 HTML 파일인 것을 나타낸다.<br>
클라이언트는 응답 메시지로부터 파일을 추출하고 HTML 파일을 조사하여 10개의 JPEG 객체에 대한 참조를 찾는다.

<br>
참조되는 JPEG 객체에 대해 1 ~ 4단계를 반복한다.

<br><br><br>브라우저는 웹 페이지를 수신하면서, 사용자에게 그 페이지를 보여준다. 다른 브라우저는 웹 페이지를 각기 다른 방식으로 해석하여 보여준다.<br>
HTTP는 통신 프로토콜만 정의할 뿐, 웹 페이지에 대한 관심은 없다.
<br><br><br>사용자는 앞의 단계를 동시에 받을지 순차적으로 받을지의 동시성 정도를 조절할 수 있도록 브라우저를 구성할 수 있다.<br>브라우저는 여러 개의 TCP 연결을 설정하며 다중 연결상에서 웹 페이지의 각기 다른 원하는 부분을 요청할 수 있다.<br>HTTP 1.0은 비지속 연결을 지원한다.<br><br>
<br><br>클라이언트가 HTML 파일을 요청하고 그 파일이 클라이언트로 수신될 때까지의 시간을 측정해보자.<br>이를 위해 RTT를 알아야 하는데,<br>
RTT(round-trip-time)란 작은 패킷이 클라이언트로부터 서버까지 가고, 다시 클라이언트로 되돌아오는 데 걸리는 시간이다.<br>RTT는 패킷 전파 지연, 큐잉 지연, 처리 지연 등을 포함한다. (1장에 논의되어 있다.)<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210491569-3638ca03-2d17-4eea-8a5f-d984bb831d00.png" alt="HTML 요청 시간 계산" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>사용자가 하이퍼링크를 클릭하면, 브라우저와 웹 서버 사이에서 TCP 연결을 시도한다. 이는 3-way handshake를 포함한다.<br>
즉, 클라이언트가 서버로 작은 TCP 메시지를 보내고, 서버는 작은 메시지로 응답하고, 마지막으로 클라이언트가 다시 서버에 응답한다.
<br><br><br>서버가 작은 메시지로 응답하면 한 RTT가 계산된다. 이때, 클라이언트는 HTTP 요청 메시지를 TCP 연결로 보내면서 세 번째 응답 부분을 함께 보낸다.<br>일단, 요청 메시지가 도착하면 서버는 HTML 파일을 TCP 연결로 보내고 이 요청은 또 하나의 RTT를 필요로 한다.<br>
즉, 대략 총 응답 시간은 2RTT와 HTML 파일을 서버가 전송하는 데 걸리는 시간을 더한 것이다.
<br><br>
<br><br><br>
<br>
각 요청 객체에 대한 새로운 연결이 설정되고 유지되어야 한다.

<br>TCP 버퍼가 할당되어야 하고, TCP 변수들이 클라이언트와 서버 양쪽에 유지되어야 하는데<br>
이는 수많은 클라이언트들의 요청을 동시에 서비스하는 웹 서버에는 심각한 부담이다.


<br>
매번 2RTT를 필요로 한다.

<br><br>
<br>
<br><br><br>HTTP/1.1 지속 연결에서 서버는 응답을 보낸 후에 TCP 연결을 그대로 유지한다. (비지속 연결도 지원한다.)<br>같은 클라이언트와 서버 간의 이후 요청과 응답은 같은 연결을 통해 보내진다.<br>즉, 같은 서버에 있는 여러 웹 페이지들을 하나의 지속 TCP 연결을 통해 보낼 수 있다.<br><br><br>이들 객체에 대한 요구는 진행 중인 요구에 대한 응답을 기다리지 않고 연속해서 만들 수 있다. (파이프라이닝, pipelining)<br>일반적으로 HTTP 서버는 일정 기간 사용되지 않으면 연결을 닫는다.<br>HTTP의 디폴트 모드는 파이프라이닝을 이용한 지속 연결을 사용한다.<br><br>
<br><br><br>RFC는 HTTP 메시지 포맷을 정의한다.<br><br><img src="https://user-images.githubusercontent.com/76640167/210494014-891426d1-0c27-47dc-8271-c6f5bab316e9.png" alt="요청 메시지 포맷" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>다음은 전형적인 HTTP 요청 메시지이다.<br>GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0
Accept-language: fr
복사<br><br><br><br>
<br>ASCII 텍스트로 쓰여 있어 사람들이 읽을 수 있다.
<br>메시지가 다섯 줄로 되어 있고, 각 줄은 CR(carriage return)과 LF(line feed)로 구별된다. 마지막 줄에 이어서 CR과 LF가 따른다.
<br>HTTP 요청 메시지의 첫 줄은 요청 라인이라 부르고, 이후의 줄들은 헤더 라인이라고 부른다.<br><br><br><br>요청 라인은 3개의 필드, 즉 방식(method) 필드, URL 필드, HTTP 버전 필드를 갖는다.<br>방식 필드는 GET, POST, HEAD, PUT, DELETE 등의 여러 가지 값을 가질 수 있다.<br><br>
<br><br><br>
<br>Host

<br>객체가 존재하는 호스트를 명시한다.
<br>이미 호스트까지 TCP 연결이 맺어져 있어 불필요하다고 생각될 수 있지만, 2.2.5절에서 나오는 웹 프록시 캐시에서 필요로 한다.


<br>Connection : 이 헤더 라인을 포함함으로써, 브라우저는 서버에게 지속 연결 사용을 원하는지 비지속 연결 사용을 원하는지 전달한다.
<br>User-agent : 서버에게 요청을 하는 브라우저 타입을 명시한다.
<br>Accept-language : 헤더는 사용자가 객체의 어떤 언어 버전을 원하고 있음을 나타낸다.
<br><br>
<br><br><br>GET일 때는 비어있고, POST일 때 사용된다.<br>POST 메시지로 사용자는 서버에 웹 페이지를 요청하고 있으나, 웹 페이지의 특정 내용은 사용자가 폼 필드에 무엇을 입력하는가에 달려 있다.<br>폼으로 생성한 요구가 반드시 POST일 필요는 없다. 대신에 흔히 요청된 URL의 입력 데이터를 전송한다.<br><br><br>HEAD 방식은 GET과 유사하다.<br>서버가 HEAD 방식을 가진 요청을 받으면 HTTP 메시지로 응답하는데, 요청 객체는 보내지 않는다. 흔히 디버깅을 위해 사용된다.<br><br><br>PUT 방식은 웹 서버에 업로드할 객체를 필요로 하는 애플리케이션에 의해 사용된다.<br>DELETE 방식은 사용자 또는 애플리케이션이 웹 서버에 있는 객체를 지우는 것을 허용한다.<br><br>
<br><br><br><br><br><br><img src="https://user-images.githubusercontent.com/76640167/210497215-8265b94b-c82f-4ea8-9374-5f41fc6eaed1.png" alt="응답 메시지" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>다음은 전형적인 HTTP 응답 메시지를 보여준다.<br>HTTP/1.1 200 OK
Connection: close
Date: Tue, 18 Aug 2015 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html
(data data data data data ...)
복사<br><br><br><br>상태 라인(status line)은 버전 필드와 상태 코드, 해당 상태 메시지를 갖는다.<br>상태 코드와 메시지<br>
<br>200 OK: 요청이 성공했고, 정보가 응답으로 보내졌다.
<br>301 Moved Permanently: 요청 객체가 영원히 이동되었다. 이때, 새로운 URL은 응답 메시지의 Location 헤더에 나와있다.
<br>400 Bad Request : 서버가 요청을 이해할 수 없다.
<br>404 Not Found : 요청한 문서가 서버에 존재하지 않는다.
<br>505 HTTP Version Not Supported : 요청 HTTP 프로토콜 버전을 서버가 지원하지 않는다.
<br><br><br><br>
<br>Connection : 클라이언트에게 메시지를 보낸 후 TCP 연결을 닫을지 말지 결정한다.
<br>Date : HTTP 응답이 서버에 의해 생성되고 보낸 날짜와 시간을 나타낸다.
<br>Server : 메시지가 어떤 웹 서버에 의해 만들어졌는지 나타낸다.
<br>Last-Modified : 객체가 생성되거나 마지막으로 수정된 시간과 날짜를 나타낸다.
<br>Content-Length : 송신되는 객체의 바이트 수를 나타낸다.
<br>Content-Type : 개체 몸체 내부(Entity body)의 객체가 어떤 타입인지 나타낸다.
<br><br><br>HTTP 명세서는 많은 헤더라인을 정의하고 있고, 위는 그 중 일부다.<br>브라우저는 브라우저 타입과 여러 설정, 캐싱하고 있는지에 따라 헤더 라인을 동적으로 생성하고 웹 서버도 비슷하다.<br><br>
<br>
<br><br><br>HTTP 서버는 상태를 유지하지 않는다.<br>그러나 서버가 사용자 접속을 제한하거나 사용자에 따라 콘텐츠를 제공하기 원하므로<br>
사용자를 확인하는 것이 바람직할 때가 있는데, 이때 HTTP는 쿠키(cookie)를 사용한다.<br>
over stateless HTTP, cookie provides a state related service layer
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210499304-190c6dc5-ab64-4864-9f25-bb27fc63f460.png" alt="쿠키를 이용한 상태 유지" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><br>
<br>웹 서버에 HTTP 요청 메시지를 전달한다.
<br>웹 서버는 유일한 식별 번호를 만들고 이 식별 번호로 인덱싱 되는 백엔드 데이터 베이스 안에 엔트리를 만든다.
<br>HTTP 응답 메시지에 Set-cookie: 식별 번호의 헤더를 포함해서 전달한다.
<br>브라우저는 헤더를 보고, 관리하는 특정한 쿠키 파일에 그 라인을 덧붙인다.
<br>다시 동일 웹 서버에 요청을 보낼 때<br>
브라우저는 쿠키 파일을 참조하고 이 사이트에 대한 식별번호를 발췌하여 Cookie : 식별 번호의 헤더를 요청과 함께 보낸다.
<br>이렇게 웹 서버는 사용자를 식별할 수 있다.<br><br>
<br>
<br><br><br>
웹 캐시(cache)(프록시(proxy) 서버)는 기점 웹 서버를 대신하여 HTTP 요구를 충족시키는 개체이다.
<br>
Goal: satisfy client request without involving origin server
<br>웹 캐시는 자체의 저장 디스크를 갖고 있어, 최근 호출된 객체의 사본을 저장 및 보존한다.<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210502046-6dbbe817-240d-401d-8ec6-f3a73210e48d.png" alt="웹 캐싱" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br><br><br>
<br>브라우저는 웹 캐시와 TCP 연결을 설정하고 웹 캐시에 있는 객체에 대한 HTTP 요청을 보낸다.
<br>웹 캐시는 객체의 사본이 저장되어 있는지 확인하고, 저장되어 있다면 클라이언트 브라우저로 HTTP 응답 메시지와 함께 객체를 전송한다.
<br>갖고 있지 않다면, 기점 서버로 TCP 연결을 설정한다.<br>
이후 웹 캐시는 캐시와 서버 간의 TCP 연결로 객체에 대한 HTTP 요청을 보낸다. 기점 서버는 웹 캐시로 HTTP 응답 메시지를 보낸다.
<br>웹 캐시의 객체를 수신할 때, 객체를 지역 저장장치에 복사하고 클라이언트 브라우저에 HTTP 응답 메시지를 보낸다. (이때, 이미 설정된 TCP를 통해 보낸다.)
<br><br><br>
캐시(cache)는 요청과 응답을 모두 하는 클라이언트이면서 서버이다.
<br>
<br>server for original requesting client
<br>client to origin server
<br><br><br>일반적으로 웹 캐시는 ISP(university, company, residential ISP)가 구입하고 설치한다.<br><br>
<br><br><br>
<br>
클라이언트 요구에 대한 응답 시간을 줄일 수 있다.<br>
보통 클라이언트와 캐시 사이에 높은 속도의 연결이 설정되어 있어 웹서버 캐시에 객체를 갖고 있다면 병목 현상을 줄일 수 있다.

<br>
웹 캐시는 한 기관에서 인터넷으로의 접속하는 링크 상의 웹 트래픽을 대폭 줄일 수 있다.

<br>
인터넷 전체의 웹 트래픽을 실질적으로 줄여주어 모든 애플리케이션의 성능이 좋아진다.

<br><br><br><br><img src="https://user-images.githubusercontent.com/76640167/210504713-f02f053c-e503-413f-8cbc-046c55082359.png" alt="병목 현상" referrerpolicy="no-referrer" style="width: 370px; max-width: 100%;"><br><br>
<br><br>
<br>평균 객체의 크기가 1 Mb이고, 기관 브라우저로부터 기점 서버에 대한 평균 요청 비율이 초당 15 요청이라고 가정하자.
<br>HTTP 메시지 요청이 무시할만큼 작으므로 네트워크 접속 회선에 어떤 트래픽도 발생시키지 않는다고 가정하자.
<br>또한, 접속 회선의 인터넷 부분 라우터가 HTTP 요청을 전달하고 응답을 받을 때까지 평균 소요 시간을 2초라고 가정하자.<br>
통상 이러한 지연을 인터넷 지연이라고 한다.
<br>
총 응답 시간 = LAN 지연 + 접속 지연 + 인터넷 지연
<br><br><br>LAN의 트래픽 강도는 다음과 같다.<br>(15 요청/초) X (1 Mb/요청) / 100 Mbps = 0.15
복사<br><br><br>접속 회선(라우터와 라우터 사이)의 트래픽 강도는 다음과 같다.<br>(15 요청/초) X (1 Mb/요청) / 15 Mbps = 1
복사<br><br><br>LAN의 트래픽 강도는 많아야 수십 ms의 지연을 야기하므로 LAN 지연을 무시할 수 있지만,<br>
트래픽 강도가 1에 가까워지면 1.4절에서 논의한 것과 같이 회선의 지연은 매우 커지고 한없이 증가한다.<br>접속 회선의 접속률을 100 Mbps 수준으로 늘리면 트래픽 강도를 0.15로 낮추어 해결할 수 있겠지만, 매우 많은 비용이 들어간다.<br><br><br><br><br><br>웹 캐시를 사용한 예시를 보자.<br><img src="https://user-images.githubusercontent.com/76640167/210506730-5cb70fea-a9ed-4817-afe0-4463bfd24a4a.png" alt="인터넷의 구성 요소" referrerpolicy="no-referrer" style="width: 370px; max-width: 100%;"><br><br>
<br><br>캐시가 만족시킨 요청의 비율(hit rate)은 일반적으로 0.2 ~ 0.7이며, 이 예시에서는 0.4의 적중률을 가진다고 가정하자.<br>
<br>캐시와 클라이언트는 고속 LAN으로 연결되어 있어, 요청의 40%는 캐시에 의해(10ms 이내) 즉시 만족된다.
<br>나머지 60%의 요청은 여전히 기점 서버에 의해 만족되어야 하므로 트래픽 강도는 1.0에서 0.6으로 감소한다.
<br>일반적으로 0.8 미만의 트래픽 강도는 작은 지연에 속한다. (2초에 의하면 무시할 수 있는 수준이다.)<br><br><br>이들을 고려한 평균 지연은 다음과 같다.<br>0.4 X 0.01초 + 0.6 X 2.01초 = 1.2....
복사<br><br><br>많은 캐시가 저렴한 PC에서 실행되는 공개 소프트웨어를 사용한다.<br>
<br>
콘텐츠 전송 네트워크(CDN)을 통해 웹 캐시는 인터넷에서 점진적으로 중요한 역할을 하고 있다.

<br>
CDN 회사는 인터넷 전역을 통해 많은 지역적으로 분산된 캐시를 설치하고 있으며,<br>
이를 통해 많은 트래픽을 지역화하고 있다. (전용 CDN을 사용하기도 한다.)

<br><br>
<br><br><br>
웹 캐싱이 사용자가 느끼는 응답 시간을 줄일 수 있지만, 웹 캐시 내부에 있는 복사본이 새 것이 아닐 수 있다는 문제를 야기한다.
<br>복사본이 클라이언트에 캐싱된 이후 웹 서버에 있는 객체가 갱신되었을 수도 있기 때문이다.<br><br><br>
💡 HTTP는 클라이언트가 브라우저로 전달되는 모든 객체가 최신의 것임을 확인하면서 캐싱해주는데,<br>
이러한 방식을 조건부 GET(conditional GET) 이라고 한다.
<br>
Goal: don't send object if cache has up-to-date cached version
<br>HTTP 요청 메시지가 (1) GET 방식을 사용하고, (2) If-modified-since 헤더를 포함한다면, 그것이 조건부 GET이다.<br><br><br><br>
<br>브라우저의 요청을 대신해서 프록시 캐시는 요청 메시지를 웹 서버로 보낸다.
<br>GET /fruit/kiwi.gif HTTP/1.1
Host: www.exotiquecuisine.com
복사<br><br><br>
<br>웹 서버는 캐시에게 객체를 가진 응답 메시지를 보낸다.
<br>HTTP/1.1 200 OK
Date: Sat, 3 Oct 2015 15:39:29
Server: Apache/1.3.0 (Unix)
Last-Modified: Wed, 9 Sep 2015 09:23:24
Content-Type: image/gif
(data data data data data ...)
복사<br>
<br>캐시는 요청하는 브라우저에게 객체를 보내주고 자신에게도 객체를 저장한다.
<br>중요한 것은 캐시가 객체와 더불어 마지막으로 수정된 날짜를 함께 저장한다는 것이다.
<br><br><br>
<br>일주일 후에 다른 브라우저가 같은 객체를 캐시에게 요청하면 캐시에 저장되어 있다.<br>
이 객체는 지난주에 웹 서버에서 수정되었으므로, 브라우저는 조건부 GET으로 조사를 수행한다.
<br>GET /fruit/kiwi.gif HTTP/1.1
Host: www.exotiquecuisine.com
If-modified-since: Wed, 9 Sep 2015 09:23:24
복사<br>
<br>
If-modified-since 값이 일주일 전에 서버가 보낸 Last-Modified 값과 완벽히 일치한다.

<br>
이 조건부 GET은 서버에게 If-modified-since에 명시된 값 이후 수정된 경우에만 그 객체를 보내라고 한다.

<br><br><br>
<br>변경되지 않았다면,
<br>HTTP/1.1 304 Not Modified
Date: Sat, 10 Oct 2015 15:39:29
Server: Apache/1.3.0 (Unix)
(empty entity body)
복사<br>
<br>위와 같은 응답을 보낸다.<br>
데이터가 변화가 없어도 객체를 보내는 것은 대역폭을 낭비하는 것이고, 특히 그 개체가 크다면 사용자가 느끼는 응답 시간이 증가된다.
<br>위 응답 메시지는 클라이언트에게 요청 객체의 캐싱된 복사본을 사용하라는 것을 의미한다.
<br><br>
<br>
<br><br><br>2020년 현재 주요 웹 사이트 천만 개의 40%가 HTTP/2를 지원하고 있다.<br>HTTP/2의 주요 목표는 하나의 TCP 연결상에서 멀티플렉싱 요청/응답 지연 시간을 줄이는 데 있으며,<br>
요청 우선순위화, 서버 푸시, HTTP 헤더 필드의 효율적인 압축 기능 등을 제공한다.<br>HTTP/2는 클라이언트와 서버 간의 데이터 포맷 방법과 전송 방법을 변경했다.<br><br>
<br><br><br>지속적인 연결을 사용할 때 웹 페이지당 오직 하나의 TCP 연결을 가짐으로써,<br>
아래 설명하듯이 서버에서의 소켓 수를 줄이며 전송되는 각 웹 페이지는 공정한 네트워크 대역폭을 가질 수 있다.<br>그러나 하나의 TCP 상에서 모든 웹페이지를 보내면 HOL(Head of Line) 블로킹 문제가 발생할 수 있다.<br><br><br><br><br>비디오 아래 수많은 작은 객체들을 포함할 때 서버와 클라이언트 사이에 저속에서 중간 속도의 병목 링크가 있다고 하자.<br>비디오 클립은 병목 링크를 통과하는데 오래 걸리는 반면, 작은 객체들은 비디오 클립 뒤에서 기다림이 길어진다.<br>즉, 비디오 클립이 객체들을 블로킹하게 된다.<br><br><br>HTTP/1.1에서는 여러 개의 병렬 TCP 연결을 열어서 위 문제를 해결해왔다.<br><br>
<br><br><br>TCP 혼잡 제어는 각 TCP 연결이 공정하게 병목 링크를 공유하여 같은 크기의 가용한 대역폭을 공평하게 나누게 해준다.<br>만일 n개의 TCP 연결이 병목 링크에서 작동하고 있다면, 각 연결은 대략 대역폭의 1/n 씩을 사용하게 된다.<br><br><br>하나의 웹 페이지를 전송하기 위해 여러 개의 병렬 TCP 연결을 열게 함으로써 브라우저는 일종의 속임수로 링크 대역폭의 많은 부분을 받게 된다.<br>많은 HTTP/1.1 브라우저들은 6개까지 병렬 TCP 연결을 열고 HOL을 막을 뿐만 아니라 더 많은 대역폭을 사용할 수 있게 한다.<br><br>
<br><br><br>
HTTP/2의 주요 목표 중 하나는 하나의 웹 페이지를 전송하기 위한 병렬 TCP 연결의 수를 줄이거나 제거하는 데 있다.
<br>이는 서버에서 열고 유지되는 데 필요한 소켓의 수를 줄일 뿐만 아니라 목표한 대로 TCP 혼잡 제어를 제어할 수 있게 하는 데 있다.<br>그러나 웹 페이지를 전송하기 위해 오직 하나의 TCP 연결만을 사용하게 될 경우에 HTTP/2는 HOL 블로킹을 피하기 위해 신중하게 구현된 메커니즘이 필요하다.<br><br><br>
💡 HTTP/2 프레이밍(framing)이란, HTTP 메시지를 독립된 프레임들로 쪼개고, 인터리빙(interleaving)하고, 반대편 사이트에서 재조립하는 것이다.
<br>예를 들어, 비디오 클립과 크기가 작은 객체 8개의 요청이 들어오면, 서버는 9개의 객체를 보내기 위한 TCP 병렬 요청을 받게된다.<br>이때 (1) 비디오 클립을 1000개의 프레임으로 나누고 (2) 각 객체를 2개의 프레임으로 나누어 비디오 클립으로부터 하나의 프레임을 전송한다.<br>이후 프레임 인터리빙을 이용하여 각 소형 객체의 첫 번째 프레임을 보내고 이를 반복하여 HOL 블로킹을 피할 수 있다.<br><br>
<br><br>HTTP 메시지를 독립된 프레임들로 쪼개고 인터리빙하고 반대편 사이트에서 재조립하는 것이야말로 HTTP/2의 가장 중요한 개선점이다.<br>프레이밍은 HTTP/2 프로토콜의 프레임으로 구현된 다른 프레이밍 서브 계층에 의해 이루어진다.<br>서버가 HTTP 응답을 보내고자 할 때, 응답은 프레이밍 서브 계층에 의해 처리되며 프레임들로 나눠진다.<br>응답의 헤더필드는 하나의 프레임이 되고, 메시지 본문은 하나의 프레임으로 쪼개진다.<br>응답 프레임들은 서버의 프레이밍 서브 계층에 의해 인터리빙된 후 하나의 지속적인 TCP 연결상에서 전송된다.<br>프레임들이 클라이언트에 도착하면 프레이밍 서브 계층에서 처음 응답메시지로 재조립되며 브라우저에 의해 처리된다. (클라이언트에서 서버로 요청할 때도 마찬가지이다.)<br><br><br>각 HTTP 메시지를 독립적인 프레임으로 쪼개는 것 외에도 프레이밍 서브 계층은 프레임을 바이너리 인코딩한다.<br>바이너리 프로토콜은 파싱하기에 효율적이고, 더 작은 프레임 크기를 갖고, 에러에 강하다.<br><br><br><br>메시지 우선순위화는 개발자들로 하여금 요청들의 상대적 우선 순위를 조정할 수 있게 함으로써 애플리케이션의 성능을 최적화할 수 있게 해준다.<br><br><br>클라이언트가 하나의 특정 서버로 동시에 여러 개의 요청을 할 때, 각 메시지에 1에서 256 사이의 가중치를 부여함으로써 요청에 우선순위를 매길 수 있다.<br>
높은 수치일수록 높은 우선순위를 갖는다.
<br>서버는 가장 높은 우선순위의 요청을 위한 프레임을 제일 먼저 보낼 수 있다.<br><br><br>클라이언트 또한 각 의존도에 따라 메시지의 ID를 지정하여 서로 다른 메시지들 간의 의존성을 나타낼 수 있다.<br><br><br><br>HTTP/2의 또 다른 특징은 서버로 하여금 특정 클라이언트 요청에 대해 여러 개의 응답을 보낼 수 있게 해주는 데 있다.<br>처음 요청에 대한 응답 외에도, 서버는 클라이언트의 요청 없이도 추가적인 객체를 클라이언트에게 푸시하여 보낼 수 있다.<br>이는 HTML 기반 페이지가 웹 페이지를 완벽하게 구동시킬 필요가 있는 객체들을 가리킬 수 있기에 가능하다.<br>이러한 객체에 대한 HTTP 요청을 기다리는 대신 서버는 HTML을 분석할 수 있고, 필요한 객체들을 식별할 수 있고,<br>
해당 객체들에 대한 요청이 도착하기도 전에 해당 객체들을 클라이언트로 보낸다.<br>서버는 해당 요청들을 기다리는 데 소요되는 추가 지연을 없앤다.<br><br>
<br><br><br>트랜스 프로토콜인 QUIC(3장에서 다룬다) 위에서 작동하도록 설계된 새로운 HTTP 프로토콜로서, 완전히 표준화된 상태는 아니다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.2-웹과-http\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.2 웹과 HTTP/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 06:50:33 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210488592-53e2960a-2ec3-4ecf-8408-8d51a3ebb968.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210488592-53e2960a-2ec3-4ecf-8408-8d51a3ebb968.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3 인터넷 전자메일]]></title><description><![CDATA[ 
 <br><br>이 절에서는 인터넷 전자메일 구조의 중심에 있는 애플리케이션 계층 프로토콜을 알아본다.<br><br><br>아래 그림은 인터넷 메일 시스템의 상위 레벨 개념을 보여준다.<br><img src="https://user-images.githubusercontent.com/76640167/210542924-1107ca75-eee8-45f6-829a-df0d0df81c15.png" alt="전자 메일 시스템" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>Three major components of Electronic mail:<br>
<br>User agents
<br>Mail servers
<br>SMTP(Simple Mail Transfer Protocol)
<br><br>
<br><br><br>
<br>a.k.a. "mail reader"
<br>사용자 에이전트는 사용자가 메시지를 읽고, 응답하고, 전달하고, 저장하고, 구성하게 해준다.
<br>대표적으로 마이크로 소프트 아웃룩(Outlook), 애플 메일 등이 있다.
<br><br>
<br><br><br>
<br>전자 메일 인프라스트럭처의 중심이다.
<br>각 수신자는 메일 서버에 메일 박스(mailbox)를 갖고 있다.

<br>메일 박스는 수신자의 메시지를 유지하고 관리한다.
<br>일반 메시지는 송신자의 사용자 에이전트에서 전달이 시작되고, 송신자의 메일 서버를 거친 후에 수신자의 메일 서버로 전달된다.<br>
거기서 수신자의 메일 박스에 저장된다.
<br>전자메일 박스에 있는 메시지를 보려면 메일 서버는 사용자 계정과 비밀 번호를 이용하여 이용자를 인증하여야 한다.


<br>송신자는 메일 서버의 고장에도 대처해야 한다.

<br>만약 메일을 수신자의 메일 서버로 전달할 수 없다면 그 메시지를 메시지 큐(queue)에 보관하고 나중에 그 메시지를 전달하기 위해 다시 시도한다.
<br>재시도는 약 30분마다 일어나고, 계속 실패 시에 서버는 그 메시지를 제거하고 송신자에게 통보한다.


<br><br>
<br><br><br>
💡 인터넷 전자메일을 위한 주요 애플리케이션 계층 프로토콜이다.
<br>
<br>SMTP는 메일을 송신자의 메일 서버로부터 수신자의 메일 서버로 전송하는 데에 TCP의 신뢰적인 데이터 전송 서비스를 이용한다.
<br>SMTP는 대부분의 애플리케이션 계층 프로토콜처럼, 클라이언트와 서버를 갖고 있다.
<br>SMTP의 클라이언트와 서버 모두가 모든 메일 서버에서 수행되고, 상대 메일로 송신할 때는 클라이언트가 되고 수신할 때는 서버가 된다.
<br><br>
<br>
<br><br><br>
uses TCP to reliably transfer email message from client to server, port 25
<br>
direct transfer: sending server to receiving server
<br><br><br>SMTP에서는 모든 메일 메시지의 몸체는 단순한 7-bit ASCII여야 한다.<br>이 때문에 전송 용량이 제한되어 커다란 첨부 파일이나 비디오 파일을 보낼 때 문제를 일으킨다.<br><br><br>Three phases of transfer<br>
<br>handshaking (greeting)
<br>transfer of messages (data exchange)
<br>closure
<br><br><br><br><img src="https://user-images.githubusercontent.com/76640167/210545342-e280b01b-fff0-4ec7-b921-9bfcddb94999.png" alt="메시지 전달 과정" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br>
<br>
앨리스는 전자 메일 사용자 에이전트를 수행하고, 밥의 전자 메일 주소를 제공하여 메시지를 보내라고 명령한다.

<br>
앨리스의 사용자 에이전트는 메시지를 그녀의 메일 서버에게 보내고, 그곳에서 메시지는 메시지 큐에 놓인다.

<br>
앨리스의 메일 서버에서 동작하는 SMTP의 클라이언트 측은 메시지 큐에 있는 메시지를 본다.<br>
밥의 메일 서버에서 수행되고 있는 SMTP 서버에게 TCP 연결을 설정한다.

<br>
초기 SMTP 핸드셰이킹 이후에 SMTP 클라이언트는 앨리스의 메시지를 TCP 연결로 보낸다.

<br>
밥의 메일 서버 호스트에서 SMTP의 서버 측은 메시지를 수신한다. 밥의 메일 서버는 그 메시지를 밥의 메일 박스에 놓는다.

<br>
밥은 편한 시간에 그 메시지를 읽기 위해 사용자 에이전트를 시동한다.

<br><br><br>
SMTP는 두 메일 서버가 먼 거리에 떨어져 있더라도 중간 메일 서버를 이용하지 않는다.
<br>즉, 메시지를 보낼 때 보내는데 실패하더라도 중간 메일 서버에 저장되는 것이 아니라 송신자의 메일 서버에 남아있다.<br><br>
<br><br><br>
<br>
클라이언트 SMTP는 서버의 SMTP의 25번 포트로 TCP 연결을 설정한다. 서버가 죽어있다면 나중에 시도한다.

<br>
연결이 설정되면, 애플리케이션 계층 핸드셰이킹을 수행한다.<br>
이때 SMTP 클라이언트는 송신자의 전자메일 주소와 수신자의 전자메일 주소를 제공한다.

<br>
이후 클라이언트는 메시지를 보낸다. (TCP의 신뢰적인 데이터 전송 서비스에 의존)

<br>
보낼 다른 메시지가 있다면 같은 TCP 연결 상에서 반복하며, 그렇지 않으면 TCP를 닫는다. (지속 연결(persistent connection))

<br><br>
<br><br><br>S:  220 hamburger.edu
C:  HELO crepes.fr
S:  250 Hello crepes.fr, pleased to meet you
C:  MAIL FROM: &lt;alice@crepes.fr&gt;
S:  250 alice@crepes.fr ... Sender ok
C:  RCPT TO: &lt;bob@hamburger.edu&gt;
S:  250 bob@hamburger.edu ... Recipient ok
C:  DATA
S:  354 Enter mail, end with ”.” on a line by itself
C:  Do you like ketchup?
C:  How about pickles?
C:  .
S:  250 Message accepted for delivery
C:  QUIT
S:  221 hamburger.edu closing connection
복사<br><br><br><img src="https://user-images.githubusercontent.com/86337233/232236656-a28366f7-e268-4cd4-a525-86b39c658069.png" alt="메시지 전달 과정 예시" referrerpolicy="no-referrer" style="width: 830px; max-width: 100%;"><br><br>
<br><br>
<br>클라이언트는 5개의 HELO, MAIL FROM, RCPT TO, DATA, QUIT 명령을 내린다.
<br>클라이언트는 하나의 점(.)으로 된 라인을 송신하며, 그것은 서버에서 메시지의 끝을 나타낸다.
<br>서버는 각 명령에 응답하며, 각 응답에는 응답 코드와 영문 설명이 있다.
<br><br><br>SMTP는 지속 연결(persistent connection)을 사용한다.<br>즉, 같은 수신 메일 서버로 보내는 여러 메시지를 갖고 있다면, 같은 TCP 연결을 통해 모든 메시지를 전달할 수 있다.<br><br><br>telnet 명령어를 사용하면 원격 메일 서버와 위와 같은 대화를 할 수 있다.<br><br>
<br>
<br><br><br>전자메일을 보낼 때 주변 정보가 포함된 헤더(header)가 메시지 몸체(body) 앞에 오게 된다.<br>
<br>이 헤더는 RFC 5322에 정의되어 있으며, 헤더와 몸체는 CRLF로 분리된다.
<br>모든 헤더는 From: 헤더라인과 To: 헤더 라인을 반드시 가져야 한다. (나머지 헤더는 선택사항이다.)
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/232237089-44b78dca-e43b-458c-9de0-f2756195c8a1.png" alt="메시지 포맷" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>일반 메시지 헤더는 다음과 같다.<br>From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.

Message
복사<br><br>
<br>
<br><br><br>
<br>SMTP : delivery / storage to receiver's server
<br>Mail access protocol : retrieval from server
<br><br><br>
메일 서버가 메일 박스를 관리하고, SMTP의 클라이언트와 서버 측 모두를 수행한다.
<br><br><br>메일 서버가 로컬 호스트에 있다면, 호스트는 언제든 도착할 수 있는 전자 메일을 수신하기 위해 항상 켜져 있어야 하고 인터넷에 연결되어 있어야 한다.<br>이는 대부분의 인터넷 사용자에게는 비현실적이다.<br><br><br>대신에 일반 사용자는 로컬 호스트에서 사용자 에이전트를 수행하고 늘 켜져 있는 공유 메일 서버에 저장된 메일박스에 접근한다.<br>메일 서버는 보통 사용자들과 공유한다.<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210550668-901b362b-a929-4d44-abe8-da7bf21ca857.png" alt="전자메일 프로토콜" referrerpolicy="no-referrer" style="width: 770px; max-width: 100%;"><br><br>
<br><br><br>
클라이언트의 사용자 에이전트는 수신자의 메일 서버로 직접 대화하지 않는다.
<br>대신에 그림처럼 (1) 클라이언트의 사용자 에이전트는 클라이언트의 메일 서버로 전자메일 메시지를 SMTP 또는 HTTP를 이용하여 보낸다.<br>(2) 그리고 수신자의 메일 서버는 SMTP를 이용하여 수신자의 메일 서버로 전자메일 메시지를 중계한다.<br><br><br>두 단계 절차를 거치는 주요 이유는 수신자의 메일 서버를 통해 중계하지 않으면 수신자의 에이전트는 목적지 메일 서버에 도달할 수 없기 때문이다.<br>송신자는 전자메일을 자신의 메일 서버에 먼저 저장하고, 수신자의 메일 서버는 그 메시지를 수신자의 메일 서버로 받을 때까지 30분 마다 반복해서 보내려고 한다.<br><br><br><br>수신자는 자신의 ISP 내부의 메일 서버에 메시지를 어떻게 얻을 수 있는가?<br>SMTP는 push 프로토콜인 반면 메시지를 얻는 것은 pull 동작이기 때문에 다른 프로토콜을 사용하여야 한다.<br><br><br>두 가지 대표적인 방법<br>
<br>HTTP

<br>웹 기반 전자메일이나 스마트폰 앱의 경우에 쓰인다.
<br>당연히 메일 서버는 SMTP 인터페이스와 HTTP 인터페이스 둘 다 가지고 있어야 한다.


<br>IMAP : RFC 3501에 정의된 인터넷 메일 접근 프로토콜
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.3-인터넷-전자메일\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.3 인터넷 전자메일/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:05 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210542924-1107ca75-eee8-45f6-829a-df0d0df81c15.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210542924-1107ca75-eee8-45f6-829a-df0d0df81c15.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.4 DNS: 인터넷의 디렉터리 서비스]]></title><description><![CDATA[ 
 <br><br><br><br><br>인터넷 호스트의 식별자 중 하나는 www.facebook.com, www.google.com 등의 호스트 이름(hostname)이다.<br><br><br>그러나 호스트의 이름은 인터넷에서의 호스트 위치에 대한 정보를 거의 제공하지 않는다.<br>또한, 가변 길이의 알파뉴메릭 문자로 구성되므로 라우터가 처리하는 데 어려움이 있다.<br><br><br>이러한 이유로 호스트는 흔히 말하는 IP 주소(IP address)로 식별된다.<br><br>
<br><br><br>IP 주소는 4 바이트로 구성되고, 계층구조를 갖는다.<br>
<br>121.7.106.83과 같은 형태로 0 ~ 255의 십진수로 표현하는 각 바이트는 점으로 구분한다.
<br>계층구조여서 왼쪽에서 오른쪽으로 조사함으로써, 그 호스트가 인터넷의 어디에 위치하는지에 대한 자세한 정보를 얻을 수 있다.<br>
(더 자세히는 4장에서 논의한다.)
<br><br>
<br>
<br><br><br>사람은 호스트 네임을 선호하지만, 라우터는 고정 길이의 계층구조를 가진 IP 주소를 선호한다.<br>
이 차이를 절충하기 위해 호스트 이름을 IP 주소로 변환해주는 디렉터리(directory) 서비스가 필요하다.
<br>이 서비스가 인터넷 DNS(Domain name system)의 주요 임무다. (hostname translations, address resolutions)<br><br><br><br>
<br>
DNS 서버들의 계층구조로 구현된 분산 데이터 베이스이다.<br>
implemented in hierarchy of many name servers

<br>
호스트가 분산 데이터 베이스로 질의하도록 허락하는 애플리케이션 계층 프로토콜이다.

<br><br><br>DNS 서버는 주로 BIND(Berkeley Internet Name Domain) 소프트웨어를 수행하는 유닉스(UNIX) 컴퓨터다.<br>DNS 프로토콜은 UDP 상에서 수행되고 포트 번호 53을 이용한다.<br><br>
<br><br><br><br>TCP의 경우 데이터 전송 시작 전에 3-way-handshaking 과정이 있는 반면, UDP는 연결 설정에 드는 비용이 없다.<br>
DNS는 신뢰성보다 속도가 더 중요한 서비스이기 때문에 TCP보다 UDP가 더 적합하다.
<br>또한, UDP는 512 bytes를 넘어가지 않는 패킷만 전송이 가능하고 오버헤드가 없어서 속도가 빠른데,<br>
DNS가 전송하는 데이터 패킷 사이즈가 매우 작으므로 UDP가 유리하다.<br>이때 단순히 패킷의 사이즈가 작다고 DNS가 UDP를 채택한 것은 아니고,<br>
전달하는 패킷의 크기가 작기 때문에 신뢰성이 보장되지 않아도 되기 때문이다. (못 받으면 다시 전달하면 된다.)<br><br><br><br>TCP는 호스트 간의 연결 상태를 유지한다.<br>이때 TCP의 패킷 안에는 여러 정보가 담겨 있지만, UDP는 어떤 정보도 기록하지 않고 유지할 필요도 없다.<br>
DNS 서버는 TCP보다 많은 클라이언트를 수용할 수 있으므로 연결 상태를 유지하지 않고 정보 기록을 최소화할 수 있는 UDP를 채택하였다.
<br><br>
<br><br><br>
<br>
같은 사용자 컴퓨터는 DNS 애플리케이션의 클라이언트를 수행한다.

<br>
브라우저는 URL로부터 호스트 이름을 추출하고 그 호스트 이름을 DNS 애플리케이션의 클라이언트에 보낸다.

<br>
DNS 클라이언트는 DNS 서버로 호스트 이름을 포함하는 질의를 보낸다. (client queries to DNS server)

<br>
DNS 클라이언트는 결국 호스트 이름에 대한 IP 주소를 받게 된다.

<br>
브라우저가 DNS로부터 IP 주소를 받으면,<br>
브라우저는 해당 IP 주소와 그 주소의 80번 포트에 위치하는 HTTP 서버 프로세스로 TCP 연결을 초기화한다.

<br><br><br>DNS는 위 예시에서 알 수 있듯이 추가 지연을 주지만,<br>
가까운 DNS 서버에 캐싱되어 있어서 평균 DNS 지연 뿐만 아니라 DNS 네크워크 트래픽 감소에 도움을 준다.<br><br>
<br><br><br><br>복잡한 호스트 이름을 가진 호스트는 하나 이상의 별명을 가질 수 있다.<br>relay1.west-coast.enterprise.com 같은 호스트 이름은 enterprise.com 같은 별칭을 가질 수 있다.<br>이 경우에 relay1.west-coast.enterprise.com를 정식 호스트 이름(canonical hostname)이라고 한다.<br>
DNS는 호스트의 IP 주소 뿐만 아니라 제시한 별칭 호스트 이름에 대한 정식 호스트 이름을 얻기 위해 이용될 수 있다.
<br><br><br><br>전자 메일 주소는 간단하지만 그 서버의 호스트 네임은 일반적으로 더 복잡하다.<br><br><br><br>
load balancing among the servers
<br><br><br>인기 있는 사이트는 여러 서버에 중복되어 있어서, 각 서버가 다른 종단 시스템에서 수행되고 다른 IP 주소를 갖는다.<br>이때 여러 IP 주소가 하나의 정식 호스트 이름과 연관되어 있다. DNS 데이터베이스는 이 IP 주소 집합을 갖고 있다.<br>클라이언트가 주소 집합으로 매핑하는 호스트 이름에 대한 DNS 질의를 하면, 서버는 IP 주소 집합 전체를 가지고 응답한다.<br><br><br>각 응답에서의 주소는 순환식으로 보낸다.<br>클라이언트는 대체로 주소 집합 내부의 첫 번째 IP 주소로 HTTP 요청 메시지를 보내므로, DNS의 순환 방식은 트래픽을 분산하는 효과를 낸다.<br><br><br><a data-tooltip-position="top" aria-label="https://www.nginx.com/resources/glossary/dns-load-balancing/" rel="noopener" class="external-link" href="https://www.nginx.com/resources/glossary/dns-load-balancing/" target="_blank">[참고] What is DNS Load Balancing?</a><br><br>
<br>
<br><br><br>사용자의 호스트에서 실행되는 어떤 애플리케이션이 호스트 이름을 IP 주소로 변환하려 한다고 가정하자.<br>과정은 다음과 같다.<br>
<br>
애플리케이션이 호스트 이름을 명시하여 DNS 클라이언트 호출한다.

<br>
사용자 호스트의 DNS는 네트워크에 질의 메시지를 보낸다.<br>
이때 모든 질의와 응답 메시지는 포트 53의 UDP 데이터그램으로 보내진다.

<br>
응답 메시지를 애플리케이션에 전달한다.

<br><br><br>DNS는 간단해보이지만 매우 복잡한데, 이는 전 세계에 분산된 많은 DNS 서버 뿐만 아니라<br>
DNS 서버와 질의를 하는 호스트 사이에서 어떻게 통신하는지를 명시하는 애플리케이션 계층 프로토콜로 구성되어 있다.<br><br>
<br><br><br>
why not centralize DNS?
<br>만약 DNS가 간단한 설계로 모든 매핑을 포함하는 하나의 인터넷 네임 서버를 갖고 있다면, 수많은 호스트를 가진 오늘날 다음과 같은 문제를 일으킬 수 있다.<br>
<br>서버의 고장 : 이 네임 서버가 고장 나면, 전체 인터넷이 작동하지 않는다. (single point of failure)
<br>트래픽 양의 과부하 : 단일 DNS 서버가 모든 질의를 해결해야 한다.
<br>먼 거리의 중앙 집중 데이터베이스: 단일 DNS 서버가 모든 질의 클라이언트로부터 '가까울' 수만은 없다. 즉, 멀면 멀수록 모든 질의가 느려진다.
<br>유지 관리

<br>단일 네임 서버는 모든 인터넷 호스트에 대한 레코드를 유지해야 한다.
<br>모든 새로운 호스트를 반영하기 위해 자주 갱신되어야 하고, 사용자에게 호스트를 등록할 수 있도록 허용하는 것과 관련된 인증 문제가 있다.


<br><br><br>요약하면 중앙 집중 데이터베이스는 확장성(scalability)이 전혀 없고, 결과적으로 DNS는 분산되도록 설계되어있다.<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210617280-e684c1b7-4f6c-4224-af7e-2e88334bdea2.png" alt="분산 계층 데이터 베이스" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>DNS는 많은 서버를 이용하고 이들을 계층 형태로 구성하며 전세계에 분산시킨다.<br><br><br><br><br>
<br>1000개 이상의 루트 서버 인스턴스가 세계에 흩어져 있다.
<br>루트 네임 서버는 TLD 서버의 IP 주소들을 제공한다.
<br>인터넷 할당 번호 관리기관 ICANN(Internet Corporation for Assigned Names and Numbers)에 의해 조정된다.
<br><br><br><br>
<br>Top-Level Domain, TLD
<br>com, org, net 같은 상위 레벨 도메인과 kr, uk 같은 모든 국가의 상위 레벨 도메인에 대한 TLD 서버가 있다.
<br>Authoritative(책임) DNS 서버에 대한 IP 주소를 제공한다.
<br><br><br><br>
<br>인터넷에서 접근하기 쉬운 호스트를 가진 모든 기관은 호스트 이름을 IP 주소로 매핑하는 공개적인 DNS 레코드를 제공해야 한다.

<br>기관의 책임 DNS 서버는 이 DNS 레코드를 갖고 있다.


<br>기관은 직접 자신의 책임 DNS 서버의 구현을 선택할 수 있고, 일부 서비스 제공자의 책임 DNS 서버에 이 레코드를 저장하도록 비용을 지불한다.
<br><br><br><br>
<br>로컬 DNS 서버는 서버들의 계층 구조에 엄격하게 속하지는 않지만 DNS 구조의 중심에 있다.
<br>ISP는 로컬 DNS 서버를 갖고, 로컬 DNS 서버로부터 IP 주소를 호스트에게 제공한다.
<br>대체로 호스트에 가까이 있기 때문에 지연이 적다.
<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210620114-71bda09c-0995-410a-b8e1-70ee1c5b76bd.png" alt="DNS 예시" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br><br>
<br><br>위 그림에서 cse.nyu.edu가 gaia.cs.umass.edu의 IP 주소를 원한다고 가정해보자.<br>
<br>자신의 로컬 DNS 서버에 질의를 보낸다. 이때 변환하고 싶은 호스트의 이름을 같이 보낸다.
<br>로컬 DNS 서버는 그 질의 메시지를 루트 DNS 서버에게 전달한다.
<br>루트 DNS 서버는 edu를 인식하고, edu에 대한 책임을 가진 TLD 서버의 IP 주소 목록을 로컬 DNS 서버에 보낸다.
<br>로컬 DNS 서버는 TLD 서버에 질의를 보낸다.
<br>TLD 서버는 umass.edu를 인식하고, dns.umass.edu로 이름 지어진 책임 DNS 서버의 IP 주소로 응답한다.
<br>로컬 DNS 서버는 작접 책임 DNS 서버로 질의 메시지를 다시 보낸다.
<br>최종 gaia.cs.umass.edu의 IP 주소를 응답한다.
<br>호스트에 최종 IP 주소를 응답한다.
<br><br><br>여기서는 총 8번의 DNS 메시지가 보내졌다.<br>일반적으로 TLD 서버는 위의 예시와 같이 책임 DNS 서버를 알지 않고, 책임 DNS 서버를 아는 중간 DNS 서버를 알고 있다.<br>즉, 해당 질의 과정 까지 포함되면 전체 10번의 메시지를 보내게 된다.<br><br><br>위 예는 재귀적 질의와 반복적 질의를 사용한다.<br>cse.nyu.edu로부터 dns.nyu.edu로 보내는 질의는 자신을 필요한 매핑을 대신하여 얻도록 dns.nyu.edu에 요구하므로 재귀적 질의이고,<br>
나머지는 반복적 질의다.<br><br>
<br><br>아래 그림은 모든 질의가 재귀적인 DNS 질의 사슬을 보여준다.<br><img src="https://user-images.githubusercontent.com/76640167/210622856-0c967585-6ce3-45c7-97bd-c1ed6e3143fc.png" alt="재귀적 질의" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br><br>
<br><br>
일반 질의는 전형적으로 반복적 질의를 따른다.
<br>
<br>재귀적 질의에서는 높은 계층에 있는 DNS server가 책임져야 하는 것들이 많다.

<br>puts burden of name resolutions on contacted name server
<br>heavy load at upper levels of hierarchy


<br>중요한 infra를 지키는 것이 훨씬 낫기 때문에, 중요한 root name server 보단 default name server가 일을 더 하는 것이 좋다.
<br><br>
<br><br><br>실제로는 DNS 지연 성능 향상과 네트워크의 DNS 메시지 수를 줄이기 위해 캐싱(caching)을 사용한다.<br>
질의 사슬에서 DNS 서버는 DNS 응답을 받았을 때 로컬 메모리에 응답에 대한 정보를 저장할 수 있다.
<br><br><br>만약 호스트의 이름과 IP 주소 쌍이 DNS 서버에 저장되고 다른 호스트 이름으로부터 같은 질의가 DNS 서버로 도착한다면,<br>
DNS 서버는 호스트 이름에 대한 책임이 없을 때조차 원하는 주소를 제공할 수 있다.<br>호스트 DNS와 IP 사이의 매핑과 호스트는 영구적이지 않기 때문에 어떤 기간(TTL, Time to Live) 이후에 저장된 정보를 제거한다.<br>로컬 DNS 서버는 구체적인 IP 주소 이외에도 TLD 서버의 IP를 저장하여 루트 DNS 서버를 우회할 수 있게 한다.<br><br>
<br>
<br><br><br>각 DNS는 하나 이상의 자원 레코드를 가진 메시지로 응답한다.<br><br><br><br>DNS 서버들은 호스트 이름을 IP 주소로 매핑하기 위한 자원 레코드(Resource Records)를 저장한다.<br>자원 레코드는 다음과 같은 필드를 포함하는 4개의 Tuple로 되어 있다.<br>(Name, Value, Type, TTL)
복사<br>TTL(Time to Live)은 자원 레코드의 생존 기간이다.<br>Name과 Value는 Type을 따른다. 즉, Type에 따라서 Name과 Value에 대한 semantic(해석법)이 달라진다.<br><br><br><br>
Address<br>
Type A 레코드는 표준 호스트 이름의 IP 주소 매핑을 제공한다.
<br>
<br>Name : 호스트 이름(hostname)
<br>Value : 호스트 이름에 대한 IP 주소
<br><br><br><br>
Name Server
<br>
<br>Name : 도메인(domain)
<br>Value : 도메인 내부의 호스트에 대한 IP 주소를 얻을 수 있는 방법을 아는 책임 DNS 서버의 호스트 이름
<br><br><br><br>
Canonical NAME
<br>
<br>Name : 정식 호스트 이름의 alias name
<br>Value : 별칭 호스트 이름 Name에 대한 정식 호스트 이름
<br><br><br><br>
Mail eXchange
<br>
<br>Value : 별칭 호스트 이름 Name을 갖는 메일 서버의 정식 이름
<br>MX 레코드는 메일 서버의 호스트 이름이 간단한 별칭을 갖는 것을 허용한다.
<br><br><br>메일 서버의 정식 이름을 얻기 위해서는 MX 레코드에 대한 질의를 해야 하고, 다른 서버의 정식 이름을 얻기 위해선 CNAME 레코드에 대한 질의를 한다.<br><br><br>DNS 서버가 특별한 호스트 이름에 대한 책임 서버이면, 그 DNS 서버는 호스트 이름에 대한 Type A 레코드를 포함한다.<br>서버가 호스트 이름에 대한 책임 서버가 아니라면, 그 서버는 호스트 이름을 포함하는 DNS 서버의 IP 주소를 제공하는 Type A 레코드도 포함할 것이다.<br><br>
<br>
<br><br><br>DNS의 요청과 응답 메시지는 모두 아래 그림과 같은 포맷을 갖고 있다.<br><img src="https://user-images.githubusercontent.com/76640167/210725479-3cc2dfe9-5ffd-49f8-9385-5cc244b7c2e6.png" alt="DNS 메시지" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br><br>처음 12 byte의 헤더 영역 : 여러 필드를 갖고 있다.<br>
<br>
첫 필드는 질의를 식별하는 16 bit의 숫자이다.<br>
이 식별자는 질의에 대한 응답 메시지에 복사되어, 클라이언트가 보낸 질의와 수신된 응답 간의 일치를 식별하게 한다.

<br>
플래그(flag) 필드에는 여러 개의 플래그가 있다.

<br>1 비트의 질의/응답 플래그는 메시지가 질의인지 응답인지 구분하게 한다.
<br>1 비트의 책임 플래그는 DNS 서버가 질의 이름에 대해 책임 서버일 때 응답 메시지에 설정된다.
<br>1 비트의 재귀 요구 플래그는 DNS 서버가 레코드를 갖지 않을 때 재귀적 질의를 수행하기를 클라이언트가 원할 때 설정된다.
<br>1 비트로 된 재귀 가능 필드는 DNS 서버가 재귀 질의를 지원하면 응답에 설정된다.


<br>
나머지 4개의 '개수' 필드는 헤더 다음에 오는 데이터 영역의 네 가지 타입의 발생 횟수를 나타낸다.

<br><br>
<br>질문 영역

<br>현재 질의에 대한 정보를 포함한다.
<br>질의되는 이름을 포함하는 이름 필드와, 이름에 대해 문의되는 질문 타임을 나타내는 타입 필드를 나타낸다. (A, NS 등)


<br>답변 영역

<br>원래 질의된 이름에 대한 자원 레코드를 포함한다. (value, TTL)
<br>여러 개의 자원 레코드를 보낼 수 있는데, 하나의 호스트 이름이 여러 개의 IP를 가질 수 있기 때문이다. (중복 웹 서버)


<br>책임 영역

<br>다른 책임 서버의 레코드를 포함한다.


<br>추가 영역

<br>다른 도움이 되는 레코드를 갖고 있다.
<br>예를 들어, MX 질의에 대한 응답에서 응답 필드는 전자메일 서버의 정식 호스트 이름을 제공하는 자원 레코드를 갖고 있고,<br>
추가 영역은 정식 호스트 이름에 대한 IP 주소를 제공하는 A 레코드를 포함한다.


<br><br>
<br><br><br>도메인 네임 networkutopia.com을 등록 기관(DNS registrar)에 등록한다고 가정해보자.<br>
등록 기관(DNS registrar)은 도메인 네임의 유일성을 확인하고,<br>
그 도메인 네임을 DNS 데이터베이스에 넣고, 그 서비스에 대한 요금을 받는 상업 기관이다.
<br>이전에는 작은 등록기관이 독점했었지만, 이제는 많은 기관이 경쟁하고 ICANN이 이러한 여러 등록기관을 승인해준다.<br><br><br>도메인 네임을 어떤 등록기관에 등록할 때 등록 기관에 주책임 서버와 부책임 서버의 이름과 IP 주소를 등록기관에 제공해야 한다.<br>
<br>주책임 서버 : dns1.networkutopia.com / 주책임 서버 IP : 212.2.212.1
<br>부책임 서버 : dns2.networkutopia.com / 부책임 서버 IP : 212.2.212.2
<br>위와 같다고 가정하자.<br><br><br>이 두 책임 DNS 서버 각각에 대해 등록 기관은 Type NS와 Type A 레코드가 TLD com 서버에 등록되도록 확인한다.<br>특히 주책임 서버의 경우 다음 두 개의 자원 레코드를 DNS 서버에 삽입한다.<br>(networkutopia.com, dns1.networkutopia.com, NS)
(dns1.networkutopia.com, 212.212.212.1, A)
복사<br><br><br>또한, Type A 레코드와 메일 서버에 대한 Type MX 자원 레코드가 책임 DNS 서버에 등록되는 것을 확인한다.<br>이러한 모든 단계가 끝나면 여러 사람들이 웹 사이트를 방문할 수 있고, 전자메일을 보낼 수 있게 된다.<br><br>
<br><br><br><br>공격자는 DNS 루트 서버로 다량의 패킷을 보내려는 시도를 하여 다른 DNS 질의들이 응답을 받지 못하게 하려 한다.<br>실제로 이 일이 일어났지만, 많은 DNS 루트 서버들은 루트 서버로 향하는 공격자가 사용한 ICMP 핑 메시지를 블록하도록 형상화한 패킷 필터로 보호되었고,<br>
대부분의 로컬 DNS 서버가 최상위 도메인 서버들의 IP 주소들을 캐싱하고 있어서 피해가 거의 없었다.<br><br><br>즉, 더 효과적인 공격은 최상위 도메인 서버를 공격하는 것이고, 실제로 최상위 도메인 서비스 제공자 Dyn에 이러한 일이 발생했다.<br>이는 유명 애플리케이션들이 무차별 교란되는 결과를 야기했다.<br><br><br><br>공격자는 DNS 서버로 가짜 응답을 보내어 그 서버가 자신의 캐시에 가짜 레코드를 받아들이도록 속임수를 쓴다.<br>이러한 공격은 웹 사용자들을 공격자의 웹사이트로 유도하는 데 이용될 수 있다.<br>이러한 공격을 막기 위해 DNS 보안 확장 프로토콜이 개발되어 사용되고 있다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.4-dns_-인터넷의-디렉터리-서비스\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.4 DNS_ 인터넷의 디렉터리 서비스/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:06 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210617280-e684c1b7-4f6c-4224-af7e-2e88334bdea2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210617280-e684c1b7-4f6c-4224-af7e-2e88334bdea2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.5 P2P 파일 분배]]></title><description><![CDATA[ 
 <br><br>
P2P 구조는 항상 켜져있는 인프라스트럭처 서버에 최소한으로 의존하고, 간헐적으로 연결되는 호스트 쌍들(피어, peer)이 서로 직접 통신한다.
<br>
<br>클라이언트-서버 파일 분배에서 서버는 파일 복사본을 각 클라이언트에게 보내려면 서버에게 커다란 부하를 주고, 많은 양의 서버 대역폭을 소비한다.
<br>P2P 파일 분배에서 각 피어는 수신한 파일의 임의의 부분을 다른 피어들에게 재분배할 수 있어서 서버의 분배 프로세스를 도울 수 있다.
<br><br><br>2020년에 가장 인기 있는 P2P 파일 분배 프로토콜은 비트 토렌트(BitTorrent)다.<br><br>
<br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210734676-39d266cf-181b-4a33-9ed4-7f518a16ad19.png" alt="파일 분배 예" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br>서버와 피어들은 접속 링크로 인터넷에 연결되어 있다.<br>
<br>서버의 접속 링크 업로드 속도를 u(s)로, i번째 피어의 접속 링크 업로드 속도는 u(i)로,<br>
그리고 i번째 피어의 접속 링크 다운로드 속도는 d(i)로 나타낸다.
<br>또한, 분배되는 파일의 크기는 F bit로, 파일을 얻고자 하는 피어들의 수는 N으로 나타낸다.
<br><br><br>분배 시간은 모든 N개의 피어들이 파일의 복사본을 얻는데 걸리는 시간이다.<br>다음 분배 시간에 대한 분석에서 클라이언트-서버와 P2P 구조 모두의 경우, 인터넷 코어가 풍부한 대역폭을 갖고 있다는 간단한 가정을 하며,<br>
이는 모든 병목 현상은 다른 네트워크 애플리케이션에 참여하지 않아서 이들의 모든 업로드와 다운로드 접속 대역폭은 이 파일 분배에 모두 사용된다고 가정한다.<br><br>
<br><br><br>
<br>서버는 파일 복사본을 N개의 피어 각각에게 전송해야 한다. 따라서 서버는 NF 비트를 전송해야 한다.

<br>즉, 서버가 파일을 분배하는 시간은 적어도 NF/u(s)이다.


<br>d(min)이 가장 낮은 다운로드 속도를 가진 피어의 다운로드 속도를 나타낸다고 하자.

<br>가장 낮은 속도를 가진 피어는 F/d(min)초보다 적은 시간에 파일의 모든 F 비트를 얻을 수 없다.
<br>즉 최소 분배 시간은 F/d(min)이다.


<br>즉, 분배 시간을 D(cs)라고 하면 다음과 같은 수식을 얻을 수 있다.<br>D(cs) ≧ max{ NF/u(s) , F/d(min)} 
복사<br><br><br>위 식에서 충분히 큰 N에 대해 클라이언트-서버 분배 시간은 NF/u(s)로 주어진다는 사실을 알 수 있다. 즉, N에 따라 선형 증가한다.<br><br>
<br><br><br>여기서는 각 피어들이 서버가 파일을 분배하는 데 도움을 줄 수 있다.<br>특히 한 피어가 파일 데이터 일부를 수신할 때, 피어는 그 데이터를 다른 피어들에게 재분배하는 데 자신의 업로드 용량을 이용할 수 있다.<br><br><br>
<br>분배가 시작되면 서버만이 파일을 갖고 있다.

<br>이 파일이 피어 커뮤니티에 도달할 수 있도록 하기 위해, 서버는 적어도 한 번 접속 링크로 파일의 각 비트를 보내야 한다.
<br>따라서 최소 분배 시간은 적어도 F/u(s)다.<br>
(서버가 한 번 보낸 비트는 서버가 다시 보낼 필요가 없는데, 이는 피어들이 그들 사이에서 재분배할 수 있기 때문이다.)


<br>클라이언트-서버 구조와 마찬가지로 다운로드 속도가 가장 낮은 피어는 F/d(min)초보다 적은 시간 안에 파일의 모든 F 비트를 얻을 수 없다.

<br>따라서 최소 분배시간은 적어도 F/d(min)이다.


<br>마지막으로, 시스템의 전체 업로드 용량은 전체적으로 서버의 업로드 속도와 각 피어들의 속도를 더한 것이다. 이를 u(total)이라 하자.

<br>시스템은 각 피어들 각각에게 F 비트를 전달해야 한다. 이는 u(total)보다 빠르게 할 수 없다.
<br>따라서 최소 분배 시간은 NF/u(total)이다.


<br><br><br>즉, 분배시간을 D(p2p)라고 하면 다음과 같은 수식을 얻을 수 있다.<br>D(p2p) ≧ max{ F/u(s) , F/d(min), NF/u(total) 
복사<br><br>
<br><br>위 수식들에서 하한값은 서버-클라이언트 구조에서 서버가 전송을 스케줄링 하거나,<br>
P2P 구조에서는 각 피어가 비트를 수신하자마자 그 비트를 재분배할 수 있다고 가정하면(실제로는 chunk가 재분배된다.),<br>
식의 하한값을 최소 분배시간으로 채택할 수 있다.<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210739434-43b60eba-5646-4f4d-bfac-91605965f0f1.png" alt="분배 시간" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br><br>위 그래프를 통해 임의의 피어 수 N에 대해 클라이언트-서버 구조보다 P2P 구조가 더 시간이 적다는 것을 볼 수 있다.<br>따라서 P2P 구조를 가진 애플리케이션은 자가 확장성을 갖는다.<br><br>
<br>
<br><br><br>
비트토렌트(BitTorrent)는 파일 분배를 위한 인기 있는 P2P 프로토콜이다.
<br><br>
<br><br><br>
비트토렌트 용어로 특정 파일의 분배에 참여하는 모든 피어의 모임을 토렌트(torrent)라고 부른다.
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210740090-9342a5c1-7bbc-4420-88cb-59fdefcf293c.png" alt="비트 토렌트" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br><br>토렌트에 참여하는 피어들은 서로에게서 같은 크기의 청크(chunk)를 다운로드한다. (일반적으로 256KB)<br>
<br>처음으로 가입하면 그 피어에는 청크가 없지만, 시간이 지나면 점점 많은 청크를 쌓을 수 있다.<br>
(accumulate chunks over time from other peers)
<br>피어가 청크를 다운로드할 때 또한 청크를 다른 피어들에게 업로드한다.
<br>일단 한 피어가 전체 파일을 얻으면 토렌트를 떠나거나, 토렌트에 남아서 다른 피어들로 청크를 계속해서 업로드할 수 있다.
<br><br>
<br><br><br>각 토렌트는 트래커(traker)라고 부르는 인프라스트럭처 노드를 갖고있다.<br>한 피어가 토렌트에 가입할 때 트래커에 자신을 등록하고 주기적으로 자신이 아직 토렌트에 있음을 알려, 트래커는 토렌트에 있는 피어들을 추적할 수 있다.<br><br><br>위의 그림을 예시로 보자.<br>새로운 피어 앨리스가 토렌트에 가입하면<br>
트래커는 참여하고 있는 피어 집합에서 임의로 피어들의 부분집합(정확히는 50)을 선택하여 이 50개 피어들의 IP 주소를 앨리스에게 보낸다.<br>이 피어들의 목록을 얻고 나서, 앨리스는 이 목록에 있는 모든 피어와 동시에 TCP 연결을 맺고,<br>
성공적으로 맺은 피어를 이웃 피어(neighbors)라고 부른다.<br><br><br>
The peers fluctuate over time
<br>churn : peers may come and go<br>시간이 지남에 따라 피어들 중 일부는 떠나고, 다른 피어들이 앨리스와 TCP 연결을 시도하고, 피어의 이웃 피어들은 시간에 따라 변동한다.<br><br>
<br><br><br>
requesting chunks: rarest first
<br><br><br>어느 임의의 시간 안에 앨리스는 청크의 일부를 가질 것이고, 이웃들이 어느 청크를 가지고 있는지를 알게 될 것이다.<br>앨리스는 이러한 정보를 바탕으로 다음 2가지 결정을 한다.<br>
<br>이웃으로부터 어느 청크를 먼저 요구할 것인가?
<br>이웃들 중 어느 피어에게 청크를 요청할 것인가?
<br><br><br>이때 rarest first(가장 드문 것 먼저) 기술을 사용한다.<br>갖고 있지 않은 청크 중에서, 이웃 가운데 가장 드문 청크를 결정하고 이를 먼저 요구하는 것이다.<br>이 방법을 통해 가장 드문 청크들은 더 빨리 재분배될 수 있어서 각 청크의 복사본 수가 대략적으로 동일해질 수 있다.<br><br>
<br><br><br>
sending chunks: tit-for-tat
<br><br><br>어느 요청에 응답할지 결정할 때 앨리스가 가장 빠른 속도로 그녀에게 데이터를 제공하는 이웃에게 우선순위를 주는 것이다.<br>
<br>특히, 계속해서 비트를 수신하는 속도를 측정하고 가장 빠르게 전송하는 4개의 피어를 결정하고, 이 4개의 피어에게 청크를 보냄으로써 보답한다.
<br>이는 10초마다 계산하여 집합을 수정한다.
<br>비트 토렌트 용어로 4개의 피어는 활성화되었다(unchoked)고 한다.<br><br><br>40초마다 위 피어를 제외하고 임의의 피어에게 청크를 보낸다.<br>비트 토렌트 용어로 이 피어는 낙관적으로 활성화되었다(optimistically unchoked)고 한다.<br>
<br>즉, 이제 앨리스는 임의의 피어에게 활성화될 수 있고, 활성화가 된다면 임의의 피어도 앨리스에게 활성화될 수 있다.
<br>임의의 선택을 통해 고정된 피어들과만 청크를 교역하는 것이 아니라 여러 피어와 교역할 수 있게 된다.
<br><br><br>이러한 5개의 피어 외의 모든 이웃 피어는 비활성화되어 어떤 청크도 교역하지 않는다. (choked by Alice = do not receive chunks from her)<br><br><br><br><br><br>비트 토렌트는 여기서 논의하지 않은 여러 기법들도 갖고 있다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.5-p2p-파일-분배\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.5 P2P 파일 분배/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:07 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210734676-39d266cf-181b-4a33-9ed4-7f518a16ad19.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210734676-39d266cf-181b-4a33-9ed4-7f518a16ad19.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.6 비디오 스트리밍과 콘텐츠 분배 네트워크]]></title><description><![CDATA[ 
 <br><br><br><br><br>비디오는 이미지의 연속으로서 일반적으로 초당 24개에서 30개의 이미지로 일정한 속도로 표시된다.<br>압축되지 않은 디지털 인코딩된 이미지는 픽셀 단위로 구성되며, 각 픽셀은 휘도와 색상을 나타내는 여러 비트들로 인코딩된다.<br><br><br>비디오의 중요한 특징은 압축될 수 있다는 것인데, 비디오 품질과 비트 전송률은 서로 반비례한다.<br>오늘날의 상용 압축 알고리즘은 근본적으로 원하는 모든 비트 전송률로 비디오를 압축할 수 있다. (비트 전송률이 높을수록 이미지 품질이 좋다.)<br><br><br>네트워킹 측면에서 비디오의 가장 두드러진 특성은 높은 비트 전송률이다.<br>인터넷 비디오는 일반적으로 고화질 동영상을 스트리밍 하기 위해 100 kbps에서 4 Mbps 이상으로 구성된다.<br>4K 스트리밍은 10 Mbps 이상의 비트 전송률로 예상된다. 이는 하이엔드 동영상의 경우 트래픽과 스토리지 용량이 엄청나게 필요함을 의미한다.<br><br><br>연속 재생을 제공하기 위해, 네트워크는 압축된 비디오의 전송률 이상의 스트리밍 애플리케이션에 대한 평균 처리량을 제공해야 한다.<br>→ 압축을 사용하여 동일한 비디오를 여러 버전의 품질로 만들 수 있다.<br><br>
<br>
<br><br><br>
HTTP 스트리밍에서 비디오는 HTTP 서버 내의 특정 URL을 갖는 일반적인 파일로 저장된다.
<br>
<br>클라이언트는 서버에게 TCP 연결을 설립하고 해당 URL에 대한 HTTP GET 요청을 발생시킨다.
<br>서버는 기본 네트워크 프로토콜 및 트래픽이 허용되는 대로 HTTP 응답 메시지 내에서 비디오 파일을 전송한다.
<br>애플리케이션 버퍼에 전송된 바이트가 저장된다.
<br>버퍼의 바이트 수가 미리 정해진 임계값을 초과하면 재생을 시작한다.
<br>특히, 버퍼에서 주기적으로 비디오 프레임을 가져와 프레임을 압축 해제한 다음 사용자의 화면에 표시한다.<br><br><br><br>가용 대역폭이 달라도 똑같이 인코딩된 비디오를 전송 받는다는 문제가 있다.<br>이 문제로 인한 HTTP 기반 스트리밍인 DASH(Dynamic Adaptive Streaming over HTTP)가 개발되었다.<br><br>
<br><br><br>
비디오는 여러가지 버전으로 인코딩 되며, 각 버전은 비트율과 품질 수준이 서로 다르다.
<br>클라이언트는 동적으로 서로 다른 버전의 비디오를 몇 초 분량의 길이를 갖는 비디오 조각 단위로 요청한다.<br>가용 대역폭이 충분할 때는 높은 비트율의 비디오 버전을 요청하며, 가용 대역폭이 적을 때는 낮은 비트율의 비디오 버전을 요청한다.<br>즉, 클라이언트는 자신의 상황에 알맞은 비디오 버전을 요청한다.<br><br><br>각 비디오 버전은 HTTP 서버에 서로 다른 URL을 가지고 저장된다.<br>HTTP 서버는 비트율에 따른 각 버전의 URL을 제공하는 매니페스트(manifest) 파일을 갖고 있다.<br>클라이언트는 이 매니페스트 파일을 제공받고,<br>
이에 따라 매번 원하는 버전의 비디오 조각 단위를 선택하여 HTTP GET 요청 메시지에 URL과 byte-range를 지정하여 요청한다.<br><br><br>궁극적으로 DASH는 클라이언트가 서로 다른 품질 수준을 자유롭게 변화시킬 수 있도록 허용한다.<br><br>
<br>
<br><br><br><br>
단일 거대 데이터 센터를 구축하고 모든 비디오 자료를 데이터 센터에 저장한 뒤, 전 세계의 사용자에게 비디오 스트림을 데이터 센터로부터 직접 전송한다.
<br><br><br><br>
<br>클라이언트가 데이터 센터로부터 먼 지점에 있는 경우 다양한 통신 링크와 ISP를 거치게 되고,<br>
이 링크들 중 하나라도 비디오 소비율 보다 낮은 전송 용량을 갖는 경우 병목현상이 발생한다.
<br>인기 있는 비디오는 같은 통신 링크를 통해 여러 번 반복적으로 전송될 것이다. 동일한 바이트를 전송하는 데에 반복 비용을 지불하게 된다.
<br>한 번의 장애로 전체 서비스가 중단될 수 있다.
<br>이러한 문제를 해결하기 위해 대부분의 비디오 스트리밍 회사들은 콘텐츠 분배 네트워크(CDN)를 이용한다.<br><br>
<br><br><br>
CDN은 다수의 지점에 분산된 서버들을 운영하며, 비디오 및 다른 형태의 웹 콘텐츠 데이터의 복사본을 이러한 분산 서버에 저장한다.
<br>사용자는 최적의 사용자 경험을 제공받을 수 있는 지점의 CDN 서버로 연결된다.<br>CDN은 구글처럼 사설 CDN일 수도 있으며, 제 3자가 운영하는 CDN을 통해 서비스될 수도 있다.<br><br><br><br>두 개의 철학 중 하나를 채용한다.<br>
<br>Enter Deep
<br>Bring Home
<br><br><br><br>
push CDN servers deep into many access networks
<br>Akamai에 의해 주창된 것으로서 서버 클러스터를 세계 곳곳의 접속 네트워크에 구축함으로써 ISP의 접속 네트워크로 깊숙이 들어가는 것이다.<br>즉, 최대한 서버를 사용자 근처에 위치시켜 링크 및 라우터를 거치는 횟수를 줄여 지연시간 및 처리율을 개선하는 것이다.<br><br><br><br>
smaller number (10’s) of larger clusters in POPs near (but not within) access networks
<br>Limelight와 다른 회사들에 의해 적용된 것으로, 좀 더 적은 수의 핵심 지점에 큰 규모의 서버 클러스터를 구축하여 ISP를 Home으로 가져오는 개념이다.<br>접속 ISP에 연결하는 대신, 일반적으로 CDN들은 그들의 클러스터를 인터넷 교환 지점(IXP)에 배치한다.<br><br><br>이에 따라 Enter Deep보다 처리율(throughput)은 더 낮고 delay가 더 걸릴 수 있지만, 회사의 입장에서는 유지 보수하기에 편하며, 비용이 적게 든다.<br><br><br>CDN은 콘텐츠의 복사본을 이들 클러스터에 저장하는데 모든 복사본을 유지하지는 않는다.<br>어떤 비디오는 인기가 거의 없거나 특정 국가에서만 인기가 있을 수 있기 때문이다.<br><br><br>실제로 CDN은 클러스터에 대해 사용자의 요청이 오면 중앙 서버나 다른 클러스터로부터 전송받아 사용자에게 서비스하는 동시에 복사본을 만들어 저장하는 pull 방식을 이용한다.<br>저장 공간이 가득 차게 되면 자주 사용되지 않는 비디오 데이터는 삭제된다.<br><br>
<br><br><br>
<br>사용자가 URL을 지정하여 비디오를 요청한다.
<br>CDN은 그 요청을 가로채 클라이언트에게 가장 적당한 CDN 클러스터를 선택한다.
<br>클라이언트의 요청을 해당 클러스터의 서버로 연결한다.
<br>요청을 가로챌 때 CDN은 DNS를 활용한다. 이를 DNS redirection이라고 한다.<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210764950-3e99de26-f101-486c-8e59-0269e7769373.png" alt="CDN DNS" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br>
<br>사용자가 URL을 입력한다.
<br>사용자의 호스트는 URL의 host name에 대한 질의를 로컬 DNS로 보낸다.
<br>로컬 DNS는 host name의 책임 DNS 서버로 질의를 전달한다.<br>
책임 DNS 서버는 해당 질의를 CDN 서버로 연결하기 위해 CDN 서버의 책임 DNS 서버의 IP를 전달한다.
<br>로컬 DNS는 CDN 서버의 책임 DNS로 질의를 보내고, CDN 콘텐츠 서버의 IP 주소를 로컬 DNS 서버로 응답한다.<br>
이때 클라이언트가 콘텐츠를 전송받게 될 서버가 결정된다.
<br>로컬 DNS 서버는 사용자 호스트에게 CDN 서버의 IP 주소를 알려준다.
<br>클라이언트는 호스트가 알게된 IP 주소로 HTTP 혹은 DASH 프로토콜을 통해 비디오를 받아온다.
<br><br><br><br>위 CDN이 DNS를 통해 가로채는 과정에서 CDN은 클라이언트의 로컬 DNS 서버의 IP 주소를 알게된다. 이 IP 주소에 기초해 최선의 클러스터를 선택한다.<br><br><br><br>
지리적으로 가장 가까운 클러스터를 할당한다.
<br>사용자 지리정보 데이터베이스를 이용하면 얻은 IP 주소를 지리적으로 매핑할 수 있고, 가장 가까운 클러스터를 선택하는 것이다.<br>대부분 잘 동작하나, 지리적으로 가까운 클러스터가 네트워크 경로의 길이 홉의 수에 따라 가장 가까운 클러스터가 아닐 수 있고,<br>
가까운 로컬 DNS 서버를 이용하고 있지 않을 수 있기 때문에 잘 동작하지 않을 수 있다.<br><br><br><br>
실시간 측정
<br>클러스터와 클라이언트 간의 지연 및 손실 성능에 대한 주기적인 실시간 측정을 통해 현재 네트워크 상황을 반영하여 최선의 클러스터를 선택하는 것이다.<br>문제는 많은 로컬 DNS 서버가 이러한 측정에 응답을 하지 않도록 설정되어 있다.<br><br>
<br>
<br><br><br><br><img src="https://user-images.githubusercontent.com/76640167/210767665-e80ff1b4-fbc3-468b-ae73-00165867631d.png" alt="넷플릭스" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br>콘텐츠 수집 : 영화를 수집하고 처리한다. 영화의 스튜디오 마스터 버전을 받아서 아마존 클라우드 시스템의 호스트에 업로드한다.
<br>콘텐츠 처리 : 아마존 클라우드 시스템의 기기에서는 데스크톱 컴퓨터, 스마트폰, TV에 견결된 게임 콘솔 등 고객들의 다양한 플레이어 기기 사양에 적합하도록 각 영화의 여러가지 형식의 비디오를 생성한다.<br>
DASH를 이용하여 각 형식별로 다양한 비트율의 여러가지 버전을 생성한다.
<br>CDN으로 버전 업로드 : 영화의 다양한 버전이 생성되면 아마존 클라우드 시스템의 호스트는 이러한 버전을 CDN으로 업로드할 수 있다.
<br><br><br>자체 CDN을 구축하기 위해 넷플릭스는 IXP 및 거주용 ISP 자체에서 서버 랙(rack)을 설치했다.<br>현재 IXP 위치에 200대 이상의 서버 렉과 서버 랙을 수용하는 수백 개의 ISP 장소도 보유하고 있다.<br>각각의 랙 서버에는 10 Gbps 이더넷 포트와 100 테라바이트 이상의 스토리지가 있다.<br><br><br>넷플릭스는 푸시 캐싱(push caching)을 사용하여 IXP 및 ISP CDN 서버를 채운다.<br>전체 라이브러리를 보유할 수 없는 위치의 경우, 매일매일 가장 많이 결정되는 비디오만 푸시한다.<br><br><br>
<br>사용자가 재생할 영화를 선택한다.
<br>아마존 클라우드에서 실행 중인 넷플릭스 소프트웨어가 영화 사본을 갖고 있는 CDN 서버를 결정한다.
<br>영화가 있는 서버 중에서 클라이언트 요청에 대한 최적의 서버를 결정한다.
<br>일반적으로 로컬 ISP가 CDN 서버 랙(rack)이 있다면 해당 CDN을 사용하거나, 근처 CDN 서버가 있는 IXP를 사용한다.
<br>클라이언트는 요청된 영화의 다른 버전에 대한 URL을 가진 메니페스트 파일과 특정 서버의 IP 주소를 보낸다.
<br>클라이언트와 해당 CDN 서버는 독점 버전의 DASH를 이용하여 직접 상호작용한다.
<br><br><br>넷플릭스는 자체 CDN을 사용하고 있기 때문에 DNS redirection을 사용할 필요가 없다.<br>대신 아마존 클라우드에서 실행되는 것처럼 넷플릭스 소프트웨어는 클라이언트에게 특정 CDN 서버를 사용하도록 알려준다.<br><br><br>또한 넷플릭스 CDN은 풀 캐싱보다 푸시 캐싱을 사용한다.<br>콘텐츠는 캐시 미스 중에 동적으로 사용되는 것이 아니라 사용량이 적은 시간 중 예약된 시간에 서버에 푸시한다.<br><br>
<br><br><br>넷플릭스와 마찬가지로 자체 CDN을 사용한다.<br>구글 역시 사용자를 특정 서버 클러스터와 연결하는 데 DNS를 사용한다.<br><br><br>대부분의 경우 클러스터 선택 정책은 클라이언트와 클러스터간의 RTT가 가장 적은 곳을 선택하는 것이다.<br>때로는 작업 부하를 위해 더 멀리 있는 CDN을 선택하기도 한다.<br><br><br>유튜브는 HTTP 스트리밍을 채용하여 사용자가 직접 버전을 선택하게 했다.<br>재생 위치 조정과 조기 종료로 인한 대역폭과 서버 자원의 낭비를 줄이기 위해,<br>
유튜브는 HTTP byte-range 헤더를 이용해 목표한 분량의 선인출 데이터 이후에 추가로 전송되는 데이터 흐름을 제한한다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.6-비디오-스트리밍과-콘텐츠-분배-네트워크\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.6 비디오 스트리밍과 콘텐츠 분배 네트워크/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:08 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210764950-3e99de26-f101-486c-8e59-0269e7769373.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210764950-3e99de26-f101-486c-8e59-0269e7769373.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.7 소켓 프로그래밍: 네트워크 애플리케이션 생성]]></title><description><![CDATA[ 
 <br><br>네트워크 애플리케이션을 생성할 때는 두 프로그램, 클라이언트와 서버 프로그램을 작성해야 한다.<br>두 프로그램을 실행하면 프로세스가 생성되고, 두 프로세스가 소켓으로부터 읽고 쓰기를 통해 서로 통신한다.<br><br>
<br><br>클라이언트 - 서버 애플리케이션에는 두 가지 형태가 있다.<br><br><br>
1️⃣ HTTP 등의 RFC에 정의된 표준 프로토콜을 구현하는 클라이언트-서버 애플리케이션
<br>이 애플리케이션을 구현할 때 그 프로토콜과 연관된 port를 사용하여야 한다.<br><br><br>
2️⃣ 개인의 독점적인 네트워크 애플리케이션으로 RFC 또는 다른 곳에 공식적으로 출판되지 않은 애플리케이션 계층 프로토콜을 채택하여 구현하는 애플리케이션
<br>다른 독립 개발자는 이 애플리케이션과 상호작용하는 코드를 개발할 수 없다. 이 애플리케이션을 구현할 때는 잘 알려진 포트번호를 사용하지 않도록 유의해야 한다.<br>개발자는 TCP, UDP 프로토콜 중 어떤 프로토콜을 사용해야 하는지 각 프로토콜의 특징을 고려하여 선택해야 한다.<br><br>
<br>
<br><br><br>UDP를 사용할 때에는 송신 프로세스가 데이터의 패킷을 소켓 문 밖으로 밀어내기 전에, 먼저 패킷에 목적지 주소를 붙여넣어야 한다.<br>이 패킷이 송신자의 소켓을 통과한 후 인터넷은 이 목적지 주소를 이용하여 그 패킷을 인터넷을 통해 수신 프로세스에 있는 소켓으로 라우트(route)할 것이다.<br>패킷이 수신 소켓에 도착하면 수신 프로세스는 소켓을 통해 그 패킷을 추출하고, 다음에 패킷의 콘텐츠를 조사하여 적절한 동작을 취한다.<br><br>
<br><br><br>패킷에 목적지 주소를 포함함으로써 인터넷의 라우터는 목적지 호스트로 인터넷을 통해 패킷을 라우트할 수 있다.<br>호스트는 각자 IP 주소를 식별자로 갖는다.<br><br><br>그러나 호스트는 하나 혹은 그 이상의 소켓을 갖는 많은 네트워크 애플리케이션 프로세스를 수행하고 있을 수 있기 때문에,<br>
목적지 호스트 내의 특정한 소켓을 식별할 필요가 있다.<br>소켓이 생성될 때 포트 번호라고 하는 프로세스 식별자가 소켓에 할당된다.<br>즉, 패킷에는 IP 주소와 포트번호로 구성된 목적지 주소가 붙게 되며, 송신자의 출발지 주소(IP와 port)도 붙게 된다.<br><br><br>일반적으로 이렇게 주소를 붙이는 것은 하부 운영체제가 자동으로 실행한다.<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210794628-43c23c47-34d8-4a5b-b5e4-d7d617cdcf90.png" alt="UDP 애플리케이션" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br>위 그림은 UDP 서비스 상에서 통신하는 클라이언트와 서버의 주요 소켓 관련 활동을 나타낸다.<br>
<br>클라이언트는 키보드로부터 한 줄의 문자를 읽고 그 데이터를 서버로 보낸다.
<br>서버는 그 데이터를 수신하고 문자를 대문자로 변환한다.
<br>서버는 수정된 데이터를 클라이언트에게 보낸다.
<br>클라이언트는 수정된 데이터를 수신하고 그 줄을 화면에 나타낸다.
<br>위 순서로 작동하는 간단한 클라이언트-서버 애플리케이션을 만들 예정이다.<br><br><br><br>소켓을 생성할 때는 따로 소켓의 포트 번호를 명시하지 않아도 되며, 운영체제가 이 작업을 대신 수행한다.<br># socket module이다. 이 module을 통해 소켓을 생성할 수 있다.
from socket import *

#서버의 IP 혹은 서버의 호스트 이름을 할당한다.
serverName = ’hostname’

# 목적지 port 번호를 나타낸다.
serverPort = 12000

# 클라이언트 소켓을 생성한다. AF_INET은 IPv4를 사용하고 있음을 나타내고, SOCK_DGRAM은 UDP 소켓임을 의미한다.
clientSocket = socket(AF_INET, SOCK_DGRAM)

# 보낼 메시지를 입력 받는다.
message = Input(’Input lowercase sentence:’)

# 소켓으로 바이트 형태를 보내기 위해 먼저 encode()를 통해 바이트 타입으로 변환한다.
# sendTo() 메서드는 목적지 주소를 메시지에 붙이고 그 패킷을 프로세스 소켓인 clientSocket으로 보낸다.
# 클라이언트 주소도 같이 보내지는데 이는 자동으로 수행된다.
clientSocket.sendto(message.encode(),(serverName, serverPort))

# 패킷 데이터는 modifiedMessage에 저장되고, 패킷의 출발지 주소(IP, port)는 serverAddress에 할당된다.
# recvfrom() 메서드는 2048의 버퍼 크기로 받아들인다. 
modifiedMessage, serverAddress = clientSocket.recvfrom(2048)

# 출력
print(modifiedMessage.decode())

# 소켓 닫기
clientSocket.close()
복사<br><br><br><br>while 문을 통하여 한 번의 통신 이후에도, 계속 다음 UDP 패킷이 도착하기를 기다린다.<br>from socket import *

# 포트 번호
serverPort = 12000

# UDP 소켓 생성
serverSocket = socket(AF_INET, SOCK_DGRAM)

# 12000 포트 번호를 소켓에 할당한다. 이를 통해 서버 IP 주소의 12000 포트로 패킷을 보내면 해당 소켓으로 패킷이 전달된다.
serverSocket.bind((’’, serverPort))

print(”The server is ready to receive”)

while True:
    # 패킷이 서버에 도착하면 데이터는 메세지에 할당되고 패킷의 출발지 주소는 clientAddress에 저장된다.
    # 해당 주소로 서버는 응답을 어디에 보내야할지 알 수 있다.
    message, clientAddress = serverSocket.recvfrom(2048)
    
    # 바이트 데이터를 decode()하고 대문자로 변환한다.
    modifiedMessage = message.decode().upper()
    
    # 클라이언트 주소를 대문자로 변환된 메시지에 붙이고, 그 결과로 만들어진 패킷을 서버에 보낸다.
    # 서버의 주소도 같이 보내지는데 이는 자동으로 수행된다.
    serverSocket.sendto(modifiedMessage.encode(), clientAddress) 
복사<br><br>
<br>
<br><br><br>TCP는 연결 지향 프로토콜로, 서로 데이터를 보내기 전에 먼저 TCP 연결을 설정할 필요가 있다.<br>TCP 연결을 생성할 때 클라이언트 소켓 주소와 서버 소켓 주소를 연결과 연관시킨다.<br>연결이 설정된 후 소켓을 통해 데이터를 TCP 연결로 보내면 된다.<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210809355-8e26c0e0-561c-45bc-ba57-8d34487c68bc.png" alt="TCP" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br>서버 프로세스가 실행되면 클라이언트 프로세스는 서버로의 TCP 연결을 시도하는데, 이는 클라이언트 프로그램에서 TCP 소켓을 생성함으로써 가능하다.<br>TCP 소켓을 생성할 때, 서버에 있는 환영(welcome) 소켓의 주소(IP, port #)를 명시한다.<br>소켓을 생성한 후 클라이언트는 3-way handshake를 하고 서버와 TCP 연결을 설정한다. (핸드셰이킹은 프로그램에서 전혀 인지 못한다.)<br><br><br>핸드셰이킹 동안 서버는 해당 클라이언트에게 지정되는 새로운 소켓을 생성한다. 이를 연결 소켓이라고 한다.<br>애플리케이션 관점에서 볼 때 클라이언트의 소켓과 서버의 연결 소켓은 파이프에 의해 직접 연결된다.<br>파이프를 통해 클라이언트는 자신의 소켓으로 임의의 바이트를 보낼 수 있으며, 서버 프로세스가 그것을 수신하는 것을 TCP가 보장한다. 이는 서버 입장에서도 마찬가지이다.<br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/76640167/210813409-0e49cc1d-bab4-4bfb-8ba2-1d039f09f3c1.png" alt="TCP 애플리케이션 구조" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br>위 그림은 전형적인 클라이언트-서버 TCP 연결 구조이다.<br>UDP 프로그램과 똑같은 기능을 하는 프로그램을 작성해보자.<br><br><br><br>주석은 UDP와 다른 부분을 위주로 작성하였다.<br>from socket import *

serverName = ’servername’
serverPort = 12000

# 클라이언트 소켓을 의미한다. SOCK_STREAM으로 TCP 소켓임을 명시했다.
# UDP 때와 마찬가지로 따로 출발지 주소를 명시하지 않는다. (운영체제가 대신 해준다.) 
clientSocket = socket(AF_INET, SOCK_STREAM)

# 클라이언트가 TCP 소켓을 이용하여 서버로 데이터를 보내기 전에 TCP 연결이 먼저 클라이언트와 서버 사이에 설정되어야 한다.
# 해당 라인으로 TCP 연결을 시작하고, connect() 메서드의 파라미터는 연결의 서버 쪽 주소이다.
# 이 라인이 수행된 후에 3-way handshake가 수행되고 클라이언트와 서버 간에 TCP 연결이 설정된다.
clientSocket.connect((serverName, serverPort))

sentence = raw_input(’Input lowercase sentence:’)

# 클라이언트 소켓을 통해 TCP 연결로 보낸다. UDP 소켓처럼 패킷을 명시적으로 생성하지 않으며 패킷에 목적지 주소를 붙이지 않는다.
# 대신 클라이언트 프로그램은 단순히 문자열에 있는 바이트를 TCP 연결에 제공한다.
clientSocket.send(sentence.encode())

# 서버로부터 바이트를 수신하기를 기다린다.
modifiedSentence = clientSocket.recv(1024)
print(’From Server: ’, modifiedSentence.decode())

# 연결을 닫는다. 이는 클라이언트 TCP가 서버의 TCP에게 TCP 메시지를 보내게 한다.
clientSocket.close()
복사<br><br><br><br>from socket import *

serverPort = 12000

# TCP 소켓 생성
serverSocket = socket(AF_INET, SOCK_STREAM)

# 서버의 포트 번호를 소켓과 연관시킨다.
serverSocket.bind((’’, serverPort))

# 연관시킨 소켓은 대기하며 클라이언트가 문을 두드리기를 기다린다.
# 큐잉되는 연결의 최대 수를 나타낸다.
serverSocket.listen(1)
print(’The server is ready to receive’)

while True:
    # 클라이언트가 TCP 연결 요청을 하면 accept() 메소드를 시작해서 클라이언트를 위한 연결 소켓을 서버에 생성한다.
    # 그 뒤 클라이언트와 서버는 핸드셰이킹을 완료해서 클라이언트의 소켓과 연결 소켓 사이의 TCP 연결을 생성한다.
    connectionSocket, addr = serverSocket.accept()
    sentence = connectionSocket.recv(1024).decode()
    capitalizedSentence = sentence.upper()
    connectionSocket.send(capitalizedSentence.encode())
    
    # 응답을 보내고 연결 소켓을 닫는다. 그러나 환영소켓인 serverSocket이 열려있어 다른 클라이언트가 서버에 연결을 요청할 수 있다. 
    connectionSocket.close()
복사]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_2\2.7-소켓-프로그래밍_-네트워크-애플리케이션-생성\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_2/2.7 소켓 프로그래밍_ 네트워크 애플리케이션 생성/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 06:50:48 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/210794628-43c23c47-34d8-4a5b-b5e4-d7d617cdcf90.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/210794628-43c23c47-34d8-4a5b-b5e4-d7d617cdcf90.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.1 트랜스포트 계층 서비스 및 개요]]></title><description><![CDATA[ 
 <br><br>
트랜스포트 계층 프로토콜은 각기 다른 호스트에서 동작하는 애플리케이션 프로세스 간의 논리적 통신(logical communication)을 제공한다.
<br>= 애플리케이션의 관점에서 보면, 프로세스들이 동작하는 호스트들이 직접 연결된 것처럼 보인다<br>아래 그림처럼, 트랜스포트 계층 프로토콜은 네트워크 라우터가 아닌 종단 시스템에서 구현된다.<br><img alt="Pasted image 20240613210240.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.1-트랜스포트-계층-서비스-및-개요\attachments\pasted-image-20240613210240.png"><br>
<br>
송신 측의 트랜스포트 계층은 송신 애플리케이션 프로세스로부터 수신한 메시지를 트랜스포트 계층 패킷으로 변환한다.<br>
(이는 트랜스포트 계층 세그먼트(segment)라고 부른다 : L4-PDU)

<br>애플리케이션 메시지를 작은 조각으로 분할한다.
<br>각각의 조각에 트랜스포트 계층 헤더를 추가한다.


<br>
트랜스포트 계층은 송신 종단 시스템에 있는 네트워크 계층으로 세그먼트를 전달한다.

<br>세그먼트는 네트워크 계층 패킷(데이터그램(datagram) : L3-PDU) 안에 캡슐화되어(encapsulate) 목적지로 전달된다.


네트워크 라우터는 오로지 데이터그램의 네트워크 계층 필드에 대해 동작한다.<br>
즉, 데이터그램 안에 캡슐화된 트랜스포트 계층 세그먼트의 필드를 검사하지 않는다.


<br>
수신 측에서 네트워크 계층은 데이터그램으로부터 트랜스포트 계층 세그먼트를 추출하고 트랜스포트 계층으로 세그먼트를 보낸다.

<br>
트랜스포트 계층은 수신 애플리케이션에서 세그먼트 내부의 데이터를 이용할 수 있도록 수신된 세그먼트를 처리한다.

<br>네트워크 애플리케이션에서는 하나 이상의 트랜스포트 계층 프로토콜을 사용할 수 있다.<br>e.g., 인터넷 : TDP, UDP라는 두 가지 프로토콜을 가지고 있다.<br><br>
💡 트랜스포트 계층 프로토콜은 각기 다른 호스트에서 동작하는 프로세스들 사이의 논리적 통신을 제공한다.
<br>
💡 네트워크 계층 프로토콜은 호스트들 사이의 논리적 통신을 제공한다.
<br>
<br>
트랜스포트 계층 프로토콜은 종단 시스템(end system)에 존재하며,<br>
애플리케이션 프로세스에서 네트워크 계층 사이에서 메시지를 운반하는 역할을 한다.<br>
<img alt="Pasted image 20240613211946.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.1-트랜스포트-계층-서비스-및-개요\attachments\pasted-image-20240613211946.png">

<br>
메시지가 네트워크 계층 내부에서 어떻게 이동하는지는 언급하지 않는다.  

<br>즉, Application을 다루는(작성하거나 run 하는) 입장에서는 앞으로 이루어질 physical connection을 염려하지 않아도 된다.


<br>
<br>Transport Lyaer가 제공할 수 있는 서비스는 하위 네트워크 계층 프로토콜의 서비스 모델에 의해 제약받는다.
<br>
e.g.<br>
Network Layer Protocol이 호스트 사이에서 전송되는 Transport Layer 세그먼트에 대한 지연 보장이나 대역폭 보장을 제공할 수 없다면,<br>
Tranport Layer Protocol은 프로세스끼리 전송하는 메시지에 대한 지연 보장이나 대역폭 보장을 제공할 수 없다.
<br>
<br>하위 네트워크 프로토콜이 상응하는 서비스를 제공하지 못할 때도, 특정 서비스는 Transport protocol에 의해 제공될 수 있다.
<br>
e.g.<br>
하위 네트워크 프로토콜이 비신뢰적일 때, Transport Layer 애플리케이션에게 신뢰적인 데이터 전송 서비스를 제공할 수 있다.<br>
(비신뢰적이다 = 패킷을 분실하거나, 손상시키거나, 복사본을 만든다)
<br><br><br><br>
<br>신뢰적이고 연결지향형 서비스를 제공한다. (reliable data transfer)
<br>혼잡 제어(congestion control) : 혼잡한 네트워크 링크에서 각 TCP 연결이 링크의 대역폭을 공평하게 공유하여 통과하도록 해준다.
<br><br>
<br>비신뢰적이고 비연결형인 서비스를 제공한다.
<br>UDP Tranport Protocol을 사용하는 애플리케이션은 허용이 되는 한, 그것이 만족하는 어떤 속도로든 전송할 수 있다.
<br><br>
<br>세그먼트(segment) : Tranport Layer 패킷을 일컫는 말
<br>TCP에 대한 패킷을 세그먼트(segment),<br>
UDP에 대한 패킷을 데이터그램(datagram)이라는 용어로 나타내기도 한다.
<br>이 책에서는 TCP와 UDP 패킷을 모두 세그먼트라고 지칭, 네트워크 계층 패킷에 대해서는 데이터그램이라는 용어를 사용한다.<br><br>인터넷의 네트워크 계층 프로토콜<br>
IP 서비스 모델은 호스트들 간에 논리적 통신을 제공하는 최선형 전달 서비스(best-effort delivery service)
<br>즉, IP가 통신하는 호스트들 간에 세그먼트를 전달하기 위해 최대한 노력하지만, 어떤 보장도 하지 않는다.<br>
<br>세그먼트의 전달 보장 X
<br>순서 보장 X
<br>내부 데이터의 무결성(integrity) 보장 X
<br>→ IP는 비신뢰적인 서비스(unreliable service)이다.<br>
💡 각 호스트는 적어도 하나의 IP 주소를 갖고 있다.
<br><br><br>
‘호스트 대 호스트 전달’ → ‘프로세스 대 프로세스 전달’
<br>종단 시스템 사이의 IP 전달 서비스를 / 종단 시스템에서 동작하는 두 프로세스 간의 전달 서비스로 확장한다.<br><br>이로써 무결성 검사를 제공한다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.1-트랜스포트-계층-서비스-및-개요\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.1 트랜스포트 계층 서비스 및 개요/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:10 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.1-트랜스포트-계층-서비스-및-개요\attachments\pasted-image-20240613210240.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.1-트랜스포트-계층-서비스-및-개요\attachments\pasted-image-20240613210240.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.2 다중화와 역다중화]]></title><description><![CDATA[ 
 <br><br>
💡 트랜스포트 계층 다중화(multiplexing)와 역다중화(demultiplexing)<br>
네트워크 계층이 제공하는 호스트 대 호스트 전달 서비스에서<br>
호스트에서 동작하는 애플리케이션에 대한 프로세스 대 프로세스 전달 서비스로 확장하는 과정
<br>
<br>
목적지 호스트에서의 트랜스포트 계층은 바로 아래의 네트워크 계층으로부터 세그먼트를 수신한다.

트랜스포트 계층은 호스트에서 동작하는 해당 애플리케이션 프로세스에게 이 세그먼트의 데이터를 전달하는 의무를 가진다.


<br>
트랜스포트 계층은 세그먼트(데이터)를 중간 매개자인 소켓(socket)에게 전달한다.

<br>프로세스는 네트워크 애플리케이션의 한 부분으로서 소켓을 가지고 있다.
<br>이는 네트워크에서 프로세스로, 한 프로세스로부터 네트워크로 데이터를 전달하는 출입구 역할을 한다.
<br>각각의 소켓은 하나의 유일한 식별자, 포트 번호(port number)를 가진다.


<br><img alt="Pasted image 20240614000727.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614000727.png"><br>Q. 수신한 트랜스포트 계층 세그먼트는 어떻게 적절한 소켓으로 향하는가?
복사<br>각각의 트랜스포트 계층 세그먼트는 세그먼트에 필드 집합을 가지고 있으며,<br>
트랜스포트 계층은 수신 소켓을 식별하기 위해 이러한 필드를 검사한 후 해당 소켓으로 보낸다.<br><br>트랜스포트 계층 세그먼트의 데이터를 올바른 소켓으로 전달하는 작업을 말한다.<br><br>
<br>출발지 호스트에서 소켓으로부터 데이터를 모으고,
<br>이에 대한 세그먼트를 생성하기 위해 각 데이터에 헤더 정보로 캡슐화(encapsulation) 한다.
<br>그 세그먼트들을 네트워크 계층으로 전달한다.
<br><br>
<br>소켓은 유일한 식별자를 갖는다. (= 포트 번호)
<br>각 세그먼트는 세그먼트가 전달될 적절한 소켓을 가리키는 특별한 필드를 갖는다.

<br>출발지 포트 번호 필드(source port number field)
<br>목적지 포트 번호 필드(destination port number field)


<br><img alt="Pasted image 20240614002839.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614002839.png"><br><br>
<br>호스트의 각 소켓은 포트 번호를 할당받는다.
<br>세그먼트가 호스트에 도착하면,

<br>트랜스포트 계층은 세그먼트 안의 목적지 포트 번호를 검사하고,
<br>그에 상응하는 소켓으로 세그먼트를 보낸다.


<br>세그먼트의 데이터는 소켓을 통해 해당되는 프로세스로 전달된다.
<br>이는 UDP의 기본적인 동작 방식과 같다.<br><br>
💡 UDP 소켓은 목적지 IP 주소와 목적지 포트 번호로 구성된 두 요소로 된 집합에 의해 식별된다.
<br>따라서 만약 2개의 UDP 세그먼트가 같은 목적지 IP 주소와 목적지 포트 번호를 가진다면,<br>
이 2개의 세그먼트는 같은 목적지 소켓을 통해 같은 프로세스로 향할 것이다.<br>그렇다면 출발지 포트 번호는 무슨 목적으로 사용되는가?<br>
출발지 포트 번호는 ‘회신 주소’의 한 부분으로 사용된다.
<br>아래 그림처럼, B가 A에게로 세그먼트를 보내기를 원할 때<br>
B에서 A로 가는 세그먼트의 목적지 포트 번호는 A로부터 B로 가는 세그먼트의 출발지 포트 번호로부터 가져온다.<br><img alt="Pasted image 20240614002937.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614002937.png"><br><br><br>
💡 TCP 소켓은 4개 요소의 집합(four-tuple)에 의해 식별된다.
<br>
<br>출발지 IP 주소
<br>출발지 포트 번호
<br>목적지 IP 주소
<br>목적지 포트 번호
<br>특히, 다른 출발지 IP 주소 또는 다른 출발지 포트 번호를 가지고 도착하는 2개의 TCP 세그먼트는 2개의 다른 소켓으로 향하게 된다.<br>
(초기 연결 설정 요청을 전달하는 TCP는 제외)<br><br>
<br>
TCP 서버 애플리케이션은 환영(welcome) 소켓을 갖고 있다.<br>
이 소켓은 포트 번호 12000을 가진 TCP 클라이언트로부터 연결 설정 요청을 기다린다.<br>
(아래 그림 참고)<br>
<img alt="Pasted image 20240614003337.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614003337.png">

<br>
TCP 클라이언트는 소켓을 생성하고, 연결 설정 요청 세그먼트를 보낸다.

<br>연결 설정 요청은 목적지 포트 번호 12000과 TCP 헤더에 설정된 특별한 연결 설정 비트(3.5절에서 설명)를 가진 TCP 세그먼트를 통해 보내진다.
<br>이 세그먼트는 출발지 포트 번호를 포함하는데, 이것은 클라이언트가 선택한 번호이다.


<br>
서버 프로세스로 동작하는 컴퓨터의 호스트 운영체제가 목적지 포트 12000을 포함하는 연결 요청 세그먼트를 수신하면,<br>
이 세그먼트를 포트 번호 12000으로 연결 수락을 기다리는 서버 프로세스로 보낸다.

<br>
서버는 연결 요청 세그먼트의 4개 요소의 집합에 주목한다.

<br>서버 호스트는 동시에 존재하는 많은 TCP 소켓을 지원할 수 있다.
<br>새롭게 생성된 연결 소켓은 4개 요소의 집합의 네 가지 값에 의해 식별된다.
<br>따라서 그다음에 도착하는 세그먼트의 출발지 포트, 출발지 IP 주소, 목적지 포트, 목적지 IP 주소가 전부 일치하면,  
<br>그 세그먼트는 이 소켓으로 역다중화될 것이다.


<br><br>서버 호스트는 동시에 존재하는 많은 TCP 소켓을 지원할 수 있다.<br>
각각의 소켓은 프로세스에 접속되어 있으며, 이들 소켓은 4개 요소 집합(four-tuple)에 의해 식별된다.<br><img alt="Pasted image 20240614003712.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614003712.png"><br>
그림 3.5 설명<br>
<br>호스트 C가 서버 B로 2개의 HTTP 세션 시작
<br>호스트 A가 호스트(서버) B로 하나의HTTP 세션 시작
<br>호스트 A와 호스트 C, 서버 B는 각자 유일한 IP 주소 소유
<br>호스트 C는 2개의 출발지 포트 번호(26145, 7532)를 자신의 HTTP 연결에 할당

<br>단, 호스트 A는 C와 독립적으로 출발지 포트 번호를 선택하므로, 호스트 C또한 26145를 할당 가능
<br>이렇게 해도 2개의 연결은 다른 출발지 IP 주소를 가지고 있어서 서버 B는 두 연결을 올바르게 역다중화 가능


<br><br>
💡 서버는 각기 다른 클라이언트가 보낸 세그먼트를 출발지 IP 주소와 출발지 포트 번호로 구별한다.
<br><img alt="Pasted image 20240614003712.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614003712.png"><br>같은 웹 서버 애플리케이션과 통신하기 위해 같은 목적지 포트 번호(80)를 이용하는 두 클라이언트에 대한 예시를 보자.<br>
<br>호스트 C가 서버 B로 2개의 HTTP 세션을 시작
<br>호스트 A가 서버 B로 하나의 HTTP 세션을 시작
<br>호스트 A, 호스트 C, 서버 B는 각자 유일한 IP 주소인 A, C, B를 각각 가지고 있다.<br>
<br>호스트 C는 2개의 출발지 포트 번호(26145, 7532)를 자신의 HTTP 연결에 할당한다.
<br>호스트 A는 호스트 C와 독립적으로 출발지 포트 번호를 선택하므로,<br>
이것 또한 HTTP 연결에 출발지 포트로 26145를 할당할 수 있다.
<br>
이렇게 하더라도, 2개의 연결은 다른 출발지 IP 주소를 가지기 때문에 서버 B는 여전히 올바르게 역다중화할 수 있다.
<br><br>웹 서버는 각각의 연결에 따라서 새로운 프로세스를 만든다.<br>이들 프로세스는 각자 연결 소켓을 가지며, 이 연결 소켓을 통해 HTTP 요청을 수신하고, HTTP 응답을 전송한다.<br>
그러나 연결 소켓과 프로세스 사이에 항상 일대일 대응이 이루어지는 것이 아니다.
<br>
<br>오늘날의 많은 고성능 웹 서버는 하나의 프로세스만 사용한다.
<br>각각의 새로운 클라이언트 연결을 위해 새로운 연결 소켓과 함께 새로운 스레드(thread)를 생성한다.
<br><br><br>지속적인 연결의 존속 기간에 클라이언트와 서버는 같은 서버 소켓을 통해 HTTP 메시지를 교환한다.<br><br>모든 요청/응답마다 새로운 TCP 연결이 생성되고 종료된다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.2 다중화와 역다중화/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:10 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614000727.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.2-다중화와-역다중화\attachments\pasted-image-20240614000727.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.3 비연결형 트랜스포트: UDP]]></title><description><![CDATA[ 
 <br><br>
💡 UDP는 트랜스포트 계층 프로토콜이 할 수 있는 최소 기능으로 동작한다.
<br>
<br>다중화/역다중화 기능
<br>간단한 오류 검사 기능
<br>이외에는 IP에 아무것도 추가하지 않는다.<br><br>
<br>
애플리케이션 프로세스로부터 메시지를 가져와서<br>
다중화/역다중화 서비스에 필요한 출발지 포트 번호 필드와 목적지 포트 번호 필드를 첨부한다.

<br>
출발지 호스트의 IP 주소 필드, 목적지 호스트의 IP 주소 필드를 추가한 후에<br>
최종 트랜스포트 계층 세그먼트를 네트워크 계층으로 넘겨준다.

<br>
네트워크 계층은 트랜스포트 계층 세그먼트를 IP 데이터그램으로 캡슐화하고,<br>
세그먼트를 수신 호스트에게 전달한다.

<br>
세그먼트가 수신 호스트에 도착한다면,<br>
UDP는 세그먼트의 데이터를 해당하는 애플리케이션 프로세스로 전달하기 위해 목적지 포트 번호를 사용한다.

<br>
💡 UDP는 세그먼트를 송신하기 전에 송신 트랜스포트 계층 개체들과 수신 트랜스포트 계층 개체들 사이에 핸드셰이크를 사용하지 않는다.
<br>→ 비연결형<br><br>DNS는 전형적으로 UDP를 사용하는 애플리케이션 계층 프로토콜의 예이다.<br>만약 질의 호스트가 응답을 수신하지 못하면 질의를 다른 네임 서버로 송신하거나, 애플리케이션에게 응답을 수신할 수 없음을 통보한다.<br><br>많은 애플리케이션은 다음과 같은 이유로 UDP에 더 적합하다.<br><br>UDP 하에서 애플리케이션 프로세스가 데이터를 UDP에 전달하자마자<br>
UDP는 데이터를 UDP 세그먼트로 만들고, 그 세그먼트를 즉시 네트워크 계층으로 전달한다.<br>
실시간 애플리케이션에서는 UDP를 사용하고, 필요한 어떤 추가 기능을 구현할 수 있다.
<br>↔︎ TCP<br>
<br>
혼잡 제어 매커니즘이 존재한다.<br>
즉, 목적지 호스트들과 출발지 호스트들 사이에서 하나 이상의 링크가 과도하게 혼잡해지면 트랜스포트 계층 TCP 송신자를 제한한다.

<br>
신뢰적인 전달이 얼마나 오래 걸리는지에 관계없이<br>
목적지가 세그먼트의 수신 여부를 확인응답할 때까지 데이터의 세그먼트 재전송을 계속한다.

<br><br>UDP는 TCP의 세 방향 핸드셰이크(three-way handshake)와 같은 공식적인 사전준비 없이 전송한다.<br>따라서 UDP는 연결을 설정하기 위한 어떤 지연도 없다.<br><br>UDP는 연결 상태를 유지하지 않으며, 연결 상태에 대한 그 어떠한 파라미터도 기록하지 않는다.<br>따라서 일반적으로 특정 애플리케이션 전용 서버는 애플리케이션 프로그램이 UDP에서 동작할 때<br>
좀 더 많은 액티브 클라이언트를 수용할 수 있다.<br><br>TCP는 세그먼트마다 20바이트의 헤더 오버헤드를 갖지만, UDP는 단지 8바이트의 오버헤드를 갖는다.<br><br>UDP는 혼잡 제어(congestion control)를 하지 않는다.<br>
💡 혼잡 제어는 네트워크가 꼭 필요한 작업을 할 수 없게 되는 폭주 상태에 빠지는 것을 막기 위해 반드시 필요하다.
<br>만약 모두가 혼잡 제어를 사용하지 않고 높은 비트의 비디오 스트리밍을 시작한다면,<br>
<br>
라우터에 많은 패킷 오버플로가 발생<br>
→ 소수의 UDP 패킷만이 출발지-목적지 간의 경로를 무사히 통과할 것이다.

<br>
제어되지 않은 UDP 송신자에 의해 발생한 높은 손실률은 그 손실률을 감소시키기 위해 TCP 송신자들이 속도를 줄이도록 할 것<br>
→ TCP 세션의 혼잡이 발생할 것이다.

<br><br>UDP는 비신뢰적인 서비스를 제공하지만,<br>
애플리케이션 자체에서 신뢰성을 제공한다면 UDP를 사용하면서 신뢰적인 데이터 전송이 가능해진다.<br>e.g., 구글의 크롬 브라우저에서 사용되는 QUIC(Quick UDP Internet Connection) 프로토콜<br>이는 기본 트랜스포트 프로토콜로 UDP를 사용하고, UDP 위에 애플리케이션 계층 프로토콜의 안정성을 구현한다.<br><br><img alt="Pasted image 20240614005732.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.3-비연결형-트랜스포트_-udp\attachments\pasted-image-20240614005732.png"><br><br>UDP 데이터그램의 데이터 필드에 위치한다.<br><br>목적지 호스트가 목적지 종단 시스템에서 동작하는 (역다중화 기능을 수행하는) 정확한 프로세스에게 애플리케이션 데이터를 넘기게 해준다.<br><br>세그먼트에 오류가 발생했는지 검사하기 위해 수신 호스트가 사용한다.<br><br>헤더를 포함하는 UDP 세그먼트의 길이를 바이트 단위로 나타낸다.<br><br>
UDP 체크섬은 세그먼트가 출발지로부터 목적지로 이동했을 때,<br>
UDP 세그먼트 안의 비트에 대한 변경사항이 있는지 검사하여 오류 검출을 하기 위한 것이다.
<br>
<br>
송신자 측에서 세그먼트 안에 있는 모든 16비트 워드의 합산에 대해 다시 1의 보수를 수행하며,<br>
합산 과정에 발생하는 오버플로는 윤회식 자리올림(wrap around)을 한다.

<br>
이 결과값이 UDP 세그먼트의 체크섬 필드에 삽입된다.

<br>
수신자에서는 체크섬을 포함한 모든 16비트 워드들이 더해진다.

<br>
만약 패킷에 어떤 오류도 없다면 수신자에서의 합은 1111111111111111이 되며,<br>
비트 중에 0이 하나라도 있다면 패킷에 오류가 발생했다는 것이다.

<br>예를 들어, 다음과 같은 3개의 16비트 워드가 있다고 하자.<br>0110011001100000
0101010101010101 
1000111100001100
복사<br>이러한 16비트 워드에서 처음 2개의 워드 합은 다음과 같다. <br>0110011001100000 
0101010101010101 
----------------
1011101110110101 
복사<br>앞 계산의 합에 세 번째 워드를 더하면 다음과 같은 결과가 나온다. <br>1011101110110101 
1000111100001100
----------------
0100101011000010
복사<br>마지막 합은 오버플로(자리 넘침)가 있고 이를 윤회식 자리올림을 했음에 유의하자.<br>1의 보수는 모든 0을 1로 변환하고 모든 1을 0으로 변환하면 구할 수 있다.<br>
그래서 합 0100101011000010의 1의 보수는 1011010100111101 이고, 이것이 체크섬이 된다.<br>수신자에서는 체크섬을 포함한 4개의 모든 16비트 워드들이 더해진다.<br>
만약 패킷에 어떤 오류도 없다면, 수신자에서의 합은 1111111111111111이 될 것이다.<br>
만약 비트 중에 하나라도 0이 있다면 패킷에 오류가 발생했음을 알 수 있다<br><br>IP는 어떠한 2계층 프로토콜에서도 동작해야 하므로, 트랜스포트 계층은 안전장치로서 오류 검사를 제공하는 것이 유용하다.<br>또한, 출발지와 목적지 사이의 모든 링크가 오류 검사를 제공한다는 보장이 없기 때문이다.<br>따라서 세그먼트들이 정확하게 링크를 통해 전송되었을지라도, 세그먼트가 라우터의 메모리에 저장될 때 비트 오류가 발생할 수가 있다.<br>
💡 UDP는 오류 검사를 제공하지만, 오류를 회복하기 위한 어떤 일도 하지 않는다.
<br>손상된 세그먼트를 그냥 버리기도 하고, 경고와 함께 손상된 세그먼트를 애플리케이션에게 넘겨주기도 한다.<br>
(처리 방식은 구현에 따라서 다름)<br><br>주어진 링크 간의 신뢰성과 메모리의 오류 검사가 보장되지도 않고, 종단 간의 데이터 전송 서비스가 오류 검사를 제공해야 한다면<br>
UDP는 종단 기반으로 트랜스포트 계층에서 오류 검사를 제공해야만 한다.<br>→ 이것은 종단과 종단의 원칙(end-end principle)의 한 예시이다.<br>
즉 어떤 기능이 종단 기반으로 구현되어야 하므로, '하위레벨에 없는 기능들은 상위 레벨에 이들을 제공하는 비용과 비교했을때 중복되거나 거의 가치가 없을 수 있다' 는 것이다.<br><br>하위 레벨에 있는 기능들은 상위 레벨에서 이들을 제공하는 비용과 비교했을 때 중복되거나 거의 가치가 없을 수 있다.<br>종단 간 원칙에 따르면 네트워크는 터미널에 연결에만 응답하며 그 외 모든 종류의 정보들은 터미널에 있어야함. -위키-<br>응용프로그램에 특화된 기능들은 종단에 있어야 한다는 법칙.<br>
i.e) 네트워크 작동에 있어 핵심이 아니면서 특정 사용자들에게는 중요한 활동은 네트워크 종단(외곽부)에 위치해야 한다는 법칙.<br>이는 네트워크 전반을 유지 보수 및 업데이트시 복잡도를 낮출 수 있게 된다. -마셀 밴 엘스테인-&nbsp;]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.3-비연결형-트랜스포트_-udp\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.3 비연결형 트랜스포트_ UDP/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:11 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.3-비연결형-트랜스포트_-udp\attachments\pasted-image-20240614005732.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.3-비연결형-트랜스포트_-udp\attachments\pasted-image-20240614005732.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.4 신뢰적인 데이터 전송의 원리]]></title><description><![CDATA[ 
 <br><br>신뢰적인 데이터 전송을 구현하는 문제는 트랜스포트 계층뿐만 아니라 링크 계층과 애플리케이션 계층에서도 발생할 수 있는 문제이다.<br>따라서 이 절에서는 일반적인 상황에서의 신뢰적인 데이터 전송 문제를 다룬다.<br>신뢰적인 데이터 전송 연구의 프레임워크는 다음과 같다.<br><img alt="Pasted image 20240614020554.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\attachments\pasted-image-20240614020554.png"><br>상위 계층 객체에게 제공되는 서비스 추상화는 / 데이터가 전송될 수 있는 신뢰적인 채널의 서비스 추상화다.<br>
<br>신뢰적인 채널에서는 전송된 데이터가 손상되거나 손실되지 않으며,
<br>모든 데이터는 전송된 순서 그대로 전달된다.
<br>= TCP가 인터넷 애플리케이션에게 제공하는 서비스 모델<br>신뢰적인 데이터 전송 프로토콜(reliable data transfer protocol)의 의무는 신뢰적인 채널의 서비스 추상화를 구현하는 것이다.<br><br>
이 절에서는 점점 복잡해지는 하위 채널 모델을 고려하여 신뢰적인 데이터 전송 프로토콜의 송신자 측면과 수신자 측면을 점진적으로 개발해나간다.
<br>논의 과정 중 채택할 한 가지 가정 : 패킷은 순서대로 전달된다. (하부 채널은 패킷의 순서를 바꾸지 않음)<br>위 두 가지 그림 중 b는 데이터 전송 프로토콜의 인터페이스를 나타낸다.<br>
<br>
데이터 전송 프로토콜의 송신 측은 rdt_send() 호출로 위쪽으로부터 호출될 것이며, 수신 측에서는 상위 계층으로 전달될 데이터를 넘길 것이다.

<br>rdt : 신뢰적인 데이터 전송(reliable data transfer) 프로토콜을 나타낸다.
<br>_send : rdt의 송신 측이 호출되고 있음을 나타낸다.


<br>
수신 측에서 rdt_rcv()는 패킷이 채널의 수신 측으로부터 도착했을 때 호출된다.

<br>
rdt 프로토콜이 상위 계층에 데이터를 전달하려고 할 때 deliver_data()를 호출한다.

<br><br>
이 절에서는 단방향 데이터 전송(unidirectional data tranfer)의 경우인 송신 측으로부터 수신 측까지의 데이터 전송만을 고려한다.
<br>양방향(전이중) 데이터 전송(bidirectional data transfer)의 설명은 상당히 복잡하다.<br>단방향 데이터 전송만 생각하더라도 프로토콜의 송신 측과 수신 측이 양방향으로 패킷을 전달할 필요가 있다.<br>즉, rdt의 송신 측과 수신 측은 전송 데이터를 포함하는 패킷을 교환하는 것 외에 제어 패킷을 양쪽으로 전송해야 한다.<br>
<br>rdt의 송신 측과 수신 측 모두 udt_send()를 호출함으로써 다른 쪽에 패킷을 전송한다.

<br>udt : 비신뢰적인 데이터 전송(unreliable data transfer)을 나타냄


<br><br><br>
<br>
화살표는 한 상태로부터 다른 상태로의 전이를 나타낸다.

<br>
FSM의 초기 상태는 점선 화살표로 표시된다.

<br>
전이를 일으키는 이벤트(event)는 변화를 표기하는 가로선 위에 나타낸다.

<br>
이벤트가 발생했을 때 취해지는 행동, 액션(action)은 가로선 아래에 나타낸다.

<br>
이벤트 발생 시 어떠한 행동도 취해지지 않거나, 어떠한 이벤트 발생 없이 행동이 취해질 때<br>
동작이나 이벤트가 없음을 표시하기 위해 각각 가로선 아래나 위에 기호 𝚲를 사용한다.

<br><br>하위 채널이 완전히 신뢰적인 가장 간단한 경우를 고려해보자.<br><br>rdt1.0 송신자와 수신자에 대한 유한상태 머신(FSM) 정리는 아래 그림과 같다.<br>
💡 송신자에 대해 그리고 수신자에 대해 분리된 FSM이 있다
<br>
<br>a는 송신자(sender)의 동작에 대한 정의
<br>b는 수신자(receiver)의 동작에 대한 정의
<br><img alt="Pasted image 20240615123050.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\attachments\pasted-image-20240615123050.png"><br>rdt1.0에서 각각의 FSM은 하나의 상태만을 가지므로, 전이는 필연적으로 그 상태로부터 자신으로 되돌아온다.<br><br>
<br>
rdt_send(data) 이벤트에 의해<br>
(이 이벤트는 상위 계층 애플리케이션의 프로시저 호출(e.g., rdt_send())에 의해 발생)

<br>상위 계층으로부터 데이터를 받아들이고
<br>데이터를 포함한 패킷을 생성한다. (make_pkt(data))


<br>
그러고 난 후 패킷을 채널로 송신한다.

<br><br>
<br>
rdt는 rdt_rcv(packet) 이벤트에 의해 하위의 채널로부터 패킷을 수신한다.<br>
: 이 이벤트는 하위 계층 프로토콜로부터의 프로시저 호출(e.g., rdt_rcv())에 의해 발생한다.

<br>
패킷으로부터 데이터를 추출하고 (extract(packet, data))

<br>
데이터를 상위 계층으로 전달한다. (deliver_data(data))

<br><br>여기서는 데이터 단위와 패킷의 차이점이 없으며, 모든 패킷 흐름은 송신자로부터 수신자까지다.<br>
💡 완전히 신뢰적인 채널에서는 오류가 생길 수 없으므로 수신 측이 송신 측에게 어떤 피드백(feedback)도 제공할 필요가 없다.
<br>또한, 수신자는 송신자가 데이터를 송신하자마자 데이터를 수신할 수 있다고 가정하였다.<br>따라서 수신자가 송신자에게 천천히 보내라는 것을 요청할 필요가 없다.<br><br>패킷 안의 비트들이 하위 채널에서 손상되는 모델이다.<br>일반적으로 이러한 비트 오류는 패킷이 전송 도는 전파되거나 버퍼링될 때 네트워크의 물리적인 구성요소에서 발생한다.<br><br>
<br>긍정 확인응답(positive acknowledgment, “OK”)
<br>부정 확인응답(negative acknowledgment, “그것을 반복해주세요”)
<br>이러한 제어 메시지는 정확하게 수신되었는지 또는 잘못 수신되어 반복이 필요한지를 수신자가 송신자에게 알려줄 수 있게 한다.<br>비트 오류를 처리하기 위해 기본적으로 다음과 같은 세 가지 부가 프로토콜 기능이 ARQ 프로토콜에 요구된다.<br><br>
비트 오류가 발생했을 때 수신자가 검출할 수 있는 기능이 필요하다. → checksum
<br>이러한 기술은 수신자가 패킷 비트 오류를 검출하고 복구할 수 있게 해준다.<br><br>
송신자가 수신자의 상태를 알기 위한 유일한 방법은 수신자가 송신자에게 피드백을 제공하는 것이다.
<br>수신자의 상태 : 패킷이 정확하게 수신되었는지 아닌지 등<br>e.g., rdt2.0 프로토콜에서은 수신자로부터 송신자 쪽으로 ACK와 NAK 패킷들을 전송할 것이다.<br>
<br>긍정 확인 응답(ACK)
<br>부정 확인 응답(NAK)
<br>→ 이러한 패킷은 단지 한 비트 길이면 된다. (0 또는 1)<br><br>
수신자에서 오류를 가지고 수신된 패킷은 송신자에 의해 재전송(retransmit)된다.
<br><br><br><img alt="Pasted image 20240615165129.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\attachments\pasted-image-20240615165129.png"><br>
2개의 상태가 존재한다.<br>
<br>
왼쪽 상태에서 송신 측 프로토콜은 상위 계층으로부터 데이터가 전달되기를 기다린다.
rdt_sent(data) 이벤트가 발생하면,

<br>송신자는 패킷 체크섬과 함께 전송될 데이터를 포함하는 패킷(sndpkt)을 생성하고,
<br>그 패킷을 udt_send(sndpkt) 동작을 통해 전송한다.


<br>
오른쪽 상태에서 송신자 프로토콜은 수신자로부터의 ACK 또는 NAK 패킷을 기다린다.

<br>만약 ACK 패킷이 수신된다면 (rdt_rcv(rcvpkt) &amp;&amp; isACK(rcvpkt))

<br>가장 최근에 전송된 패킷이 정확하게 수신되었음을 의미한다.
<br>따라서 프로토콜은 상위 계층으로부터 데이터를 기다리는 상태로 돌아간다.


<br>만약 NAK가 수신된다면

<br>프로토콜은 마지막 패킷을 재전송한다.
<br>재전송된 데이터 패킷에 대한 응답으로 수신자에 의해 응답하는 ACK 또는 NAK를 기다린다.




<br>rdt2.0과 같은 프로토콜은 전송 후 대기(stop-and-wait) 프로토콜이다.<br>
💡 송신자가 ACK 또는 NAK를 기다리는 상태에 있을 때, 상위 계층으로부터 더 이상의 데이터를 전달받을 수 없다.
<br>즉, rdt_send() 이벤트는 발생할 수 없으며, 이는 오직 송신자가 ACK를 수신하고 이 상태를 떠난 후에 발생할 것이다.<br>따라서 송신자는 수신자가 현재의 패킷을 정확하게 수신했음을 확신하기 전까지 새로운 데이터를 전달하지 않는다.<br><br><img alt="Pasted image 20240615165148.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\attachments\pasted-image-20240615165148.png"><br>단일 상태를 갖는다.<br>패킷이 도착했을 때, 수신자는 수신된 패킷이 손상되었는지 아닌지에 따라 ACK 또는 NAK로 응답한다.<br><br>여기서는 ACK 또는 NAK 패킷이 손상될 수 있다는 가능성을 고려하지 않았다.<br>만약 ACK 또는 NAK가 손상되었다면, 송신자는 수신자가 전송된 데이터의 마지막 부분을 올바르게 수신했는지를 알 방법이 없다.<br>
대안 1 : 송신자가 검출뿐만 아니라 비트 오류로부터 회복할 수 있도록 충분한 체크섬 비트들을 추가한다.
<br>이 방식은 패킷이 손상될 수 있으나 손실되지는 않는 채널의 경우에는 즉각적으로 문제를 해결할 수 있다.<br>
대안 2 : 송신자가 왜곡된 ACK 또는 NAK 패킷을 수신할 때 현재 데이터 패킷을 단순히 다시 송신한다.
<br>그러나 이 방식은 송신자에게 수신자 간의 채널로 중복 패킷(duplicate packet)을 전송한다.<br>
<br>송신자 입장에서는 마지막으로 전송된 ACK 또는 NAK가 송신자에게 정확하게 수신됐는지를 알 수 없다.
<br>수신자 입장에서는 도착하는 패킷이 새로운 데이터를 포함하고 있는 것인지 아니면 재전송인지를 사전에 알 수 없다.
<br><br>
💡 데이터 패킷에 새로운 필드를 추가하고 이 필드 안에 순서 번호(sequence number)를 삽입하는 방식으로 데이터 패킷에 송신자가 번호를 붙인다.
<br>이는 현존하는 데이터 전송 프로토콜에 채택된 방법이다.<br>수신자는 수신된 패킷이 재전송인지를 결정할 때는 이 순서 번호만 확인하면 된다.<br><br>
rdt2.1은 rdt2.0보다 두 배 많은 상태를 가지고 있다.
<br>이는 아래의 2가지를 반영해야 하기 때문이다.<br>
<br>프로토콜 상태가 현재 (송신자에 의해) 전송되고 있는지에 대한 반영
<br>(수신자가) 기다리고 있는 패킷이 순서 번호 0 또는 1을 가져야 하는지에 대한 반영
<br>
프로토콜 rdt2.1은 수신자로부터 송신자까지의 긍정 확인응답과 부정 확인응답을 모두 포함한다.
<br>
<br>순서가 바뀐 패킷이 수신되면, 수신자는 이미 전에 수신한 패킷에 대한 긍정 확인응답을 전송한다.
<br>손상된 패킷이 수신되면, 수신자는 부정 확인응답을 전송한다.
<br>NAK를 송신하는 것 대신에,<br>
가장 최근에 정확하게 수신된 패킷에 대해 ACK를 송신함으로써 NAK를 송신한 것과 같은 효과를 얻을 수 있다.<br>즉, 같은 패킷에 대해 2개의 ACK를 수신(즉, 중복(duplicate) ACK를 수신)한 송신자는<br>
수신자가 두 번 ACK 한 패킷의 다음 패킷을 정확하게 수신하지 못했다는 것을 알게 된다. (NAK의 의미와 동일)<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394879-965b1e5e-242d-43a3-a3e5-2981ae49fced.png" alt="rdt2.1 - 송신자" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br><img src="https://user-images.githubusercontent.com/86337233/211394881-dc92f052-6cc5-44a5-a6ac-716c07f3b6dd.png" alt="rdt2.1 - 수신자" referrerpolicy="no-referrer" style="width: 870px; max-width: 100%;"><br><br>rtd2.2는 rdt2.1과 다르게,<br>
<br>수신자가 반드시 ACK 메시지에 의해 확인 응답되는 패킷의 순서 번호를 포함해야 한다.

<br>이는 수신자 FSM의 make_pkt()에 ACK, 0 또는 ACK, 1인 인수를 넣어서 수행한다.


<br>송신자는 수신된 ACK 메시지에 의해 확인응답된 패킷의 순서 번호를 반드시 검사해야만 한다.

<br>이는송신자 FSM의 isACK()에 0 또는 1인 인수를 넣어서 수행한다.


<br><br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394883-973fc4cf-0f42-48e4-a1b5-42d72c818b9f.png" alt="rdt2.2 - 송신자" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br><img src="https://user-images.githubusercontent.com/86337233/211394888-1ad9f22d-9166-487c-a8aa-f0a380e03cfd.png" alt="rdt2.2 - 수신자" referrerpolicy="no-referrer" style="width: 870px; max-width: 100%;"><br><br>하위 채널이 패킷을 손실하는 경우도 생각해보자.<br>다음과 같은 두 가지 부가 내용을 프로토콜이 다루어야 한다.<br>
<br>어떻게 패킷 손실을 검출할 것인가?
<br>패킷 손실이 발생했을 때 어떤 행동을 할 것인가?
<br>
💡 송신자에게 손실된 패킷의 검출과 회복 책임을 부여한다.
<br>송신자가 데이터 패킷을 전송하고, 패킷 또는 수신자의 패킷에 대한 ACK를 손실했다고 가정하자.<br>어느 경우에서나 송신자에게는 수신자로부터 어떠한 응답도 없다.<br>즉, 송신자는 데이터 패킷이 손실되었는지, ACK가 손실되었는지, 패킷 또는 ACK가 단순히 지나치게 지연된 것인지를 알지 못한다.<br>만약 송신자가 패킷을 잃어버렸다고 확신할 정도로 충분한 시간을 기다릴 수만 있다면, 데이터 패킷은 간단하게 재전송될 수 있다.<br><br>그러나 송신자가 어떤 패킷을 손실했다는 것을 확신하기 위해 얼마나 오랫동안 기다려야 할까?<br>송신자는 적어도 다음의 시간만큼을 기다려야 한다.<br>
송신자와 수신자 사이의 왕복 시간 지연(중간 라우터에서의 버퍼링을 포함) + 수신 측에서 패킷을 처리하는 데 필요한 시간
<br>실제 상황에서 채택한 접근 방식은 이와 같다.<br>
💡 패킷 손실이 일어났을 만한 그런 시간을 선택하여, 만일 ACK가 이 시간 안에 수신되지 않는다면 패킷은 재전송된다.
<br>이것은 송신자 대 수신자 채널에서 중복 데이터 패킷(duplicate data packet)의 가능성을 포함하나,<br>
프로토콜 rdt2.2에서처럼 패킷의 순서 번호를 통하여 처리가 가능하다.<br><br>
시간 기반의 재전송 메커니즘을 구현하기 위해서는<br>
주어진 시간이 지난 후에 송신자를 인터럽트(중단)할 수 있는 카운트다운 타이머(countdown timer)가 필요하다.
<br>그러므로 송신자는 다음처럼 동작해야 한다.<br>
<br>매 패킷(첫 번째 또는 재전송 패킷)이 송신된 시간에 타이머를 시작한다.
<br>타이머 인터럽트에 반응한다. (즉, 적당한 행동을 취함)
<br>타이머를 멈춘다.
<br><br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394896-6188b35e-abc3-45a4-b3c1-2ad0fbc91738.png" alt="rdt3.0 - 송신자" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><br>아래의 4가지 다이어그램은 프로토콜이 패킷 손실 또는 지연 없이 어떻게 동작하는지와 손실된 데이터 패킷을 어떻게 처리하는지를 나타낸 것이다.<br><br><br>시간은 다이어그램의 위로부터 아래로 흐른다.<br>
패킷에 대한 수신 시간은 전송 지연과 전파 지연 때문에 패킷 전송 시간보다 더 늦다.
<br><br><br>
패킷의 순서 번호가 0과 1이 번갈아 일어나기 때문에 프로토콜 rdt3.0은 얼터네이팅 비트 프로토콜(alternating-bit protocol)이라고 부른다.
<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394899-41093893-28a0-4036-99ae-01bb820c7cc9.png" alt="무손실 동작" referrerpolicy="no-referrer" style="width: 350px; max-width: 100%;"><br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394906-3176a415-2270-493e-92a1-528344a5e00a.png" alt="패킷 손실" referrerpolicy="no-referrer" style="width: 350px; max-width: 100%;"><br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394858-92791860-cacf-4f94-ab98-f9d7611f337f.png" alt="ACK 손실" referrerpolicy="no-referrer" style="width: 350px; max-width: 100%;"><br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394848-a1a0d5ce-2190-4bfe-a14f-734a8f23b284.png" alt="조급한 타임아웃" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br>
<br><br><br>프로토콜 rdt3.0은 기능적으로는 정확한 프로토콜이나, 오늘날의 고속 네트워크에서 누구나 이것의 성능에 만족하는 것은 아니다.<br><br><br>
💡 rdt3.0의 핵심적인 성능 문제는 전송 후 대기(stop-and-wait) 프로토콜이라는 점 때문에 발생한다.
<br>전송 후 대기 프로토콜은 형편없는 송신자 이용률(utilization, 또는 효율)을 갖는다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394844-59fc6038-cbb8-4df0-823d-3a00bbc12081.png" alt="전송 후 대기 프로토콜의 동작" referrerpolicy="no-referrer" style="width: 380px; max-width: 100%;"><br><br>
<br><br><br><br><br>이에 대한 해결책은 다음과 같다.<br>
송신자에게 확인응답을 기다리기 전에 송신을 전송하도록 허용하는 것이다. = 파이프라이닝(pipelining)
<br><br><br>즉, 많은 전송 중인 송신자-수신자 패킷을 파이프라인에 채워 넣는 것이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394855-29852bd1-16df-41bf-94a6-46cbda8a13fa.png" alt="파이프라이닝된 프로토콜의 동작" referrerpolicy="no-referrer" style="width: 380px; max-width: 100%;"><br><br>
<br><br>아래의 그림들을 통해 만약 확인응답들을 기다리기 전에 송신자가 3개의 패킷을 전송하도록 허용한다면<br>
송신자의 이용률은 3배가 되리라는 것을 볼 수 있다.<br>즉, window size 만큼 효율이 증가한다는 것이다.<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394842-0a9b9db2-f2a5-4668-b5e8-bc8d634c323e.png" alt="전송 후 대기 동작" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394851-46a5b475-2554-47f4-b33e-5699f909e4cb.png" alt="파이프라이닝된 동작" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><br><br><br>파이프라이닝 방식은 신뢰적인 데이터 전송 프로토콜에서 다음과 같은 중요성을 지니고 있다.<br><br><br><br>각각의 전송 중인 패킷은 유일한 순서 번호를 가져야 한다.<br>전송 중인 확인응답(ACK)이 안 된 패킷이 여럿 있을지도 모르기 때문이다.<br><br><br><br>최소한 ‘송신자는 전송되었으나 확인응답되지 않은 패킷’을 버퍼링해야 한다.<br>정확하게 수신된 패킷의 버퍼링은 수신자에게서도 필요하다.<br><br><br><br>파이프라인 오류 회복의 두 가지 기본적인 접근 방법<br>
<br>GBN(Go-Back-N) : N부터 반복
<br>SR(Selective Repeat) : 선택적 반복
<br><br>
<br><br><br>
💡 GBN(Go-Back-N, N부터 반복) 프로토콜에서 송신자는 확인 응답을 기다리지 않고 여러 패킷을 전송(가능할 때)할 수 있다.
<br>
그러나 파이프라인에서 확인응답이 안 된 패킷의 최대 허용 수 N보다 크지 말아야 한다.
<br><br><br>아래 그림은 GBN 프로토콜에서 송신자 관점의 순서 번호 범위를 보여준다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394862-a28b3bd5-60b4-45b9-b16a-db23e1718476.png" alt="전송 후 대기 동작" referrerpolicy="no-referrer" style="width: 850px; max-width: 100%;"><br><br>
<br><br>
<br>확인응답이 안 된 가장 오래된 패킷의 순서 번호를 base로 정의한다.
<br>가장 작은 순서 번호를 nextseqnum(전송될 다음 패킷의 순서 번호)으로 정의한다.
<br><br><br>이를 통해서 순서 번호의 범위에서 4개의 간격을 식별할 수 있다.<br>
<br>
간격 [0, base-1] : 순서 번호는 이미 전송되고 확인응답이 된 패킷

<br>
간격 [base, nextseqnum-1] : 송신은 되었지만 아직 확인응답되지 않은 패킷

<br>
간격 [nextseqnum, base+N-1] : 상위 계층으로부터 데이터가 도착하면 바로 전송될 수 있는 패킷

<br>
base+N 이상<br>
→ 파이프라인에서 확인응답이 안 된 패킷(특히, 순서 번호 base를 가진 패킷)의 확인응답이 도착할 때까지 사용될 수 없다.

<br><br><br><br>
전송되었지만 아직 확인응답이 안 된 패킷을 위해,<br>
허용할 수 있는 순서 번호의 범위는 순서 번호의 범위상에서 크기가 N인 ‘윈도(window)’로 나타낸다.
<br>
<br>프로토콜이 동작할 때, 이 윈도는 순서 번호 공간에서 오른쪽으로 이동(slide)된다.
<br>N = 윈도 크기(window size)
<br><br><br>따라서 GBN 프로토콜은 슬라이딩 윈도 프로토콜(sliding-window protocol)이라고 부른다.<br><br><br><br>
실제로 패킷의 순서 번호는 패킷 헤더 안의 고정된 길이 필드에 포함된다.
<br>
<br>만약 k가 패킷 순서 번호 필드의 비트 수라면, 순서 번호의 범위는 [0, 2^k - 1]
<br>순서 번호의 제한된 범위에서, 순서 번호를 포함하는 모든 계산은 모듈로(modulo) 2^k 연산을 이용한다.
<br><br><br><br>
<br>base와 nextseqnum 변수를 추가한다.
<br>이러한 변수에서의 동작과 이러한 변수를 포함하는 조건부 동작을 추가한다.
<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394871-a9808254-013c-4858-b27c-6830d9602384.png" alt="GBN - 송신자" referrerpolicy="no-referrer" style="width: 770px; max-width: 100%;"><br><br>
<br><br>GBN 송신자는 다음과 같은 세 가지 타입의 이벤트에 반응해야 한다.<br><br><br>
1️⃣ 상위로부터의 호출
<br>
<br>
rdt_send()가 위로부터 호출되면, 송신자는 우선 윈도가 가득 찼는지 확인한다.<br>
(즉, N개의 아직 확인응답되지 않은 패킷이 있는지를 확인)

<br>
만약 윈도가 가득 차 있지 않다면 패킷이 생성되고 송신되며, 변수들이 적절하게 갱신된다.

<br>
만약 윈도가 가득 차 있다면, 단지 데이터를 상위 계층으로 반환한다.

<br>이는 윈도가 가득 차 있음을 가리키는 함축적인 의미이다.
<br>따라서 상위 계층은 나중에 rdt_send()를 다시 시도할 것이다.


<br><br><br>실제적인 구현에서 송신자는 아래와 같은 방법을 사용할 것이다.<br>
<br>이 데이터를 버퍼링한다. (그러나 즉시 송신하진 않음)
<br>오직 윈도가 가득 차 있지 않을 때만 rdt_send()를 호출하는 동기화 메커니즘을 사용한다.<br>
(e.g., semaphore 또는 flag)
<br><br><br>
2️⃣ ACK의 수신
<br>GBN 프로토콜에서<br>
순서 번호 n을 가진 패킷에 대한 확인응답은 누적 확인응답(cumulative acknowledgment)으로 인식된다.<br>이 누적 확인 응답은 수신 측에서 올바르게 수신된 n을 포함하여, n까지의 순서 번호를 가진 모든 패킷에 대한 확인 응답이다.<br><br><br>
3️⃣ 타임아웃 이벤트
<br>타이머는 손실된 데이터 또는 손실된 확인응답 패킷으로부터 회복하는 데 사용된다.<br>만약 타임아웃이 발생한다면, 송신자는 이전에 전송되었지만 아직 확인응답되지 않은 !!모든!! 패킷을 다시 송신한다.<br><br><br>위의 그림에서 송신자는<br>
가장 오래된 ‘전송했지만, 아직 확인응답 안 된 패킷’에 대한 타이머로 생각될 수 있는 단일 타이머를 사용한다.<br>
<br>만일 한 ACK가 수신되었지만, 추가로 ‘전송했지만, 아직 확인응답 안 된 패킷’이 아직 존재한다면,<br>
타이머를 다시 시작한다.
<br>만약 아직 확인응답 안 된 패킷이 없다면, 타이머를 멈춘다.
<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394884-f585ef99-e84a-4b88-a268-794e31d1ad38.png" alt="GBN - 송신자" referrerpolicy="no-referrer" style="width: 580px; max-width: 100%;"><br><br>
<br><br>
<br>
만약 순서 번호 n을 가진 패킷이 오류 없이, 그리고 순서대로 수신된다면<br>
(= 상위 계층에 마지막으로 전달된 데이터가 순서 번호 n-1을 가진 패킷에서 온 것이라면)<br>
수신자는 패킷 n에 대한 ACK를 송신하고 상위 계층에 패킷의 데이터 부분을 전달한다.

<br>
그 외의 경우에는 수신자는 그 패킷을 버리고 가장 최근에 제대로 수신된 순서의 패킷에 대한 ACK를 재전송한다.

<br><br><br><br>지금 패킷 n이 수신되어야 하지만, 그 사람 다음의 패킷 n+1이 먼저 도착했다고 가정하자.<br>수신자는 상위 계층에 데이터를 전달해야 한다.<br>데이터가 순서대로 전달되어야 하므로, 수신자는 패킷 n+1을 저장하고<br>
나중에 패킷 n이 수신되고 전달된 후에 상위 계층에 이 패킷을 전달한다.<br><br><br>그러나 만일 패킷 n이 손실된다면, GBN 재전송 규칙에 따라 수신자에게는 패킷 n과 n+1이 모두 재전송될 것이다.<br>
💡 이점 : 수신자 버퍼링이 간단하다 (수신자는 어떤 순서가 잘못된 패킷에 대해 버퍼링을 할 필요가 없다!)
<br>
<br>송신자가 유지해야 하는 것

<br>윈도 상위와 하위 경계
<br>이 윈도 안에 있는 nextseqnum 위치


<br>수신자가 유지해야 하는 것 : 다음 순서 패킷의 순서 번호
<br><br><br>물론, 올바르게 수신된 패킷을 버리는 것의 단점은 그 패킷의 재전송이 손실되거나 왜곡될 수 있으므로 많은 재전송이 필요할 수도 있다는 것이다.<br><br><br><br><br><br>아래 그림은 윈도 크기가 4 패킷인 경우에 대한 GBN 프로토콜의 동작을 보여준다.<br>
<br>윈도 크기가 4 → 송신자는 패킷 0부터 3까지 송신한다.
<br>송신을 계속하기 전에 하나 이상의 패킷이 긍정 확인응답되는 것을 기다려야 한다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394894-0ebcca6d-1174-446b-a2c4-e74ca263ab63.png" alt="GBN에서의 동작" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>
<br>
ACK0, ACK1처럼 각각의 성공적인 ACK가 수신되었을 때

<br>윈도는 앞으로 이동한다.
<br>송신자는 하나의 새로운 패킷(pkt4와 pkt5, 각각)을 전송한다.


<br>
수신 측에서는 pkt2가 손실되었으므로 pkt3, 4, 5는 순서가 잘못된 패킷으로 발견되어 제거된다.

<br><br><br><br>앞에서 본, 확장된(extended) FSM을 다시 떠올려보자.<br>이 구현은 발생할 수 있는 다양한 이벤트에 대한 대응으로 취할 수 있는 동작을 구현하는 다양한 절차들과 유사하다.<br><br><br>
이러한 이벤트 기반 프로그래밍(event-based programming)에서의 다양한 프로시저들은<br>
프로토콜 스택에서 다른 프로세저에 의해 야기되거나 인터럽트의 결과로 요청될 것이다.
<br><br><br>송신자에서 이러한 이벤트들에 대한 예시로는 다음과 같다.<br>
<br>rdt_send()를 호출하기 위한 상위 계층 개체로부터의 호출
<br>타이머 인터럽트
<br>패킷이 도착했을 때 rdt_rcv()를 호출하기 위한 하위 계층으로부터의 호출
<br><br><br><br>GBN 프로토콜은 송신자가 패킷으로 파이프라인을 채우는 것을 통해 전송 후 대기 프로토콜에서의 채널 이용률 문제를 피하도록 하였다.<br><br><br>그러나 GBN 자체에는 성능 문제를 겪는 시나리오들이 존재한다.<br>윈도 크기와 대역폭 지연(bandwidth-delay) 곱의 결과가 모두 클 때, 많은 패킷이 파이프라인에 있을 수 있다.<br><br><br>GBN은 패킷 하나의 오류 때문에 많은 패킷을 재전송하므로, 많은 패킷을 불필요하게 재전송하는 경우가 발생한다.<br>
채널 오류의 확률이 증가할수록 파이프라인은 불필요한 재전송 데이터로 채워진다.
<br><br>
<br><br><br>
💡 SR(Selective Repeat, 선택적 반복) 프로토콜은<br>
수신자에서 오류(손실되거나 변조된)가 발생한 패킷을 수신했다고 의심되는 패킷만을 재전송한다.
<br>
<br>이를 통해서 SR는 불필요한 재전송을 피한다.
<br>필요에 따라 각각의 개별적인 재전송은 수신자가 올바르게 수신된 패킷에 대한 개별적인 확인응답을 요구할 것이다.
<br><br><br>윈도 크기 N은 파이프라인에서 아직 확인응답이 안 된 패킷 수를 제한하는 데 사용된다.<br>그러나 GBN과는 달리, 송신자는 윈도에 있는 몇몇 패킷에 대한 ACK를 이미 수신했을 것이다.<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394904-44a6f9a3-d889-487b-b88f-dbeb04e73e59.png" alt="순서 번호 공간에 대한 SR 송신자와 수신자 관점" referrerpolicy="no-referrer" style="width: 720px; max-width: 100%;"><br><br>
<br><br>
<br>
SR 수신자는 패킷의 순서와는 무관하게 손상 없이 수신된 패킷에 대한 확인응답을 할 것이다.

<br>
빠진 패킷이 존재하는 경우

<br>순서가 바뀐 패킷은 빠진 패킷이 수신될 때까지 버퍼에 저장하고,<br>
(빠진 패킷 = 아직 도착하지 않은 더 낮은 순서 번호를 가진 패킷)
<br>빠진 패킷이 수신된 시점에서 일련의 패킷을 순서대로 상위 계층에 전달할 수 있다.<br>
(re-order &amp; reassemble the packets → in-order delivery to upper layer)


<br><br><br><br>
1️⃣ 상위로부터 데이터 수신
<br>상위에서 데이터가 수신될 때, SR 송신자는 패킷의 다음 순서 번호를 검사한다.<br>
<br>순서 번호가 송신자 윈도 내에 있으면 데이터는 패킷으로 송신된다.
<br>그렇지 않으면 GBN처럼 버퍼에 나중에 전송하기 위해 되돌려진다.
<br><br><br>
2️⃣ 타임아웃
<br>타이머는 손실된 패킷을 보호하기 위해 재사용된다.<br>그러나 타임아웃 시 오직 한 패킷만이 전송되기 때문에, 각 패킷은 자신의 논리 타이머가 있어야 한다.<br><br><br>
3️⃣ ACK 수신
<br>ACK가 수신되었을 때, SR 송신자는 그 ACK가 윈도 내에 있다면 그 패킷을 수신된 것으로 표기한다.<br>
<br>만약 패킷 순서 번호가 send_base와 같다면, 윈도 베이스는 가장 작은 순서 번호를 가진 아직 확인응답되지 않은 패킷으로 옮겨진다.
<br>만약 윈도가 이동하고 윈도 내의 순서 번호를 가진 미전송 패킷이 있다면, 이 패킷들은 전송된다.
<br><br><br><br>
1️⃣ [rcv_base, rcv_base+N-1] 내의 순서 번호를 가진 패킷이 손상 없이 수신된다.
<br>이 경우는 수신된 패킷이 수신자의 윈도에 속하는 것이며, 선택적인 ACK 패킷이 송신자에게 회신된다.<br>
<br>만약 이 패킷이 이전에 수신되지 않았던 것이라면 버퍼에 저장된다.
<br>만약 이 패킷이 수신 윈도의 base와 같은 순서 번호를 가졌다면,<br>
이 패킷과 이전에 버퍼에 저장되어 연속적으로 번호를 가진(rcv_base로 시작하는) 패킷들은 상위 계층으로 전달된다.
<br><br><br>
2️⃣ [rcv_base-N, rcv_base-1] 내의 순서 번호를 가진 패킷이 수신된다.
<br>이 경우에는 이 패킷이 수신자가 이전에 확인응답한 것이라도 ACK가 생성되어야 한다.<br><br><br>
3️⃣ 그 외의 경우, 패킷을 무시한다.
<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394908-f90e0b68-e305-486a-94b4-20ce10469130.png" alt="SR 동자" referrerpolicy="no-referrer" style="width: 620px; max-width: 100%;"><br><br>
<br><br>
<br>처음에 pkt3, 4, 5를 버퍼에 저장한다.
<br>마지막으로 pkt2가 수신되었을 때 pkt2와 함께 상위 계층에 전달한다.
<br><br><br><br>SR 수신자 이벤트와 행동의 2단계 : [rcv_base-N, rcv_base-1] 내의 순서 번호를 가진 패킷이 수신된다.<br><br><br>
여기서 수신자가 현재의 윈도 base보다 작은 특정 순서 번호를 가진 ‘이미 수신된 패킷’을 무시하지 않고 재확인 응답을 하는 것이 중요하다!
<br>e.g.,<br>
송신자와 수신자의 순서 번호 공간을 줬을 때, 수신자가 송신자에게 보내는 send_base 패킷에 대한 ACK가 없다면<br>
(우리에게는 수신자가 그 패킷을 이미 수신했음이 분명하더라도) 결국 송신자는 send_base 패킷을 재전송할 것이다.<br><br><br>만약 수신자가 이 패킷에 대한 확인응답을 하지 않는다면, 송신자의 윈도는 결코 앞으로 이동하지 않을 것이다.<br><br><br>
💡 송신자와 수신자는 올바른 수신과 그렇지 않은 수신에 대해 항상 같은 관점을 갖지는 않을 것이다.
<br>→ 이는 SR 프로토콜에서 송신자와 수신자의 윈도가 항상 같지 않다는 것을 뜻한다.<br><br><br><br><br><br>송신자와 수신자 윈도 사이의 동기화 부족은 순서 번호의 한정된 범위에 직면했을 때 중대한 결과를 가져온다.<br><br><br>e.g.,<br>
<br>한정된 범위의 네 패킷 순서 번호 0, 1, 2, 3
<br>윈도 크기 : 3
<br><br><br>0부터 2까지의 패킷이 전송되어 올바로 수신되고, 수신자에게서 확인이 되었다고 가정하자.<br>그 순간에 수신자의 윈도는 각각의 순서 번호가 3, 0, 1인 4, 5, 6번째 패킷에 있다.<br><br><br><br>
<br>
처음 3개의 패킷에 대한 ACK가 손실되고, 송신자는 이 패킷을 재전송한다.

<br>
수신자는 순서 번호가 0인 패킷(처음 보낸 패킷의 복사본)을 수신한다.

<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394834-3ca59693-1674-474f-b726-92b6b4db0f61.png" alt="첫 번째 시나리오" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;"><br><br>
<br><br><br>
<br>
처음 3개의 패킷에 대한 ACK가 모두 올바르게 전달되었다.

<br>
송신자는 자신의 윈도를 앞으로 이동시켜, 각각의 순서 번호가 3, 0, 1인 4, 5, 6번째 패킷을 보낸다.

<br>
순서 번호 3을 가진 패킷이 손실되고, 순서 번호 0을 가진 패킷(새로운 데이터를 포함한 패킷)은 도착한다.

<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211394820-f3805860-5058-49e5-8e01-c63729a33699.png" alt="두 번째 시나리오" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;"><br><br>
<br><br><br>수신자는 송신자의 행동을 볼 수 없다.<br><br><br>모든 수신자는 채널을 통해 받고, 채널을 통해 보내는 메시지의 순서를 관찰하는데, 이는 위의 두 가지 시나리오가 똑같다.<br>즉, 다섯 번째 패킷의 원래 전송과 첫 번째 패킷의 재전송을 구별할 방법은 없다.<br><br><br><br>
윈도 크기는 SR 프로토콜에 대한 순서 번호 공간 크기의 절반보다 작거나 같아야 한다.
<br><br>
<br><br><br>맨 앞에서 패킷들은 송신자와 수신자 사이의 채널 안에서 순서가 바뀔 수 없다는 가정 하에 신뢰적인 데이터 전송 프로토콜에 대한 설명을 진행하였다.<br>
이는 일반적으로 송신자와 수신자가 단일한 물리적 선으로 연결되어 있을 때 적합한 가정이다.<br>
하지만 둘을 연결하는 ‘채널’이 네트워크일 때는 패킷 순서 바뀜이 일어날 수 있다.
<br><br><br>패킷 순서 바뀜 현상으로, 송신자와 수신자의 윈도가 x를 포함하지 않고 있더라도<br>
순서 번호 또는 확인응답 번호 x를 가진 오래된 패킷의 복사본들이 생길 수 있다.<br><br><br>
패킷 순서가 바뀌는 채널이라는 것은 본질적으로 패킷들을 버퍼에 저장하고, 나중에 어느 때나 이 패킷들을 임의로 내보낸다고 간주할 수 있다.
<br>순서 번호가 재사용될 수 있으므로 그런 중복된 패킷들을 막을 수 있는 조치가 필요하다.<br><br><br>실제 방식은 송신자가 이전에 송신된 순서 번호 x를 가진 패킷들이<br>
더는 네트워크 상에 없음을 어느 정도 ‘확신’할 때까지 순서 번호가 재사용되지 않음을 확실히 하는 것이다.<br>이는 패킷이 어느 일정 시간 이상으로 네트워크에서 존재할 수 없다는 가정에 의해 이루어진다.<br><br>
<br><br><br><br>전송된 패킷 안의 비트 오류를 발견하는 데 사용된다.<br><br><br><br>채널 안에서 패킷이 손실되었기 때문에 발생되는 패킷(또는 이것의 ACK)의 타임아웃/재전송에 사용된다.<br><br><br><br>발생 이유<br>
<br>
패킷이 지연되었지만 손실되지는 않았을 경우 (조기 타임 아웃)

<br>
패킷이 수신자에 의해 수신되었으나 수신자에서 송신자로의 ACK가 손실되었을 경우

<br>→ 수신자에 의해 수신되는 패킷은 중복으로 복사(수신)된 패킷일 수 있다.<br><br><br><br>송신자에서 수신자로 가는 데이터 패킷의 순서 번호를 붙이기 위해 사용된다.<br>
<br>수신자 패킷의 순서 번호의 간격 : 수신자가 손실된 패킷을 검사하게 한다.
<br>중복된 순서 번호를 갖는 패킷 : 수신자가 패킷의 중복 복사를 검사하게 한다.
<br><br><br><br>수신자가 한 패킷 또는 패킷 집합이 정확히 수신되었다는 응답을 송신자에게 하기 위해 사용된다.<br>
<br>일반적으로 패킷 또는 이미 확인응답된 패킷들의 순서 번호를 전달한다.
<br>프로토콜에 따라 개별적이거나 누적된 것일 수 있다.
<br><br><br><br>수신자가 패킷이 정확히 수신되지 않았다는 응답을 송신자에게 하기 위해 사용된다.<br>
<br>일반적으로 정확히 수신되지 않은 패킷의 순서 번호를 전달한다.
<br><br><br><br>송신자는 주어진 범위에 있는 순서 번호를 가진 패킷만 전송하도록 제한될 수 있다.<br>확인응답은 없지만 허가된 패킷이 전송될 수 있으므로, 송신자의 이용률은 전송 후 대기 모드의 동작보다 증가할 수 있다.<br>윈도 크기는 수신자의 메시지를 수신하고 버퍼링하는 능력, 네트워크의 혼잡 정도, 또는 두 가지 모두에 근거하여 설정된다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.4 신뢰적인 데이터 전송의 원리/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Sun, 16 Jun 2024 07:51:57 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\attachments\pasted-image-20240614020554.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.4-신뢰적인-데이터-전송의-원리\attachments\pasted-image-20240614020554.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.5 연결지향형 트랜스포트: TCP]]></title><description><![CDATA[ 
 <br><br><br>
💡 TCP는 애플리케이션 프로세스가 데이터를 다른 프로세스에게 보내기 전에,<br>
두 프로세스가 서로 ’핸드셰이크’를 먼저 해야 하므로 연결지향형(connection-oriented)이다.
<br>즉, 데이터 전송을 보장하는 파라미터들을 각자 설정하기 위한 어떤 사전 세그먼트들을 보내야 한다.<br><br><br>TCP 연결은 두 통신 종단 시스템의 TCP에 존재하는 상태를 공유하는 논리적인 것이다.<br><br><br>TCP 연결은 전이중 서비스(full-duplex service)를 제공한다.<br>
만약 호스트 A의 프로세스와 호스트 B의 프로세스 사이에 TCP 연결이 있다면,<br>
애플리케이션 계층 데이터는 B에서 A로 흐르는 동시에 A에서 B로 흐를 수 있다.
<br><br><br>TCP 연결은 항상 단일 송신자와 단일 수신자 사이의 점대점(point-to-point)이다.<br>따라서 단일 송신 동작으로 한 송신자가 여러 수신자에게 데이터를 전송하는 ‘멀티캐스팅(multicasting)’은 TCP에서는 불가능하다.<br><br><br><br>
<br>
클라이언트 프로세스(client process) : 연결을 초기화하는 프로세스

<br>
서버 프로세스(server process)

<br><br><br><br>(3.5.6에서 더 자세히 다룰 예정)<br><br><br>
<br>
클라이언트 애플리케이션 프로세스는 서버의 프로세스와 연결을 설정하기를 원한다고 TCP 클라이언트에게 먼저 알린다.

<br>
클라이언트의 트랜스포트 계층은 서버의 TCP와의 TCP 연결 설정을 진행한다.

즉, 클라이언트가 먼저 특별한 TCP 세그먼트를 보낸다.


<br>
서버는 두 번째 특별한 TCP 세그먼트로 응답한다.

<br>
마지막으로, 클라이언트가 세 번째 특별한 세그먼트로 다시 응답한다.

<br><br><br>
<br>
처음 2개의 세그먼트에는 페이로드(payload, 애플리케이션 계층 데이터)가 없다.

<br>
세 번째 세그먼트는 페이로드를 포함할 수 있다.

<br><br><br><br>일단 TCP 연결이 설정되면, 두 애플리케이션 프로세스는 서로 데이터를 보낼 수 있다.<br>
<br>
클라이언트 프로세스는 소켓(프로세스의 관문)을 통해 데이터의 스트림을 전달한다.

<br>
데이터가 관문을 통해 전달되면, 이제 데이터는 클라이언트에서 동작하고 있는 TCP에 맡겨진다.

<br>TCP는 초기 세 방향 핸드셰이크 동안 준비된 버퍼 중의 하나인 연결의 송신 버퍼(send buffer)로 데이터를 보낸다.
<br>때때로 TCP는 송신 버퍼에서 데이터 묶음을 만들어서 네트워크로 보낸다.<br>
(TCP가 언제 버퍼된 데이터를 전송해야 하는지는 정해져 있지 않음)


<br><br><br><br>
세그먼트로 모아 담을 수 있는 최대 데이터 양은 최대 세그먼트 크기(maximum segment size, MSS)로 제한된다.
<br><br><br>MSS를 결정하는 요소<br>
<br>
로컬 송신 호스트에 의해 전송될 수 있는 가장 큰 링크 계층 프레임의 길이<br>
(최대 전송 단위(maximum transmission unit, MTU)

<br>
TCP 세그먼트(IP 데이터그램 안에 캡슐화되었을 때)와 TCP/IP 헤더 길이(통상 40바이트)가 단일 링크 계층 프레임에 딱 맞도록 한다.

<br><br><br>
💡 MSS는 헤더를 포함하는 TCP 세그먼트의 최대 크기가 아니라,   세그먼트에 있는 애플리케이션 계층 데이터에 대한 최대 크기이다.
<br><br><br><br>
TCP 헤더 + 클라이언트 데이터
<br>
<br>
네트워크 계층에 전달되어 네트워크 계층 IP 데이터그램 안에 각각 캡슐화된다.

<br>
세그먼트는 네트워크로 송신된다.

<br>
TCP가 상대에게서 세그먼트를 수신했을 때, 세그먼트의 데이터는 TCP 연결의 수신 버퍼에 위치한다.<br>
→ 애플리케이션은 이 버퍼로부터 데이터의 스트림을 읽는다.

<br><br><br><br><br><br>
TCP 연결의 양 끝은 각각 자신의 송신 버퍼와 수신 버퍼를 갖고 있다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437579-b86e832e-cd39-4707-a212-9ee7c7d6869f.png" alt="TCP 송신 버퍼와 수신 버퍼" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>
💡 즉, TCP 연결은 한쪽 호스트에서의 버퍼, 변수, 프로세스에 대한 소켓 연결과<br>
다른 쪽 호스트에서의 버퍼, 변수, 프로세스에 대한 소켓 연결의 집합으로 이루어진다.
<br><br>
<br><br><br><br><br>
<br>
출발지와 목적지 포트 번호(source and destination port number)

<br>
체크섬 필드(checksum field)

<br>
32비트 순서 번호 필드(sequence number field)

<br>
32비트 확인응답 번호 필드(acknowledgement number field)

<br>
16비트 수신 윈도(receive window) : 흐름 제어에 사용된다.<br>
(수신자가 받아들이려는 바이트의 크기를 나타내는데 사용됨)

<br>
4비트 헤더 길이 필드(header length field) : 32비트 워드 단위로 TCP 헤더의 길이를 나타낸다.

<br>
옵션 필드(option field)

<br>이 필드는 선택적이고 가변적인 길이를 가진다.
<br>송신자와 수신자가 최대 세그먼트 크기(MSS)를 협상하거나 고속 네트워크에서 사용하기 위한 윈도 확장 요소로 이용된다.


<br>
플래그 필드(flag field) : 6비트를 포함한다.

<br>ACK 비트 : 확인응답 필드에 있는 값이 유용함을 가리키는 데 사용된다.
<br>RST, SYN, FIN 비트 : 연결 설정과 해제에 사용된다.
<br>PSH 비트 : 이 비트가 설정되었다면 이것은 수신자가 데이터를 상위 계층에 즉시 전달해야 함을 가리킨다.
<br>URG 비트

<br>이 세그먼트에서 송신 측 상위 계층 개체가 ‘긴급’으로 표시하는 데이터임을 가리킨다.
<br>이 긴급 데이터의 마지막 바이트의 위치는 16비트의 긴급 데이터 포인터 필드(urgent data pointer field)에 의해 가리켜진다.




<br><br><br><br>애플리케이션 데이터의 일정량을 담는다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437603-f0cab27b-5fc5-4dd3-a7e5-b6d4a23797e7.png" alt="TCP 세그먼트 구조" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br><br>MSS는 세그먼트 데이터 필드의 크기를 제한한다.<br>
<br>큰 파일 전송 시, 일반적으로 MSS 크기로 파일을 분절한다.
<br>많은 대화식 애플리케이션은 MSS보다 작은 양의 데이터를 전송한다.
<br><br><br><br>이 두 필드는 TCP의 신뢰적인 데이터 전송 서비스의 중대한 부분이다.<br><br><br><br>
TCP는 데이터를 구조화되어 있지 않고 단지 순서대로 정렬되어 있는 바이트 스트림으로 본다.
<br>
세그먼트에 대한 순서 번호는 세그먼트에 있는 첫 번째 바이트의 바이트 스트림 번호다.
<br><br><br>e.g.,<br>
<br>데이터 스트림은 500,000 바이트로 구성된 파일이라고 가정한다.
<br>MSS는 1,000 바이트
<br>데이터 스트림의 첫 번째 바이트는 0으로 설정한다.
<br><br><br>아래 그림처럼 TCP는 데이터 스트림으로부터 500개의 세그먼트들을 구성하며, 각 세그먼트가 할당받는 순서 번호는 다음과 같다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437602-133ef178-ba22-4269-86c4-7444efd50f76.png" alt="TCP 세그먼트" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br>
💡 각각의 순서 번호는 적절한 TCP 세그먼트의 헤더 내부의 순서 번호 필드에 삽입된다.
<br><br><br><br>TCP는 전이중 방식임을 상기하자.<br>
(호스트 A가 호스트 B로 데이터를 송신하는 동안에 호스트 B로부터 데이터를 수신하게 해줌)<br><br><br>호스트 B로부터 도착한 각 세그먼트는 B로부터 A로 들어온 데이터에 대한 순서 번호를 갖는다.<br>
💡 호스트 A가 자신의 세그먼트에 삽입하는 확인응답 번호는 호스트 A가 호스트 B로부터 기대하는 다음 바이트의 순서 번호다.
<br><br><br>e.g.,<br>
호스트 A가 호스트 B로부터<br>
0 ~ 535의 바이트를 포함하는 어떤 세그먼트와 900 ~ 1,000의 바이트를 포함하는 또 다른 세그먼트를 수신했다고 가정하자.<br>(어떤 이유 때문인지 몰라도, 호스트 A는 그 사이 536~899의 바이트를 아직 수신하지 않았음)<br><br><br>호스트 A는 B의 데이터 스트림을 재생성하기 위해 536번째(와 그 다음의) 바이트를 아직 기다리고 있다.<br>그러므로 B에 대한 A의 다음 세그먼트이 확인응답 번호 필드에 536을 가질 것이다.<br><br><br>
TCP는 스트림에서 첫 번째 잃어버린 바이트까지의 바이트들까지만 확인응답하기 때문에,<br>
TCP는 누적 확인응답(cumulative acknowledgment)을 제공한다고 한다.
<br><br><br><br><br><br>위 예에서 호스트 A는 세 번째 세그먼트(900~1,000 값의 바이트)를 두 번째 세그먼트(536~899 값의 바이트)가 수신되기 전에 수신했다.<br>즉, 세 번째 세그먼트는 순서가 틀리게 도착했다.<br><br><br>이 상황에서 호스트는 어떻게 행동을 할까?<br>
TCP RFC는 TCP 연결에서 순서가 바뀐 세그먼트를 수신할 때 호스트가 어떤 행동을 취해야 하는지에 대한 어떤 규칙도 부여하지 않았고,<br>
TCP 구현 개발자에게 맡기고 있다.
<br><br><br>두 가지 선택지<br>
<br>
수신자가 순서가 바뀐 세그먼트를 즉시 버린다.

<br>
수신자는 순서가 바뀐 데이터를 보유하고, 빈 공간에 잃어버린 데이터를 채우기 위해 기다린다.

<br>후자가 네트워크 대역폭 관점에서는 효율적이며, 실제에서도 취하는 방법이다.<br><br><br><br><br>
<br>원격 로그인을 위해 사용되는 유명한 애플리케이션 계층 프로토콜
<br>TCP 상에서 실행되며, 한 쌍의 호스트들 사이에서 동작하도록 설계되었다.
<br><br><br><br><br><br>호스트 A가 호스트 B로 텔넷 세션을 시작한다고 가정하자.<br>
<br>호스트 A가 세션을 시작하므로 클라이언트
<br>호스트 B는 서버
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437590-612a9b6b-4d54-49b3-ad1a-d0d925d64da7.png" alt="텔넷 애플리케이션" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>
💡 세그먼트의 순서 번호 = 데이터 필드 안에 있는 첫 번째 바이트의 순서 번호
<br>
<br>클라이언트의 초기 순서 번호 : 42 → 클라이언트에서 송신된 첫 번째 세그먼트는 순서 번호 42를 가진다.
<br>서버의 초기 순서 번호 : 79 → 서버에서 송신된 첫 번째 세그먼트는 순서 번호 79를 가질 것이다.
<br><br><br>
💡 확인응답 번호 = 호스트가 기다리는 데이터의 다음 바이트의 순서 번호
<br>TCP 연결이 설정된 후에 어떤 데이터도 송신되기 전,<br>
<br>클라이언트는 바이트 79를 기다리고 있다.
<br>서버는 바이트 42를 기다리고 있다.
<br><br><br><br><br><br>사용자가 하나의 문자 ‘C’를 입력하고, 커피를 마신다고 가정하자.<br>위 그림처럼 3개의 세그먼트가 송신된다. = 세 방향 핸드셰이크(three-way handshake)<br><br><br>
1️⃣ 첫 번째 세그먼트
<br>
<br>
클라이언트에서 서버로 송신된다.

<br>
순서 번호 필드 안에 42를 가진다.

<br><br><br>
2️⃣ 두 번째 세그먼트
<br>
<br>
서버에서 클라이언트로 송신된다.

<br>
두 가지 목적을 가진다.

<br>
수신하는 서버에게 데이터에 대한 확인응답을 제공

확인응답 필드 안에 43을 넣음으로써,<br>
(1) 서버는 클라이언트에게 바이트 42를 성공적으로 수신했고<br>
(2) 앞으로 바이트 43을 기다린다는 것을 말해준다.


<br>
문자 ‘C’를 반대로 반향되도록 하는 것
→ 그의 데이터 필드에 ‘C’의 ASCII 표현을 한다.

두 번째 세그먼트는 TCP 연결의 서버-클라이언트 데이터 흐름의 최초 순서 번호인 순서 79를 갖는다.<br>
(이는 서버가 보내는 데이터의 맨 첫번째 바이트)




<br><br><br>
💡 클라이언트/서버 데이터에 대한 확인응답은 서버와 클라이언트 간에서 데이터를 운반하는 세그먼트 안에서 전달된다.<br>
= 확인응답은 서버-클라이언트 데이터 세그먼트 상에서 피기백된다(piggybacked)
<br><br><br>
3️⃣ 세 번째 세그먼트
<br>
<br>
클라이언트에서 서버로 송신된다.

<br>
목적 : 서버로부터 수신한 데이터에 대한 확인응답을 하는 것

<br>이 세그먼트는 빈 데이터 필드를 갖는다.
<br>즉, 확인응답은 어떤 클라이언트-서버 데이터와 함께 피기백되지 않는다.


<br>
세그먼트는 확인응답 필드 안에 80을 갖는다.

<br>클라이언트가 순서 번호 79의 바이트를 통해 바이트의 스트림을 수신했기 때문이다.
<br>앞으로 80으로 시작하는 바이트를 기다린다.


<br><br><br>
이 세그먼트가 데이터를 포함하지 않는데도 순서 번호를 갖는다는 것이 이상하지만,<br>
TCP가 순서 번호 필드를 갖고 있으므로 세그먼트 역시 어떤 순서 번호를 가져야 한다.
<br><br>
<br><br><br>
💡 TCP는 손실 세그먼트를 발견하기 위해 타임아웃/재전송 매커니즘을 사용한다.
<br>타임아웃은 연결의 왕복 시간(round-trip time, RTT)보다 좀 커야 한다.<br><br><br><br>
💡 왕복 시간(round-trip time, RTT) : 세그먼트가 전송된 시간부터 긍정 확인응답될 때까지의 시간
<br>TCP가 송신자와 수신자 사이에 왕복 시간을 어떻게 예측하는지에 대하여 알아보자.<br><br><br>✅  SampleRTT라고 표시되는 세그먼트에 대한 RTT 샘플<br>
: 세그먼트가 송신된 시간(IP에게 넘겨진 시간)으로부터 그 세그먼트에 대한 긍정응답이 도착한 시간까지의 시간 길이<br>대부분의 TCP는 한 번에 하나의 SampleRTT 측정만을 시행한다.<br>
<br>즉, 어떤 시점에서 SampleRTT는 전송되었지만 현재까지 확인응답이 없는 세그먼트 중 하나에 대해서만 측정된다.
<br>이는 대략 왕복 시간마다 SampleRTT의 새로운 값을 얻게 한다.
<br><br><br>✅ SampleRTT 값은 라우터에서의 혼잡과 종단 시스템에서의 부하 변화 때문에 세그먼트마다 다르기 때문에<br>
대체로 RTT를 추정하기 위해 SampleRTT 값의 평균값을 채택한다.<br>→ TCP는 SampleRTT 값의 평균(EstimatedRTT)을 유지한다.<br>
EstimatedRTT = (1 - α) × EstimatedRTT + α × SampleRTT<br>
(권장되는 α의 값 : 0.125)
<br><br><br>
💡 EstimatedRTT는 SampleRTT의 가중평균(weighted average)이다.
<br>
<br>
이 가중평균은 예전 샘플보다 최근 샘플에 높은 가중치를 준다.

<br>
최신 샘플들이 네트워크상의 현재 혼잡을 더 잘 반영한다. → 지수적 가중 이동 평균(exponential weighted moving average, EWMA)

<br><br><br>아래는 TCP 연결에 대해 α = 1/8의 값에 대한 SampleRTT 값들과 EstimatedRTT를 보여준다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437598-d947f320-f340-4b47-8f64-fb2fc7558e95.png" alt="RTT 샘플과 RTT 추정치" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>✅  DevRTT는 RTT 변화율을 의미한다.<br>이는 SampleRTT가 EstimatedRTT로부터 얼마나 많이 벗어나는지에 대한 측으로 정의한다.<br>
DevRTT = (1 - β) × DevRTT + β × | SampleRTT - EstimatedRTT |<br>
(권장되는 β의 값 : 0.25)
<br>DevRTT는 SampleRTT와 EstimatedRTT 값 차이의 EWMA이다.<br><br><br><br>주어진 EstimatedRTT 와 DevRTT 값에서, TCP 타임아웃 주기에는 어떤 값이 사용되어야 하는가?<br><br><br>
<br>
주기는 EstimatedRTT보다 크거나 같아야 한다.<br>
(그렇지 않다면 불필요한 재전송이 보내질 것)

<br>
EstimatedRTT보다 너무 크면 안된다.<br>
(너무 크면 세그먼트를 잃었을 때, TCP는 세그먼트의 즉각적인 재전송을 하지 않게 됨)

<br>→ 타임아웃값은 EstimatedRTT에 약간의 여윳값을 더한 값으로 설정하는 것이 바람직하다.<br><br><br>
TimeoutInterval = EstimatedRTT + 4 × DevRTT
<br>
<br>
초기 TimeoutInterval의 값으로는 1초를 권고한다.

<br>
타임아웃이 발생할 때, TimeoutInterval의 값은 두 배로 하여<br>
조만간 확인응답할 후속 세그먼트에게 발생할 수 있는 조기 타임아웃을 피하도록 한다.

<br><br>
<br><br><br>
💡 TCP는 IP의 비신뢰적인 최선형 서비스에서 신뢰적인 데이터 전송 서비스(reliable data transfer service)를 제공한다.
<br>
<br>
프로세스가 자신의 수신 버퍼로부터 읽은 데이터 스트림이 손상되지 않음을 보장한다.

<br>
중복이 없다는 것과 순서가 유지된다는 것을 보장한다.

<br><br><br>즉, 바이트 스트림은 송신자가 전송한 것과 같은 바이트 스트림이다.<br><br><br>타이머 관리는 상당한 오버헤드를 유발할 수 있다.<br>따라서 전송되었지만 확인응답이 안 된 다수의 세그먼트들이 있다고 하더라도,<br>
권장되는 TCP 타이머 관리 절차에서는 오직 단일 재전송 타이머를 사용한다.<br>(이 장에서 설명하는 TCP 프로토콜은 단일 타이머를 따름)<br><br><br><br>
1️⃣ 상위 애플리케이션으로부터 수신된 데이터
<br>첫 번째 이벤트 발생으로,<br>
<br>TCP는 애플리케이션으로부터 데이터를 받고,
<br>세그먼트로 이 데이터를 캡슐화하고,
<br>IP에게 이 세그먼트를 넘긴다.
<br><br><br>
<br>
각 세그먼트는 세그먼트의 첫 번째 데이터 바이트의 바이트 열 번호인 순서 번호를 포함한다.

<br>
타이머가 이미 다른 세그먼트에 대해 실행 중이 아니면,<br>
TCP는 이 세그먼트를 IP로 넘길 때 타이머를 시작한다.

<br><br><br>
2️⃣ 타이머 타임아웃
<br>
<br>TCP는 타임아웃 이벤트에 대해 타임아웃을 일으킨 세그먼트를 재전송하여 응답한다.
<br>그리고 TCP의 타이머를 다시 시작한다.
<br><br><br>
3️⃣ 수신 확인응답 세그먼트(ACK) 수신
<br>이 이벤트가 발생하면, TCP는 변수 SendBase와 ACK 값 y를 비교한다.<br>
<br>SendBase : 수신 확인응답이 확인되지 않은 / 가장 오래된 바이트의 순서번호
<br>SendBase-1 : 수신자에게서 정확하게 차례대로 수신되었음을 알리는 마지막 바이트의 순서번호
<br><br><br>
TCP는 누적 확인응답을 사용하고, y는 y바이트 이전의 모든 바이트의 수신을 확인한다.
<br>y &gt; SendBase이면, ACK는 이전에 확인응답 안 된 하나 이상의 세그먼트들을 확인해준다.<br>
<br>송신자는 자신의 SendBase 변수를 갱신한다.
<br>아직 확인응답 안 된 세그먼트들이 존재한다면 타이머를 다시 시작한다.
<br><br><br><br>TCP 프로토콜이 어떻게 작동하는지 몇 가지 간단한 시나리오를 통해 알아보자.<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437606-210348ac-1c16-4f20-b87e-6047251daee9.png" alt="손실된 확인응답에 기인하는 재전송" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br><br>
<br><br>호스트 A로부터 세그먼트가 호스트 B 측에서 수신되었음에도 B로부터 A로의 긍정 확인응답이 손실된다면<br>
<br>타임아웃이 발생한다.
<br>호스트 A는 같은 세그먼트를 B에게 재전송한다.
<br>호스트 B의 TCP는 재송신된 세그먼트의 바이트를 버린다.
<br><br><br><br>호스트 A가 연속해서 두 세그먼트를 전송한다.<br>호스트 A에서 타임아웃 이전에 어떠한 긍정 확인응답도 수신하지 못한다고 가정하자.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437609-5d593657-1975-4515-8614-9a8cf0d2d1fe.png" alt="세그먼트 100이 재전송되지 않는 경우" referrerpolicy="no-referrer" style="width: 520px; max-width: 100%;"><br><br>
<br><br>타임아웃 이벤트가 발생하면<br>
<br>호스트 A는 순서 번호 92로 첫 번째 세그먼트를 재전송한다.
<br>타이머를 다시 시작한다.
<br>새로운 타임아웃 이전에 두 번째 세그먼트에 대한 ACK가 도착하는 한,<br>
두 번째 세그먼트는 재전송을 하지 않을 것이다.
<br><br><br><br>호스트 A가 연속해서 두 세그먼트를 전송한다.<br><img src="https://user-images.githubusercontent.com/86337233/211437607-08796096-fe33-4e0b-b443-54e51db96706.png" alt="누적 확인응답" referrerpolicy="no-referrer" style="width: 520px; max-width: 100%;"><br><br>
<br><br>첫 번째 세그먼트의 긍정 확인응답이 네트워크에서 분실되었지만,<br>
첫 번째 세그먼트의 타임아웃 전에 호스트 A가 긍정 응답번호 120의 긍정 확인응답을 수신하면<br>
<br>호스트 A는 호스트 B가 119바이트까지 모든 데이터를 수신했음을 알게 된다.
<br>그러므로 호스트 A는 두 세그먼트 중 어느 것도 재전송하지 않는다.
<br><br><br><br>
💡 TCP 확인응답은 누적되고 올바르게 수신되지만, 순서가 잘못된 세그먼트는 수신자가 개별적으로 ACK를 받지 않는다.
<br>
TCP 송신자는 전송했지만 확인응답 안 된 바이트의 가장 작은 순서 번호, SendBase와 전송될 다음 바이트의 순서 번호, NextSeqNum을 유지해야 한다.
<br>이런 관점에서 TCP는 GBN 형태의 프로토콜과 비슷해보이나, ’TCP에서는 올바르게 수신되었지만 순서가 바뀐 세그먼트들을 버퍼링한다’는 차이점이 존재한다.<br>e.g.,<br>
패킷 n &lt; N에 대한 긍정 확인응답이 손실되었지만,<br>
나머지 N-1개의 긍정 확인 응답들은 타임아웃 전에 송신 측에 도달했다고 가정한다.<br>
<br>
GBN : 패킷 n뿐만 아니라, 연속적인 패킷 n+1, n+2, … , N 모두를 재전송한다.

<br>
TCP

<br>세그먼트 n 하나만을 재전송
<br>세그먼트 n에 대한 타임아웃 전에 세그먼트 n+1에 대한 긍정 확인 응답이 도착한다면 세그먼트를 재전송하지 않는다.


<br><br><br>
💡 TCP에서 수정제안된 선택적 확인응답(selective acknowledgment)<br>
: TCP 수신자가 마지막으로 올바로 수신된 ‘순서가 맞는’ 세그먼트에 대해 누적 확인응답을 하기보다는<br>
‘순서가 틀린’ 세그먼트에 대해 선택적으로 확인응답을 하게 한다.
<br>이를 선택적 재전송과 결합했을 경우, SR 프로토콜과 매우 유사하다.<br><br><br>따라서 TCP의 오류 복구 메커니즘은 GBN과 SR 프로토콜의 혼합으로 분류하는 것이 적당하다.<br><br><br><br>
타임아웃이 유발하는 재전송의 문제 : 타임아웃의 주기가 때때로 비교적 길다.
<br>긴 타임아웃 주기는 종단 간의 지연을 증가시키지만,<br>
다행히도 송신자는 종종 중복 ACK에 의한 타임아웃이 일어나기 전에 패킷 손실을 발견한다.<br><br><br>
💡 중복 ACK(duplicate ACK) : 송신자가 이미 이전에 받은 확인응답에 대한 재확인응답 세그먼트 ACK
<br><br><br><br>
TCP는 부정 확인응답을 사용하지 않으므로, 수신자는 송신자에게 부정 확인 응답을 보낼 수 없다.
<br>
<br>TCP 수신자가 기다리는 다음 것보다 더 큰 순서 번호를 가진 세그먼트를 받았을 때, TCP 수신자는 손실 세그먼트를 찾아낼 것이다.
<br>수신자는 마지막으로 수신된 순차적인 바이트를 갖는 데이터를 그냥 다시 확인응답한다.<br>
즉, 중복 ACK를 생성한다.
<br><br><br><br>
이벤트 1️⃣<br>
기다리는 순서 번호를 가진 ‘순서가 맞는’ 세그먼트의 도착<br>
기다리는 순서 번호까지의 모든 데이터는 이미 확인응답된다.
<br>TCP 수신자 동작 : 지연된 ACK<br>
<br>또 다른 ‘순서가 맞는’ 세그먼트의 도착을 위해 500 ms까지 기다린다.
<br>만약 다음 ‘순서에 맞는’ 세그먼트가 이 기간에 도착하지 않으면, 그냥 ACK를 보낸다.
<br><br><br>
이벤트 2️⃣<br>
기다리는 순서 번호를 가진 ‘순서가 맞는’ 세그먼트의 도착<br>
ACK 전송을 기다리는 다른 하나의 ‘순서에 맞는’ 세그먼트가 있다.
<br>TCP 수신자 동작 : 2개의 ‘순서가 맞는’ 세그먼트들을 ACK하기 위해, 하나의 누적된 ACK를 즉시 보낸다.<br><br><br>
이벤트 3️⃣<br>
기다리는 것보다 높은 순서 번호를 가진 ‘순서가 바뀐’ 세그먼트의 도착 격자가 발견된다.
<br>TCP 수신자 동작<br>
: 순서 번호가 다음의 기다리는 바이트(즉, 격차의 최솟값)를 나타내는 중복 ACK를 즉시 보낸다.<br><br><br>
이벤트 4️⃣<br>
수신 데이터에서 격차를 부분적으로 또는 모두 채우는 세그먼트의 도착
<br>TCP 수신자 동작 : 그 세그먼트가 격차의 최솟값에서 시작한다고 하면, 즉시 ACK를 보낸다.<br><br><br><br>만약 TCP 송신자가 같은 데이터에 대해 3개의 중복 확인응답을 수신한다면,<br>
이것은 ACK된 세그먼트의 다음 3개의 세그먼트가 분실되었음을 의미한다.<br>
💡 3개의 중복 ACK를 수신할 때,<br>
TCP는 세그먼트의 타이머가 만료되기 이전에 손실 세그먼트를 재전송한다.
<br><br><br>아래 그림을 보면 두 번째 세그먼트를 잃어버린 경우, 타이머가 만료되기 전에 재전송되었다.<br><img src="https://user-images.githubusercontent.com/86337233/211437613-e03e0eac-251b-4e1c-8d29-c975dfa545b1.png" alt="빠른 재전송" referrerpolicy="no-referrer" style="width: 430px; max-width: 100%;"><br><br>
<br>
<br><br><br>
💡 TCP는 송신자가 수신자의 버퍼를 오버플로시키는 것을 방지하기 위해<br>
애플리케이션에게 흐름 제어 서비스(flow-control service)를 제공한다.
<br>→ 수신하는 애플리케이션이 읽는 속도와 송신자가 전송하는 속도를 같게 한다.<br><br><br>
TCP 송신자는 IP 네트워크에서 혼잡 때문에 억제될 수도 있다. = 혼잡 제어(congestion control)
<br>흐름 제어와 혼잡 제어는 명백히 각기 다른 목적으로 수행된다. (잘 구별하여야 함)<br><br><br><br>
💡 TCP는 수신 윈도(receive window)라는 변수를 유지하여 흐름 제어를 제공한다.
<br>
<br>
수신 측에서 가용한 버퍼 공간이 얼마나 되는지를 송신자에게 알려주는데 사용된다.

<br>
TCP는 전이중(full-duplex)이므로 연결의 각 측의 송신자는 별개의 수신 윈도를 유지한다.

<br><br><br><br><br><br>e.g., TCP 연결상에서 호스트 A가 호스트 B에게 큰 파일을 전송한다고 가정<br>
<br>
호스트 B는 이 연결에 수신 버퍼를 할당한다.<br>
(이때 할당된 수신 버퍼의 크기 : RcvBuffer)

<br>
호스트 B의 애플리케이션 프로세스는 버퍼로부터 데이터를 읽으며 다음과 같은 변수들을 정의한다.

<br>LastByteRead<br>
: 호스트 B의 애플리케이션 프로세스에 의해 버퍼로부터 읽힌 데이터 스트림의 마지막 바이트 번호

<br>LastByteRcvd<br>
: 호스트 B에서 네트워크로부터 도착하여 수신 버퍼에 저장된 데이터 스트림의 마지막 바이트 번호
<br>rwnd
<br>수신 윈도 = 버퍼의 여유 공간
<br>시간에 따라 여유 공간은 변하므로 이 변수는 동적이다.




<br><br><br>
LastByteRcvd - LastByteRead ≤ RcvBuffer
<br>
rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437616-fd0b34a2-9117-4bd5-bfb0-3fe82e59e4c3.png" alt="수신 윈도와 수신 버퍼" referrerpolicy="no-referrer" style="width: 480px; max-width: 100%;"><br><br>
<br><br><br><br><br>
<br>
호스트 B는 호스트 B가 호스트 A에게 전송하는 모든 세그먼트의 윈도 필드에 현재 rwnd 값을 설정한다.

이를 통해 호스트 A에게 연결 버퍼에 얼마만큼의 여유 공간이 있는지를 알려준다.


<br>
호스트 A는 두 변수 LastByteSent와 LastByteAcked를 유지한다.

LastByteSent - LastByteAcked = 호스트 A가 이 연결에 전송 확인응답이 안 된 데이터의 양


<br><br><br>
💡 rwnd의 값보다 작은 확인응답 안 된 데이터의 양을 유지함으로써<br>
호스트 A는 호스트 B의 수신 버퍼에 오버플로가 발생하지 않는다는 것을 확신한다.
<br><br><br>호스트 A는 연결된 동안 다음의 내용을 보장한다.<br>
LastBySent - LastByteAcked ≤ rwnd
<br><br><br><br>
<br>호스트 B의 수신 버퍼는 rwnd = 0으로서 가득 찼고
<br>호스트 A에게 rwnd = 0이라고 알린 후 호스트 B는 호스트 A에게 전송할 것이 없는 경우
<br>
호스트 B에서의 애플리케이션 프로세스가 버퍼를 비우더라도,<br>
TCP는 호스트 A에게 새로운 rwnd로 새로운 세그먼트를 전송하지 않는다.
<br><br><br>즉, TCP는 전송할 데이터가 있거나, 전송해야 할 확인응답을 가진 경우에만 호스트 A에게 세그먼트를 전송할 것이다.<br>→ 호스트 A는 차단되고 더는 데이터를 전송할 수 없다.<br><br><br>따라서 TCP 명세서는 호스트 A가 호스트 B의 수신 윈도가 0일 때, 1바이트 데이터로 세그먼틀르 계속해서 전송하도록 요구한다.<br><br>
<br><br><br>TCP 연결이 어떻게 설정되고 해제되는가?<br><br><br>하나의 호스트(클라이언트)에서 운영되는 프로세스가 다른 호스트(서버) 안의 또 다른 프로세스와 연결을 시작하길 원한다고 가정하자.<br>
<br>클라이언트 애플리케이션 프로세스는 서버에 있는 프로세스와 연결 설정하기를 원한다는 것을 클라이언트 TCP에게 알린다.
<br>클라이언트 안의 TCP는 다음과 같은 방법으로 TCP를 이용해 서버와 TCP 연결 설정을 시작한다.
<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211437617-b3a75ef9-8307-499f-b011-2bfb62f92916.png" alt="TCP 세 방향 핸드셰이크" referrerpolicy="no-referrer" style="width: 450px; max-width: 100%;"><br><br>
<br><br><br>
<br>
클라이언트 측 TCP는 서버 TCP에게 특별한 TCP 세그먼트, SYN 세그먼트를 송신한다.

<br>애플리케이션 계층 데이터를 포함하지 않는다.
<br>세그먼트 헤더에 SYN 비트를 1로 설정한다.


<br>
클라이언트는 최소 순서 번호(client_isn)를 임의로 선택하고, 최초의 TCP SYN 세그먼트의 순서 번호 필드에 이 번호를 넣는다.

<br>
이 세그먼트는 IP 데이터그램 안에서 캡슐화되고 서버로 송신된다.

<br><br><br><br>TCP SYN 세그먼트를 포함하는 IP 데이터그램이 서버 호스트에 도착하면,<br>
<br>
서버는 데이터그램으로부터 TCP SYN 세그먼트를 추출한다.

<br>
연결에 TCP 버퍼와 변수를 할당한다.

<br>
클라이언트 TCP로 연결 승인 세그먼트, SYNACK 세그먼트를 송신한다.

<br>애플리케이션 계층 데이터를 포함하지 않는다.
<br>SYN 비트는 1로 설정된다.
<br>TCP 세그먼트 헤더의 확인응답 필드는 client_isn+1로 설정된다.
<br>서버는 자신의 최초의 순서 번호(server_isn)를 선택하고, TCP 세그먼트 헤더의 순서 번호 필드에 이 값을 넣는다.


<br><br><br><br>연결 승인 세그먼트를 수신하면,<br>
<br>
클라이언트는 연결에 버퍼와 변수를 할당한다.

<br>
클라이언트 호스트는 서버로 또 다른 세그먼트를 송신한다.

<br>클라이언트는 TCP 세그먼트 헤더의 확인응답 필드 안에 server_isn+1 값을 넣어, 서버의 연결 승인 세그먼트를 확인한다.
<br>연결이 설정되었기 때문에 SYN 비트는 0으로 설정된다.


<br><br><br>
세 번째 단계는 클라이언트에서 서버로의 데이터를 세그먼트 페이로드에서 운반할 수 있다.
<br><br><br><br><br><br>위의 세 단계가 완료되면,<br>
<br>클라이언트와 서버 호스트들은 각각 서로에게 데이터를 포함하는 세그먼트를 보낼 수 있다.
<br>SYN 비트는 0으로 설정된다.
<br><br><br><br>TCP 연결에 참여하는 두 프로세스 중 하나가 연결을 끊을 수 있다.<br>연결이 끝날 때, 호스트의 ‘자원’(버퍼와 변수)는 회수된다.<br><img src="https://user-images.githubusercontent.com/86337233/211437618-6aea0b08-6847-450d-b5d7-a1ae129d0c56.png" alt="TCP 연결 종료" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br><br>
<br><br>
<br>
클라이언트 애플리케이션 프로세스는 종료 명령을 내린다.

<br>
이는 클라이언트 TCP가 서버 프로세스에게 특별한 TCP 세그먼트를 보내도록 한다.<br>
(FIN 비트를 1로 설정)

<br>
서버가 이 세그먼트를 수신하면, 서버는 클라이언트에게 확인응답 세그먼트를 보낸다.

<br>
그 다음에 FIN 비트가 1로 설정된 자신의 종료 세그먼트를 송신한다.

<br>
마지막으로 클라이언트는 서버의 종료 세그먼트에 확인응답을 한다.

이 시점에서 두 호스트의 모든 자원은 할당이 해제된다.


<br><br><br><br>TCP 연결이 존재하는 동안 각 호스트에서 동작하는 TCP 프로토콜은 다양한 TCP 상태를 두루 전이한다.<br>아래의 두 그림은 클라이언트가 연결 해제를 시작한다는 것을 가정한다.<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211440563-c245132e-f149-46d6-a184-621ccb29b848.png" alt="TCP 상태 전이 - 클라이언트" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211440566-f2dc1e33-46ab-459b-8dc6-707fc963ba70.png" alt="TCP 상태 전이 - 서버" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br>
<br><br><br><br>
<br>
서버는 수신된 SYN에 대한 응답으로 연결 변수와 버퍼를 할당하고 초기화한다.

<br>
그 다음, 서버는 응답으로 SYNACK을 보내고 클라이언트의 ACK 세그먼트를 기다린다.

<br><br><br>
클라이언트가 이 세 방향 핸드셰이크의 세 번째 단계를 완료하기 위한 ACK를 보내지 않으면<br>
결국(종종 1분 이상 후에) 서버가 절반만 열린 연결을 종료하고 할당된 자원을 회수한다.
<br>→ 이는 SYN 플러드 공격의 무대가 된다.<br><br><br><br>고전적인 서비스 거부(Denial of Service, DoS) 공격<br><br><br>
<br>
공격자는 핸드셰이크의 세 버너째 단계를 완료하지 않은 상태에서 무수한 TCP SYN 세그먼트를 보낸다.

<br>
서버의 연결 자원이 반쪽 연결에 할당된다.

<br>
결국 서버의 연결 자원이 소진됨에 따라 합법적인 클라이언트들이 서비스 거부가 된다.

<br><br><br><br>이는 SYN 플러드 공격에 대한 방어책으로, 현재 대부분의 운영체제에 존재하고 있다.<br><br><br><br>
<br>
서버는 SYN에 대해 반만 열린(half-open) TCP 연결을 만들지 않고,<br>
초기 TCP 순서 번호(쿠키, cookie)를 만든다.

<br>서버가 SYN 세그먼트를 받을 때, 그 세그먼트가 정당한 사용자로부터 또는 공격자로부터 온 것인지 구별할 수 없기 때문이다.
<br>해시 함수에 아래의 항목들을 사용하여 쿠키를 생성한다.

<br>비밀번호
<br>SYN 세그먼트의 출발지와 목적지 IP 주소들과 포트번호




<br>
서버는 이 특별한 초기 순서 번호를 가진 SYNACK 패킷을 보낸다.

💡 서버는 SYN에 관련된 쿠키나 어떤 다른 상태 정보를 기억하지 않는다.


<br>
합법적인 클라이언트는 ACK 세그먼트를 회신한다.

<br>
이 ACK를 받은 서버는 ACK가 이전에 보낸 일부 SYN에 관한 것인지 확인해야 한다.

<br>이는 이전에 보낸 일부 SYN에 관한 것인지는 쿠키를 통해 확인한다.
<br>서버는 SYNACK에 있는 출발지와 목적지 IP 주소와 포트번호, 비밀번호를 사용해서 동일한 해시 함수를 실행한다.


<br><br><br>만약 함수의 결과에 1을 더한 것이 클라이언트의 SYNACK에 있는 확인응답 번호(쿠키)와 같다면<br>
서버는 ACK가 초기 SYN 세그먼트에 관련된 것, 즉 올바른 것이라고 결론짓는다.<br>→ 이후 서버는 소켓을 가지고 완전하게 열린 연결을 만든다.<br><br><br>만약 클라이언트가 ACK 세그먼트를 회신하지 않으면<br>
서버가 처음의 가짜 SYN에 대해 어떤 자원도 할당하지 않았기 때문에 처음의 SYN은 서버에 해를 끼치지 못한다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.5-연결지향형-트랜스포트_-tcp\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.5 연결지향형 트랜스포트_ TCP/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:15 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/211437579-b86e832e-cd39-4707-a212-9ee7c7d6869f.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/211437579-b86e832e-cd39-4707-a212-9ee7c7d6869f.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.6 혼잡 제어의 원리]]></title><description><![CDATA[ 
 <br><br>
💡 네트워크 혼잡의 원인 : 너무 많은 출발지가 너무 높은 속도로 데이터를 보내려고 시도
<br>→ 이를 처리하기 위해서는 네트워크 혼잡을 일으키는 송신자들을 억제하는 매커니즘이 필요하다.<br><br><br><br><br>
<br>두 호스트 A와 B가 각각 출발지와 목적지 사이에서 단일 홉을 공유하는 연결을 갖는다.
<br>호스트 A와 B의 애플리케이션이 λin 바이트/초의 평균 전송률로 데이터를 전송하고 있다.
<br>라우터 버퍼의 양은 무한하다고 가정한다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211454689-76fb01a5-de4b-4556-a80b-fc908571ceda.png" alt="혼잡 시나리오 1" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br>아래 그래프들은 A의 연결 성능을 나타낸다.<br>
<br>연결당 처리량(per-connection throughput) : 수신자 측에서의 초당 바이트 수

<br>0 ~ R/2 사이의 전송률 : 수신자 측의 처리량은 송신자의 전송률과 같다.
<br>R/2 이상의 전송률 : 처리량은 R/2
<br>즉, 호스트 A와 B가 전송률을 아무리 높게 설정하더라도 각자 R/2보다 높은 처리량을 얻을 수 없다.


<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211454696-58c0e5d1-ece7-4eaf-ab49-12ca7b243f3e.png" alt="혼잡 시나리오 1 - 처리량" referrerpolicy="no-referrer" style="width: 280px; max-width: 100%;"><br><br>
<br><br>
<br>평균 지연

<br>전송률이 R/2에 근접할 경우 : 평균 지연은 점점 커진다.
<br>전송률이 R/2를 초과할 경우 : 무제한 (무한한 사용 가능한 버퍼링을 가정)


<br><img src="https://user-images.githubusercontent.com/86337233/211454693-638ed740-069f-498a-9928-1da5aad7544b.png" alt="혼잡 시나리오 1 - 지연" referrerpolicy="no-referrer" style="width: 280px; max-width: 100%;"><br><br>
<br><br>
패킷 도착률이 링크 용량에 근접함에 따라 큐잉 지연이 커진다.
<br><br><br><br>
<br>라우터 버퍼의 양이 유한하다고 가정한다. → 버퍼가 가득 찼을 때 도착하는 패킷들은 버려진다.
<br>각 연결은 신뢰적이라고 가정한다. → 패킷이 라우터에 버려지면 송신자에 의해 재전송될 것이다.
<br>애플리케이션이 원래의 데이터를 소켓으로 보내는 송신율 : λin 바이트/초
<br>네트워크 안으로 세그먼트를 송신하는 트랜스포트 계층에서의 송신율(제공된 부하, offered load)<br>
: λ'in 바이트/초 = 최초의 데이터 전송과 재전송 합의 속도
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211454697-900ad2b0-7639-4da4-8ea7-dc8007abdb0c.png" alt="혼잡 시나리오 2" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><img src="https://user-images.githubusercontent.com/86337233/211454701-c4833238-04e5-4e71-930a-da27777bcec6.png" alt="혼잡 시나리오 2 - 그래프" referrerpolicy="no-referrer" style="width: 780px; max-width: 100%;"><br><br>
<br><br>a. 어떠한 손실도 발생하지 않는 경우 (버퍼가 비어 있을 때만 패킷을 송신)<br>
<br>연결의 처리량 = λin
<br>평균 호스트 송신율은 R/2를 초과할 수 없다.
<br><br><br>b. 패킷이 확실히 손실된 것을 알았을 때만 송신자가 재전송하는 경우<br>
<br>제공된 부하 λ'in이 R/2일 경우 : 데이터의 전송률은 R/3
<br>전송된 데이터의 R/2 중

<br>0.333R 바이트/초는 원래의 데이터
<br>초당 0.166R 바이트/초(평균)는 재전송 데이터


<br>
송신자는 버퍼 오버플로 때문에 버려진 패킷을 보상하기 위해 재전송을 수행해야 한다.
<br><br><br>c. 송신자에서 너무 일찍 타임아웃되어 패킷이 손실되지 않았지만, 큐에서 지연되고 있는 패킷을 재전송하는 경우<br>
<br>원래의 데이터 패킷과 재전송 패킷 둘 다 수신자에게 도착한다.
<br>각 패킷이 라우터에 의해 두 번씩 전달된다고 가정했을 때, 제공된 부하가 R/2일 때의 처리량은 R/4
<br>
커다란 지연으로 인한 송신자의 불필요한 재전송은 라우터가 패킷의 불필요한 복사본들을 전송하는 데 링크 대역폭을 사용하는 원인이 된다.
<br><br><br><br>
<br>4개의 호스트는 겹쳐지는 2홉 경로를 통해 패킷을 전송한다.
<br>각각의 호스트가 타임아웃/재전송 매커니즘을 사용한다.
<br>모든 호스트는 λin의 동일한 값을 가진다.
<br>모든 라우터 링크는 R 바이트/초 옹량을 갖는다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211454704-dbe234c3-f42c-4129-a971-03994afbfad0.png" alt="혼잡 시나리오 3" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;"><br><br>
<br><br>
<br>라우터 R2는 λin과 관계없이, R1에서 R2까지의 링크 용량, 최대 R인 도착률을 가질 수 있다.
<br>A ~ C와 B ~ D의 트래픽은 버퍼 공간을 라우터 R2에 경쟁해야 한다.<br>
→ R2를 성공적으로 통과하는 A ~ C의 트래픽의 양은 B ~ D에서 제공된 부하가 크면 클수록 더 작아진다.
<br>
트래픽이 많은 경우 A~C 종단 간 처리율이 0이 된다.
<br><br><br>즉, 아래 그래프처럼 제공된 부하와 처리량 간의 tradeoff가 발생한다.<br><img src="https://user-images.githubusercontent.com/86337233/211454705-89d22fd0-1433-4a11-ac8b-3f284d3e4dbb.png" alt="혼잡 시나리오 3 - 그래프" referrerpolicy="no-referrer" style="width: 320px; max-width: 100%;"><br>
패킷이 경로상에서 버려질 때, 버려지는 지점까지 패킷을 전송하는 데 사용된 상위 라우터에서 사용된 전송 용량은 낭비된 것이다.
<br><br>
<br><br><br><br>
네트워크 계층은 혼잡 제어 목적을 위해 트랜스포트 계층에게 어떤 직접적인 지원도 제공하지 않는다.
<br>따라서 네트워크에서 혼잡의 존재는 단지 관찰된 네트워크 동작(패킷 손실 및 지연)에 기초하여 종단 시스템이 추측해야 한다.<br><br><br>이는 TCP가 혼잡 제어를 위해 취하는 방식이다.<br>
<br>TCP 세그먼트 손실과 증가하는 왕복 지연값을 네트워크 혼잡의 발생 표시로 간주한다.
<br>TCP는 그에 따라서 윈도 크기를 줄인다.
<br><br><br><br>
라우터들은 네트워크 안에서 혼잡 상태와 관련하여 송신자나 수신자 또는 모두에게 직접적인 피드백을 제공한다.
<br>
<br>
ATM ABR(Available Bite Rate) 혼잡 제어에서<br>
라우터는 자신이 출력 링크(outgoing link)에 제공할 수 있는 전송률을 송신자에게 명확히 알릴 수 있게 해준다.

<br>
최근 IP와 TCP가 이 방식을 선택적으로 구현할 수 있다.

<br><br><br>혼잡 정보가 전달되는 두 가지 방법 → 둘 중 하나로 네트워크에서 송신자에게 피드백된다.<br>
<br>
직접 피드백

<br>네트워크 라우터 → 송신자
<br>알림의 형태 : 초크 패킷(choke packet)


<br>
송신자에서 수신자에게로 흐르는 패킷 안에 특정 필드에 표시/수정

<br>수신자가 표시된 패킷을 수신했을 때, 혼잡 상태를 송신자에게 알린다.
<br>완전한 왕복 시간이 걸린다.


<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211454707-13003c37-f04c-4276-8f62-9c6287bbd253.png" alt="네트워크 지원 혼잡 정도" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;">]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.6-혼잡-제어의-원리\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.6 혼잡 제어의 원리/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:16 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/211454689-76fb01a5-de4b-4556-a80b-fc908571ceda.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/211454689-76fb01a5-de4b-4556-a80b-fc908571ceda.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.7 TCP 혼잡 제어]]></title><description><![CDATA[ 
 <br><br>IP 계층은 네트워크 혼잡에 관해 종단 시스템에게 어떠한 직접적인 피드백도 제공하지 않는다.<br><br><br><br>
네트워크의 혼잡에 따라 연결에 트래픽을 보내는 전송률을 각 송신자가 제한하도록 한다.
<br>
<br>TCP 송신자가 자신과 목적지 간의 경로에서 혼잡이 없음을 감지 → 송신율을 높인다.
<br>TCP 송신자가 경로 사이에 혼잡을 감지 → 송신율을 줄인다.
<br><br><br><br>
💡 송신 측에서 동작하는 TCP 혼잡 제어 메커니즘은<br>
추가적인 변수인 혼잡 윈도(congestion window)를 추적한다.
<br>
<br>cwnd로 표시
<br>TCP 송신자가 네트워크로 트래픽을 전송할 수 있는 속도에 제약을 가한다.
<br><br><br>송신하는 쪽에서 확인응답이 안 된 데이터의 양은<br>
cwnd와 rwnd(수신 윈도 = 버퍼의 여유 공간)의 최솟값을 초과하지 않을 것이다.<br>
LastByteSent - LastByteAcked ≤ min{cwnd, rwnd}
<br>→ 따라서 cwnd의 값을 조절하여 송신자는 링크에 데이터를 전송하는 속도를 조절할 수 있다.<br><br><br><br>
1️⃣ 손실 이벤트(loss event)가 발생한 경우
<br>과도한 혼잡이 발생하면<br>
<br>
경로에 있는 하나 이상의 라우터 버퍼들이 오버플로되고

<br>
그 결과 데이터그램이 버려진다.

<br>
버려진 데이터그램은 송신 측에서 손실 이벤트를 발생시킨다.
(e.g., 타임아웃 또는 3개의 중복된 ACK의 수신)

<br>이를 통해 송신자는 송신자와 수신자 사이의 경로상의 혼잡이 발생했음을 알게 된다.<br><br><br>
2️⃣ 손실 이벤트가 발생하지 않은 경우
<br>
💡 자체 클로킹(self-clocking)<br>
TCP는 확인응답을 혼잡 윈도 크기의 증가를 유발하는 트리거(trigger)또는 클록(clock)으로 사용한다.
<br>
<br>확인응답이 늦은 속도로 도착한다면 → 혼잡 윈도는 상대적으로 낮은 속도로 증가
<br>확인응답이 높은 속도로 도착한다면 → 혼잡 윈도는 더 빨리 증가
<br><br><br><br>전송률을 제어하는 cwnd 값을 조정하는 매커니즘은 무엇인가?<br>
<br>TCP 송신자들이 너무 빠르게 송신하면 → 혼잡 붕괴가 나타날 것이다.
<br>TCP 송신자들이 너무 천천히 송신한다면 → 네트워크 내의 대역폭을 충분히 활용하지 못할 것이다.
<br><br><br>TCP는 다음과 같은 3가지 처리 원칙에 따라 자신이 송신할 속도를 결정하게 된다.<br><br><br>
1️⃣ TCP 전송률은 한 세그먼트를 손실했을 때 줄여야 한다.
<br>손실된 세그먼트 = 혼잡을 의미<br>손실 세그먼트의 재전송을 야기하는 이벤트는 다음과 같다.<br>
<br>타임아웃 이벤트
<br>4개의 확인응답 수신 (하나의 원래의 ACK + 3개의 중복된 ACK)
<br><br><br>
2️⃣ 확인응답되지 않은 세그먼트에 대해 ACK가 도착하면 송신자의 전송률은 증가할 수 있다.
<br>확인응답의 도착 = 네트워크가 송신자의 세그먼트를 수신자에게 성공적으로 전송하였다.<br>즉, 네트워크는 혼잡하지 않다는 묵시적 표시로 받아들여진다.<br><br><br>
3️⃣ 대역폭 탐색
<br>혼잡이 없는 출발지에서 목적지까지의 경로를 표시하는 ACK와 혼잡한 경로를 표시하는 손실 이벤트가 주어지면,<br>
<br>TCP 송신자로 하여금 손실 이벤트가 발생할 때까지는 ACK가 도착함에 따라 전송률을 증가시킨다.
<br>손실 이벤트가 발생한 시점에서 전송률을 줄인다.
<br><br><br>그러므로<br>
<br>TCP 송신자는 혼잡이 발생하는 시점까지 전송률을 증가시키고
<br>그 시점 이후로부터는 줄인 후,
<br>다시 혼잡 시작이 발생했는지를 보기 위한 탐색을 시작한다.
<br><br><br><br>세 가지 구성요소<br>
<br>
슬로 스타트(slow start)

<br>
혼잡 회피(congestion avoidance)

<br>
빠른 회복(fast recovery) → 권고, 필수사항은 아니다.

<br><br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625829-2117ddf7-f325-4168-86cb-39d6bac3e2bd.png" alt="TCP 혼잡 제어의 FSM" referrerpolicy="no-referrer" style="width: 780px; max-width: 100%;"><br><br>
<br><br><br>
<br>
TCP 연결 시작 시, cwnd의 값은 일반적으로 1 MSS로 초기화된다.<br>
→ 초기 전송률은 대략 MSS/RTT

<br>
TCP 송신자에게 가용 대역폭은 MSS/RTT보다 훨씬 크기 때문에 TCP 송신자는 가용 대역폭 양을 조속히 찾고자 한다.

<br><br><br>
슬로 스타트 상태에서는 cwnd 값을 1 MSS에서 시작하여,<br>
한 전송 세그먼트가 첫 번째로 확인응답을 받을 때마다 1 MSS 씩 증가한다.
<br><br><br>아래 그림처럼 TCP 전송률은 지수적으로 증가하게 된다.<br><img src="https://user-images.githubusercontent.com/86337233/211625835-f36ebe84-04de-4091-86a2-fcedfb50fe4f.png" alt="TCP 슬로 스타트" referrerpolicy="no-referrer" style="width: 380px; max-width: 100%;"><br><br>
<br><br><br>이 지수적 증가는 언제 끝나는 것인가?<br>아래와 같이 3가지 경우가 존재한다.<br><br><br>
1️⃣  타임아웃으로 표시되는 손실 이벤트(혼잡)가 있을 경우
<br>
<br>TCP 송신자는 cwnd 값을 1로 설정
<br>새로운 슬로 스타트를 시작한다.
<br><br><br>
2️⃣ cwnd 값이 ssthreah 값과 같을 경우
<br>
<br>슬로 스타트는 종료되고
<br>TCP는 혼잡 회피 모드로 전환한다.
<br><br><br>
<br>
ssthreah(slow start threshold, 슬로 스타트 임곗값)는 두 번째 상태 변수로, cwnd/2로 정한다.<br>
(= 혼잡이 검출되었을 시점에서의 혼잡 윈도 값의 반)

<br>
TCP는 혼잡 회피 모드에서는 cwnd를 좀 더 조심스럽게 증가시킨다.

<br><br><br>
3️⃣ 중복 ACK가 검출되는 경우
<br>
<br>TCP는 빠른 재전송을 수행하여 빠른 회복 상태로 들어간다.
<br><br><br><br>혼잡 회피 상태로 들어가는 시점에서 cwnd의 값은 대략 혼잡이 마지막으로 발견된 시점에서의 값의 반이 된다.<br>
혼잡 회피 상태에서 일반적으로 TCP는 RTT마다 하나의 MSS만큼 cwnd를 증가시킨다.
<br>즉, 새로운 승인이 도착할 때마다 cwnd를 MSS 바이트(MSS/cwnd)만큼 증가시킨다.<br><br><br><br>언제 혼잡 회피의 (RTT당 1 MSS) 선형 증가가 끝날 것인가?<br><br><br>TCP 혼잡 회피 알고리즘은 타임아웃이 발생했을 때 슬로 스타트의 경우와 같이,<br>
cwnd의 값은 1 MSS로 설정하고,<br>
ssthreash의 값은 손실 이벤트가 발생할 때의 cwnd 값의 반으로 설정한다.
<br><br><br>그러나 손실 이벤트는 3개의 중복된 ACK 이벤트에 의해 야기되며,<br>
이 경우 네트워크는 송신자로부터 세그먼트를 수신자에게 계속 전달하고 있는 중이다.<br><br><br>따라서 이러한 타입의 손실 이벤트에 대해서 TCP는<br>
<br>3개의 중복 ACK를 수신한 시점에서 cwnd의 값을 반으로 줄이고
<br>ssthresh 값을 cwnd 값의 반으로 기록한다.
<br>이후 빠른 회복 상태로 들어간다.
<br><br><br><br>
빠른 회복 상태에서는 cwnd 값을 손실된 세그먼트에 대해 수신된<br>
모든 중복된 ACK에 대해 1 MSS 만큼씩 증가시킨다.
<br>이때 손실된 세그먼트는 TCP를 빠른 회복 상태로 들어가게 했던 세그먼트를 말한다.<br><br><br>
<br>
손실된 세그먼트에 대한 ACK가 도착하면 TCP는 cwnd 혼잡 회피 상태로 들어간다.

<br>
만약 타임아웃 이벤트가 발생한다면 빠른 회복은 슬로 스타트 및 혼잡 회피에서와 같은 동작을 수행한 후 슬로 스타트로 전이한다.

즉, cwnd 값은 1 MSS로 하고, ssthresh 값은 손실 이벤트가 발생할 때의 cwnd 값의 반으로 한다.


<br><br><br>빠른 회복은 구성요소의 권고사항이며, 필수는 아니다.<br>
<br>
TCP 타호(TCP Tahoe, 초기 TCP 버전)<br>
: 타임아웃으로 표시되거나 3개의 중복 ACK로 표시되는 손실이 발생하면

<br>무조건 혼잡 윈도를 1 MSS로 줄이고
<br>슬로 스타드 단계로 들어간다.


<br>
TCP 리노(TCP Reno, 새로운 TCP 버전)는 빠른 회복을 채택했다.

<br><br><br>아래는 리노와 타노에 대한 TCP의 혼잡 윈도 변화를 나타낸 그래프이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625839-e0b75f39-a78a-4265-aad1-b9382257e8de.png" alt="TCP의 혼잡 윈도의 발달" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>손실 이벤트가 발생했을 때<br>
<br>
TCP 리노

<br>혼잡 윈도가 9•MSS로 설정되고
<br>선형적으로 증가한다.


<br>
TCP 타호

<br>혼잡 윈도는 1 MSS로 설정되고
<br>ssthreash에 도달할 때까지 지수적으로 증가하며
<br>그 이후에는 선형적으로 증가한다.


<br><br><br><br>
<br>연결이 시작되고 초기 슬로 스타트 기간을 무시하고,
<br>손실이 타임아웃이 아니라 3개의 중복 ACK로 표신된다고 가정한다면,
<br>
💡 TCP의 혼잡 제어는<br>
RTT마다 1 MSS씩 cwnd의 선형(가법적인) 증가와<br>
3개의 중복 ACK 이벤트에서 cwnd의 절반화(승법적 감소)로 구성된다.
<br>→ TCP의 혼잡 제어는 가법적 증가, 승법적 감소(additive-increase, multiplicative decrease, AIMD)의 혼잡 제어 형식이라고 불린다.<br><br><br>
<br>TCP는 3개의 중복 ACK 이벤트가 발생할 때까지 선형으로 그 혼잡 윈도 크기(결국 전송률)를 증가시킨다.
<br>그러고 나서는 혼잡 윈도 크기를 감소시키지만,
<br>다시 추가적인 가용 대역폭이 있는지를 탐색하기 위해 선형으로 증가시키기 시작한다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625842-798c4c59-a967-4847-b29f-4e4a3ebfcc32.png" alt="AIMD 혼잡 제어" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br><br><br>
패킷 손실이 발생한 혼잡한 링크의 상태가 많이 변경되지 않은 경우<br>
전송 속도를 더 빠르게 높여 손실 전 전송 속도에 근접한 다음 대역폭을 신중하게 조사한다.
<br><br><br>ACK 수신 시에만 혼잡 윈도를 늘리고 슬로 스타트 단계와 빠른 복구 단계는 TCP 리노와 동일하지만,<br>
아래의 혼잡 회피 단계가 수정되었다.<br><br><br>
✅ 몇 가지 조율 가능한 큐빅 매개변수들이 프로토콜의 혼잡 윈도 크기가 얼마나 빨리 Wmax에 도달하는가(K)를 결정한다.
<br>
<br>Wmax : 손실이 마지막으로 감지되었을 때 TCP의 혼잡 제어 윈도 크기
<br>K 시각 : 손실이 없다고 가정할 때 TCP 큐빅의 윈도 크기가 다시 Wmax에 도달하는 미래 시점
<br><br><br>
✅ 큐빅은 혼잡 윈도를 현재 시각 t와 K 시각 사이 거리의 세제곱 함수로 증가시킨다.
<br>→ t가 K에 가까울 때보다 멀리 떨어졌을 때 혼잡 윈도 크기 증가가 훨씬 더 커진다.<br><br><br>즉,<br>
<br>큐빅은 손실 전 속도인 Wmax에 가까워지도록 TCP의 전송 속도를 빠르게 증가시킨 다음,
<br>Wmax에 가까워지면 대역폭을 조심스럽게 탐지한다.
<br><br><br>
✅ 손실을 유발한 링크의 수준이 크게 변경된 경우 큐빅이 새 작동 지점을 더 빨리 찾을 수 있다.
<br>
<br>t가 K에 가까울 때는 큐빅의 혼잡 윈도 증가가 작다.<br>
(이는 손실을 유발하는 링크의 혼잡 수준이 많이 변경되지 않은 경우 좋음)
<br>t가 K를 크게 초과함에 따라 혼잡 윈도가 급격히 증가한다.
<br><br><br><br><br><br>아래 그래프는 TCP 리노와 TCP 큐빅의 이상적인 성능 비교를 나타낸 것이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625843-6a80951a-f492-41bc-9cf2-635b8159ce7b.jpg" alt="TCP 리노와 TCP 큐빅" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>슬로 스타트 단계는 t0에서 끝나며,<br>
t1, t2, t3에서 혼잡 손실이 발생하면 큐빅은 Wmax에 가깝게 더 빠르게 증가한다.<br>→ 따라서 TCP 큐빅이 더 많은 전체 처리량을 누린다.<br>TCP 큐빅은 혼잡 임곗값 바로 아래에서 가능한 한 오랫동안 흐름을 유지하려고 시도한다.<br><br>
<br><br><br>1980년대 후반 슬로 스타트와 혼잡 회피의 초기 표준화 이후, TCP는 종단 끝 혼잡 제어 형식을 구현했다.<br>하지만 최근에는 네트워크가 TCP 송신자와 수신자에게 명시적으로 혼잡 신호를 보낼 수 있도록<br>
IP 및 TCP에 대한 확장이 제안, 구현 및 배포되었다. (네트워크 지원 혼잡 제어 방식)<br>또한 측정된 패킷 지연을 사용하여 혼잡을 추론하는 TCP 혼잡 제어 프로토콜의 일부 변형이 제안되었다.<br><br><br><br>인터넷 내에서 수행되는 네트워크 지원 혼잡 제어의 한 형태이다.<br><br><br>네트워크 계층에서 IP 데이터그램 헤더의 서비스 유형(Type of Service) 필드에 있는 2비트가 ECN에 사용된다.<br>
💡 손실이 발생하기 전에 혼잡 시작을 송신자에게 알리기 위해 혼잡 알림 비트를 설정한다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625847-eee59d74-7fa9-4570-adf2-2d007837b231.png" alt="명시적 혼잡 알림" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br><br>ECN 비트의 한 설정은 라우터가 정체를 겪고 있음을 나타내기 위해 라우터에서 사용된다.<br>→ 이 혼잡 표시는 표시된 IP 데이터그램에서 목적지 호스트로 전달되어 위의 그림처럼 송신 호스트에게 알린다.<br><br><br>ECN 비트의 두 번째 설정은 발신 호스트가 라우터에게 다음의 정보를 알리는 데에 사용된다.<br>
<br>송신자와 수신자가 ECN을 사용할 수 있다.
<br>이에 따라 ECN으로 표시된 네트워크 혼잡에 대한 응답으로 조취할 수 있다.
<br><br><br><br>
💡 혼잡해지는 라우터는<br>
그 라우터에서 버퍼가 가득 차서 패킷들이 삭제되기 전에<br>
송신자에게 혼잡 시작을 알리는 혼잡 알림 비트를 설정할 수 있다.
<br>
<br>
수신 호스트의 TCP가 수신 데이터그램을 통해 ECN 혼잡 알림 표시를 수신하면,

<br>
수신 호스트의 TCP는 수신자-송신자 TCP ACK 세그먼트의<br>
ECE(Explicit Congestion Notification Echo, 명시적 혼잡 알림 에코) 비트를 설정하여<br>
송신 호스트의 TCP에 혼잡 표시를 알린다.

<br>
TCP 송신자는 혼잡 윈도를 절반으로 줄여 혼잡 알림 표시가 있는 ACK에 반응하고,

<br>
다음 전송되는 TCP 수신자 세그먼트 헤더에 CWR(Congestion Window Reduced) 비트를 1로 설정한다.

<br><br><br><br>
패킷 손실이 발생하기 전에 혼잡 시작을 사전에 감지
<br><br><br>
TCP 베가스(Vegas)는<br>
TCP 송신자가 파이프를 가득 채우되 그 이상으로 채우지 않도록 해야 한다는 원칙하에 동작한다.
<br>즉, 파이프가 가득 찬 상태에서는 큰 큐가 쌓이도록 허용되는 경우가 좋을 게 없다는 것을 의미한다.<br><br><br>
<br>
TCP 베가스는 모든 확인응답된 패킷에 대한 출발지에서 목적지까지 경로의 RTT를 측정한다.

<br>
RTTmin : 송신자에서 측정한 RTT 값 중 최솟값

<br><br><br>
<br>
실제 송신자가 측정한 처리량이 cwnd/RTTmin에 가깝다면

<br>경로가 아직 정체되지 않았고,
<br>따라서 TCP 전송 속도가 증가할 수 있다는 것이다.


<br>
실제 송신자가 측정한 처리량이 혼잡하지 않을 때의 처리율보다 현저히 낮다면

<br>경로가 혼잡하고
<br>TCP 베가스 송신자는 전송 속도를 낮추게 된다.


<br><br>
<br><br><br>각각 다른 종단 간의 경로를 갖지만, 모두 R bps의 전송률인 병목 링크(bottleneck link)를 지나는 K개의 TCP 연결을 생각해보자.<br><br><br>각 연결은 큰 파일을 전송하고 있고, 병목 링크를 통과하는 UDP 트래픽은 없다고 가정했을 때,<br>
각 연결의 평균 전송률이 R/K에 가깝다면 혼잡 제어는 메커니즘이 공평하다고 한다.<br>
즉, 각 연결은 링크 대역폭을 동등하게 공유한다.
<br><br><br>아래 그림처럼 전송률이 R인 링크 하나를 공유하는 2개의 TCP 연결을 살펴보자.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625853-ca717317-75e6-47ec-ac70-971a8f475fcf.png" alt="병목 링크" referrerpolicy="no-referrer" style="width: 570px; max-width: 100%;"><br><br>
<br><br>가정<br>
<br>두 연결이 같은 MSS와 RTT를 가진다.<br>
→ 그들이 같은 혼잡 윈도우 크기를 갖는다면 같은 처리율을 가질 것이다.
<br>송신할 많은 양의 데이터가 있다.
<br>TCP의 슬로 스타트 현상을 무시한다.
<br>TCP 연결이 언제나 혼잡 회피 방식으로 동작한다.
<br><br><br>TCP 연결 1과 2에 의해 실현되는 처리율은 다음과 같이 나타낼 수 있다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211625855-65fb1a01-7341-46a3-85d6-1e38f5e0be51.png" alt="처리율" referrerpolicy="no-referrer" style="width: 360px; max-width: 100%;"><br><br>
<br><br>
<br>만약 TCP가 두 연결 사이에서 링크 대역폭을 똑같이 공유한다면,<br>
실제 처리율은 원점에서부터 발산하면서 45º 각도의 화살표(동등한 대역폭 공유)를 따라야 한다.
<br>이상적으로는 두 처리율의 합이 R과 같아야 한다.
<br><br><br>→ 목적 : 동등한 대역폭 공유 선과 완전한 대역폭 이용선의 교차 지점 가까운 곳의 처리율을 얻는 것<br><br><br><br><br><br>1️⃣ TCP 윈도 크기가 어느 주어진 시점에서 연결 1과 2가 A 지점으로 나타내는 처리율을 실현한다고 하자.<br>
<br>
두 연결에 의해 공동으로 소비되는 링크 대역폭의 양이 R보다 적기 때문에<br>
어떠한 손실도 발생하지 않을 것이다.

<br>
양 연결은 TCP 혼잡 회피 알고리즘의 결과로서 RTT당 1 MSS씩 이들의 윈도우를 증가시킬 것이다.

<br><br><br>따라서 두 연결의 공동 처리율은 A 지점에서 시작하는 45º 각도의 선을 따라서 계속되며,<br>2️⃣ 결국 두 연결에 의해 공동으로 소비되는 링크 대역폭은 R보다 커질 것이다. → 패킷 손실이 발생<br>(B 지점에 의해 나타내는 처리율을 실현할 때 패킷 손실을 경험한다고 하자)<br><br><br>그러므로 연결 1과 2는 반으로 그들의 윈도를 감소시킨다.<br><br><br>3️⃣ 결과적으로 실현된 처리율은 C 지점에 있게 되는데, 이는 B와 원점의 중간이다.<br>공동 대역폭 사용이 C 지점에서 R보다 낮으므로,<br>
두 연결은 다시 C로부터 시작하는 45º 각도의 선을 따라 처리율을 증가시킨다.<br><br><br>4️⃣ 결국 손실은 다시 발생할 것이고(D 지점), 두 연결은 다시 반으로 윈도 크기를 감소시킨다.<br><br><br>
즉, 두 연결에 의해 실현되는 대역폭은 동등한 대역폭 공유선을 따라서 결국에는 변동하며<br>
2차원 공간 어디에 있든지 간에 상관없이 수렴한다.
<br>→ 왜 TCP가 연결 사이에서 대역폭을 똑같이 공유하는지에 대한 직관적 느낌<br><br><br><br><br><br>위의 이상적인 시나리오와는 다르게,<br>
현실에서는 클라이언트-서버 애플리케이션들은 링크 대역폭의 각기 다른 양을 얻을 수 있다.<br><br><br>특히 여러 연결이 공통의 병목 링크를 공유할 때,<br>
<br>더 작은 RTT를 갖는 세션은 대역폭이 좀 더 빠르게 비워지므로 링크에서 가용한 대역폭을 점유할 수 있고,
<br>그래서 큰 RTT를 갖는 연결보다 더 높은 처리율을 갖는다.
<br><br><br><br>UDP는 혼잡 제어를 갖고 있지 않는다.<br><br><br>TCP의 관점에서 보면 UDP 상에서 수행되는 멀티미디어 애플리케이션은 공평하지 못하다.<br>즉, 다른 연결들과 협력하지도 않으며, 그들의 전송률을 적당하게 조절하지도 않는다.<br><br><br>TCP 혼잡 제어는 혼잡(손실) 증가에 대해 전송률을 감소시키므로,<br>
그럴 필요가 없는 UDP 송신자들이 TCP 트래픽을 밀어낼 가능성이 있다.<br>→ UPD 트래픽으로 인해 인터넷이 마비되는 것을 방지하는 인터넷을 위한 혼잡 제어 방식의 개발이 필요하다.<br><br><br><br>UDP 트래픽이 공평하게 행동하도록 강요하더라도,<br>
TCP 기반 애플리케이션의 다중 병렬 연결의 사용을 막을 방법이 없기 때문에 공평성 문제는 여전히 완전하게 해결되지 않는다.<br>애플리케이션이 다중 병렬 연결을 사용할 때는 혼잡한 링크 대역폭의 더 많은 부분을 차지한다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.7-tcp-혼잡-제어\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.7 TCP 혼잡 제어/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:17 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/211625829-2117ddf7-f325-4168-86cb-39d6bac3e2bd.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/211625829-2117ddf7-f325-4168-86cb-39d6bac3e2bd.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.8 트랜스포트 계층 기능의 발전]]></title><description><![CDATA[ 
 <br><br>앞서 언급된 TCP들 뿐만 아니라, 더 많은 버전의 TCP가 존재한다.<br><br><br>여러 TCP 변형 프로토콜의 유일한 공통 특징은<br>
<br>TCP 세그먼트 포맷을 사용하고
<br>네트워크 혼잡에 직면하여 서로 ‘공정하게’ 경쟁해야 한다는 점이다.
<br><br><br><br>애플리케이션에서 필요로 하는 트랜스포트 서비스는<br>
<br>UDP가 제공하는 것보다 더 많은 서비스가 필요하지만,
<br>TCP와 함께 제공되는 특정 기능들을 모두 원하지는 않거나 다른 서비스를 원할 수 있다.
<br><br><br>
💡 애플리케이션 설계자는 애플리케이션 계층에 항상 ‘자신의 프로토콜을 확장’할 수 있다.
<br><br><br>e.g., QUIC(Quic UDP Internet Connections) = 빠른 UDP 인터넷 연결<br>
<br>
특히 QUIC은 보안 HTTP를 위한 트랜스포트 계층 서비스의 성능을 향상하기 위해<br>
처음부터 새롭게 설계된 애플리케이션 계층 프로토콜이다.

<br>
오늘날 인터넷의 7% 이상이 QUIC이다.

<br>
신뢰적인 데이터 전송, 혼잡 제어 및 연결 관리를 위한 많은 접근 방식을 사용한다.

<br><br><br>아래 그림을 통해 볼 수 있듯, QUIC은 UDP를 하위 트랜스포트 계층 프로토콜로 사용하는 애플리케이션 계층 프로토콜이며,<br>
HTTP/2 버전 위에서 인터페이스되도록 설계되었다.<br><br><br>왼쪽 : 전통적인 보안 HTTP 프로토콜 스택 / 오른쪽 : 보안 QUIC 기반 HTTP/3 프로토콜 스택<br><img src="https://user-images.githubusercontent.com/86337233/211638914-123c4f6e-d1ce-4ec3-a88c-66785ab4a046.png" alt="HTTP 프로토콜 스택" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br>가까운 장래에 HTTP/3은 기본적으로 QUIC을 통합할 것이다.<br><br><br><br>
✅ 연결지향적이고 안전함
<br>QUIC은 두 종단 간의 연결지향 프로토콜이다.<br>
<br>QUIC 연결 상태를 설정하기 위해 종단 간에 핸드셰이크가 필요
<br>연결 상태의 두 부분 : 출발지와 목적지 연결 ID
<br><br><br>QUIC은 연결 상태를 설정하는 데 필요한 핸드셰이크와 인증 및 암호화에 필요한 핸드셰이크를 결합하여,<br>
<br>먼저 TCP 연결을 설정한 다음
<br>TCP 연결을 통해 TLS 연결을 설정하여
<br>여러 RTT가 필요한 전통적인 보안 HTTP 프로토콜 스택보다 더 빠른 설정을 제공한다.<br><br><br>
✅ 스트림
<br>
<br>단일 QUIC 연결을 통해 여러 애플리케이션 레벨의 ‘스트림’들을 다중화할 수 있다.
<br>QUIC 연결이 설정되면 새 스트림을 빠르게 추가할 수 있다.
<br><br><br>
✅&nbsp; 신뢰적이고 TCP 친화적인 혼잡 제어 데이터 전송
<br>QUIC은 각 QUIC 스트림에 대해 독립적으로 신뢰적인 데이터 전송을 제공한다.<br>이는 아래 그림에서 확인할 수 있다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/211638922-d9383a31-b0a0-4a5d-bb75-94dd44aad696.jpg" alt="HTTP" referrerpolicy="no-referrer" style="width: 800px; max-width: 100%;"><br><br>
<br><br><br>TCP의 RDT(신뢰적인 데이터 전송) 및 CC(혼잡 제어)상에서<br>
애플리케이션 프로그램 레벨의 TLS 암호화를 사용하는 단일 연결 클라이언트 및 서버<br><br><br>
TCP는 신뢰적이고 순서대로 바이트 전달을 제공하므로 여러 HTTP 요청이 목적지 HTTP 서버에서 순서대로 전달되어야 한다.
<br>따라서 한 HTTP 요청의 바이트가 손실되면<br>
나머지 HTTP 요청들은 손실된 바이트가 재전송되어 HTTP 서버에서 TCP가 올바르게 수신할 때까지 전달될 수 없다.<br>
(= HOL 차단 문제)<br><br><br><br>UDP의 비신뢰적인 데이터그램 서비스상에서<br>
QUIC의 암호화, 신뢰적인 데이터 전송 및 혼잡 제어를 사용하는 멀티스트림 클라이언트 및 서버<br><br><br>
QUIC은 스트림별로 신뢰적이고 순서대로 전달하기 때문에<br>
손실된 UDP 세그먼트는 해당 세그먼트에서 데이터가 전달된 스트림에만 영향을 준다.
<br>즉, 다른 스트림의 HTTP 메시지는 계속 수신되어 애플리케이션에 전달될 수 있다.<br><br><br>QUIC은 TCP와 유사한 확인응답 메커니즘을 사용하여 신뢰적인 데이터 전송을 제공한다.<br>QUIC의 혼잡 제어는 TCP 리노 프로토콜을 약간 수정한 TCP 뉴리노(NewReno)를 기반으로 한다.<br><br><br><br><br><br>
💡 QUIC은 두 종단 사이에 신뢰적이고 혼잡 제어된 데이터 전송을 제공하는 애플리케이션 계층 프로토콜이다.
<br><br><br>이는 ‘애플리케이션 프로그램 업데이트 시간 척도’면에서 QUIC으로 변경될 수 있음을 의미하며,<br>이는 TCP 또는 UDP 업데이트 시간 척도보다 훨씬 빠르다는 뜻이다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_3\3.8-트랜스포트-계층-기능의-발전\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_3/3.8 트랜스포트 계층 기능의 발전/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:18 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/211638914-123c4f6e-d1ce-4ec3-a88c-66785ab4a046.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/211638914-123c4f6e-d1ce-4ec3-a88c-66785ab4a046.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.1 네트워크 계층 개요]]></title><description><![CDATA[ 
 <br><br><img alt="Pasted image 20240617235245.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.1-네트워크-계층-개요\attachments\pasted-image-20240617235245.png"><br>두 호스트 H1과 H2가 있을 때, 네트워크 계층은 두 호스트 중 하나의 트랜스포트 계층 세그먼트를 추출하여 H2의 트랜스포트 계층까지 전달하는 역할을 한다.<br>라우터는 트랜스포트 계층과 애플리케이션 계층을 지원하지 않으므로 프로토콜 스택에서 네트워크 계층의 상위 계층은 존재하지 않는다.<br>각 라우터에는 데이터 평면과 제어 평면이 존재한다. <br>
<br>데이터 평면 : 입력 링크에서 출력 링크로 데이터그램을 전달한다.
<br>제어 평면 : 데이터그램이 출발지 호스트에서 목적지 호스트까지 전달되게끔 로컬 포워딩, 라우터별 포워딩을 대응시킨다.
<br><br>
💡 네트워크 계층의 근본적인 역할은 송신 호스트에서 수신 호스트로 패킷을 전달하는 것이다.
<br>위 역할을 위한 중요한 기능 두 가지<br>
<br>포워딩(전달) : 패킷이 라우터의 입력 링크에 도달했을 때 라우터는 그 패킷을 적절한 출력 링크로 이동시켜야한다. 포워딩에서 예외적으로 한 기능은 데이터 평면에서 실행된다. 매우 짧은 시간 단위(보통 몇 나노초)를 갖기에 대표적으로 하드웨어에서 실행된다.
<br>라우팅 : 송신자가 수신자에게 패킷을 전송할 때 네트워크 계층은 패킷 경로를 결정해야 한다. 이러한 경로를 계산하는 알고리즘을 라우팅 알고리즘이라고 한다. 네트워크 전반에 걸쳐 출발지에서 목적지까지 데이터그램의 종단 간 경로를 결정하여 시간이 오래걸려 소프트웨어에서 실행된다.
<br><br><img src="https://user-images.githubusercontent.com/76640167/212542030-df6ba632-c5a2-4460-959e-347960dd256f.png" alt="포워딩 테이블" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;">
![[Pasted image 20240618002507.png]]
라우터는 도착하는 **패킷 헤더의 필드값**을 통해 **`포워딩 테이블`의 내부 색인으로 사용하여 패킷을 전달**한다.<br>포워딩 테이블 엔트리에 저장되어 있는 헤더의 값은 해당 패킷이 전달되어야 할 라우터의 외부 링크 인터페이스를 나타낸다.<br><br>라우팅 알고리즘은 각각의 모든 라우터에서 실행되며, 라우터는 포워딩과 라우팅 기능을 모두 갖고 있어야 한다.<br>또한, 한 라우터의 라우팅 알고리즘 기능은 다른 라우터의 라우팅 알고리즘과 소통하며 포워딩 테이블의 값을 계산한다.<br>이러한 소통은 라우팅 프로토콜에 따라 라우팅 정보에 포함된 라우팅 메시지를 교환하며 이루어진다.<br>(더 자세한 내용은 5장에서 다룬다.)<br><br><img src="https://user-images.githubusercontent.com/76640167/212543852-6720ef7e-0ff9-46f5-bdf3-1771335eaca5.png" alt="SDN 포워딩 테이블" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;">
![[Pasted image 20240618003305.png]]
위 그림은 라우터로부터 물리적으로 분리된 원격 컨트롤러 컴퓨터와 각각의 라우터에 의해 사용될 포워딩 테이블을 분배하는 다른 접근법을 보여준다.<br>라우터는 원격 컨트롤러와 포워딩 테이블과 그 밖의 라우팅 정보를 포함한 메시지를 교환함으로써 소통한다.<br>원격 컨트롤러가 포워딩 테이블을 계산 및 배분하는 동안 라우팅 기기는 포워딩만을 수행한다.<br>즉, 네트워크가 소프트웨어적으로 정의되었을 때 포워딩 테이블을 계산하는 컨트롤러는 라우터와 상호작용을 하며 소프트웨어에서 실행된다.<br>이렇게 원격 컨트롤러가 라우터와 떨어져서 높은 신뢰성과 중복성을 갖춘 원격 데이터 센터에 위치하는 접근 방법은 SDN(software defined networking)의 중심이다.<br>(더 자세한 내용은 5장에서 다룬다.)<br><br>네트워크 계층 제공 서비스<br>
<br>보장된 전달: 이 서비스는 패킷이 출발지 호스트에서부터 목적지 호스트까지 도착하는 것을 보장한다.
<br>지연 제한 이내의 보장된 전달: 이 서비스는 패킷의 전달을 보장할 뿐만 아니라 호스트 간의 특정 지연 제한(예: 100ms 이내) 안에 전달한다.
<br>순서화 패킷 전달: 이 서비스는 패킷이 목적지에 송신된 순서대로 도착하는 것을 보장한다.
<br>최소 대역폭 보장: 이 네트워크 계층 서비스는 송신과 수신 호스트 사이에 특정한 비트율의 전송 링크를 에뮬레이트한다. 송신 호스트가 비트들을 특정한 비트율 이하로 전송하는 한, 모든 패킷이 목적지 호스트까지 전달된다.
<br>보안 서비스: 네트워크 계층은 모든 데이터 그램을 출발지 호스트에서는 암호화, 목적지 호스트에서는 복호화할 수 있게 하여 트랜스포트 계층의 모든 세그먼트에 대해 기밀성을 유지해야한다.
<br>이 외에도 수많은 변형들이 있다.<br>인터넷 네트워크 계층은 최선형 서비스(best-effort service) 라고 알려진 서비스를 제공한다.<br>최선형 서비스의 특징<br>
<br>패킷을 보내는 순서대로 수신됨을 보장하지 않는다.
<br>목적지까지 패킷이 전송됨을 보장하지 않는다.
<br>종단 시스템 간 지연이 보장되지 않는다.
<br>보장된 최소 대역폭이 없다.
<br>이렇게 서비스를 제공하지 못하는 인터넷 네트워크 계층의 대안으로 좋은 보다 서비스 모델을 정의하고 구현했지만 인터넷 네트워크 계층은 놀라운 범위의 애플리케이션을 가능하게 할만큼 충분히 좋다고 입증되었다.<br><br>4장에서는 네트워크 계층 데이터 평면의 구성요소를 살펴본다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.1-네트워크-계층-개요\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_4/4.1 네트워크 계층 개요/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Mon, 17 Jun 2024 15:33:08 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.1-네트워크-계층-개요\attachments\pasted-image-20240617235245.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.1-네트워크-계층-개요\attachments\pasted-image-20240617235245.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.2 라우터 내부에는 무엇이 있을까?]]></title><description><![CDATA[ 
 <br><br><img src="https://user-images.githubusercontent.com/76640167/212551546-16b6533b-58ec-421a-9863-e7d581e0cb41.png" alt="라우터 구조" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;">
![[Pasted image 20240618004402.png]]
위 그림을 라우터의 구조를 나타낸다.<br>
<br>입력 포트

<br>입력 포트의 맨 왼쪽과 맨 오른쪽 박스는 라우터로 들어오는 입력 링크로, 물리 계층 기능을 수행한다. 
<br>또한 입력 포트는 들어오는 링크의 반대편에 있는 링크 계층과 상호 운용하기 위해 필요한 링크 계층 기능을 수행한다. 이것은 입력 및 출력 포트에서 미들박스로 표시된다.
<br>가장 중요한 기능은 입력 포트의 가장 오른쪽에서 수행되는 검색 기능이다. 여기서 포워딩 테이블을 참조하여 도착된 패킷이 스위치 구조를 통해 라우터 출력 포트를 결정한다.
<br>라우팅 프로토콜 정보를 전달하는 패킷인 제어 패킷은 입력 포트에서 라우팅 프로세서로 전달된다.
<br>여기서의 포트는 앞에서 언급한 포트와는 다르다.


<br>스위치 구조

<br>스위치 구조는 라우터의 입력 포트와 출력 포트를 연결한다.
<br>라우터 내부에 포함되어 있다.


<br>출력 포트

<br>출력 포트는 스위치 구조에서 수신한 패킷을 저장하고 필요한 링크 계층 및 물리 계층 기능을 수행하여 출력 링크로 패킷을 전송한다.
<br>링크가 양방향일 경우 출력 포트는 일반적으로 동일한 링크의 입력 포트와 한 쌍을 이룬다.


<br>라우팅 프로세서

<br>제어평면 기능을 수행한다.
<br>전통적인 라우터에서는 라우팅 프로토콜을 실행하고 라우팅 테이블과 연결된 링크 상태 정보를 유지 관리하며 라우터의 포워딩 테이블을 계산한다.
<br>SDN 라우터에서 라우팅 프로세서는 원격 컨트롤러와 통신하여 원격 컨트롤러에서 계산된 포워딩 테이블 엔트리를 수신하고 라우터의 입력 포트에 이러한 엔트리를 설치한다.
<br>네트워크 관리 기능을 수행한다.


<br>라우터의 입력 포트, 출력 포트, 스위치 구조는 거의 항상 하드웨어로 구현된다.<br>제어 평면은 일반적으로 소프트웨어로 구현되며 라우팅 프로세서(일반적으로 기존 CPU)에서 실행된다.<br><br><img src="https://user-images.githubusercontent.com/76640167/212552679-134bbf97-c8fd-452c-a6dc-283454e8d745.png" alt="입력 포트 처리" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;">
![[Pasted image 20240618005140.png]]
입력 포트의 기능은 위에서 언급한 바와 같다.<br>입력 포트에서 수행되는 검색은 라우터 동작의 핵심이다.<br>라우터는 포워딩 테이블을 사용하여 도착 패킷이 스위치 구조를 통해 전달되는 출력 포트를 검색한다.<br>포워딩 테이블은 라우팅 프로세서에서 계산되거나 갱신되거나 원격 SDN 컨트롤러에서 수신된다.<br>포워딩 테이블은 라우팅 프로세서에서 맨 위 그림과 같이 각 라인 카드로 복사되고, 이렇게 각 라인이 복사본을 사용하여 패킷 단위로 중앙 집중식 라우팅 프로세서를 호출하지 않게 되어 병목 현상을 피할 수 있다.<br><br>32비트의 IP 주소의 경우 포워딩 테이블을 억지로 구현한다면 모든 가능한 목적지 주소마다 하나의 엔트리가 필요하고, 이는 40억개 이상의 주소가 있어야 하므로 불가능하다.<br>라우터에서 0에서 3까지의 4개의 링크가 있다고 가정해보자.<br><img alt="Pasted image 20240618014252.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618014252.png"><br>
목적지 주소 범위로 포워딩 테이블을 구성할 경우 4개의 엔트리를 갖는 포워딩 테이블이면 된다.<br><br><img alt="Pasted image 20240618014249.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618014249.png"><br>
이런 형식의 포워딩 테이블에서 라우터는 패킷의 목적지 주소의 프리픽스(prefix)를 테이블의 엔트리와 매치한다.<br>예를 들어, 패킷의 목적지 주소가 11001000 00010111 00010110 10100001 라면 앞 21개의 비트 프리픽스가 테이블의 첫 번째 엔트리와 매치되므로 라우터는 이 패킷을 링크 인터페이스 0으로 보낸다.<br>11001000 00010111 00011000 10101010와 같이 처음 24비트는 2번째에 처음 21비트는 3번째에 매치되는 경우 라우터는 최장 프리픽스 매치 규칙(longest prefix matching rule)을 사용한다.<br>즉, 테이블에서 가장 긴 매치 엔트리를 찾고, 여기에 연관된 링크 인터페이스로 패킷을 보낸다. (이유에 대해서는 4.3절에서 다룬다.)<br>이러한 테이블 설계 뿐만 아니라  검색은 나노초 단위로 수행되어야 하므로 이외의 기술이 필요하다.<br>메모리 접속 시간에 특별한 주의를 기울여야 하므로 내장형 DRAM과 빠른 SRAM 메모리가 있는 설계가 필요하다. 실제로 TCAM도 검색을 위해 자주 사용된다.<br>검색을 통해 패킷의 출력 포트가 결정되면 패킷을 스위치 구조로 보낼 수 있다. 일부 설계에서는 다른 입력 포트로부터 패킷이 현재 구조를 사용하고 있다면 패킷이 스위칭 구조에 들어가는 것을 일시적으로 차단할 수 있다.<br>앞으로 패킷의 차단, 큐잉, 스케줄링에 대해 자세히 살펴본다.<br><br>스위치 구조는 패킷이 입력 포트에서 출력 포트로 실제로 스위칭 되는 구조를 통과하므로 라우터의 핵심이다.<br>여기서는 여러가지 스위칭 방법을 설명한다.<br>
<img alt="Pasted image 20240618014324.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618014324.png"><br><br><img alt="Pasted image 20240618014330.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618014330.png"><br>
초기의 라우터는 라우터 프로세서를 직접 제어해서 입력 포트와 출력 포트 사이에서 패킷을 스위칭하는 전통적인 컴퓨터다. 입력 포트와 출력 포트는 I/O 장치처럼 작동한다.<br>패킷 전달 과정<br>
<br>패킷이 도착하면 입력 포트는 라우팅 프로세서에게 인터럽트를 보내 패킷을 프로세서 메모리에 복사한다.
<br>라우팅 프로세서는 헤더에서 목적지 주소를 추출한다. 
<br>포워딩 테이블에서 적절한 출력 포트를 찾은 다음 패킷을 출력 포트의 버퍼에 복사한다.
<br>위 과정에서 메모리 대역폭이 초당 최대 B인 패킷을 메모리에 쓰거나 메모리에서 읽을 수 있는 경우 전체 전달 처리량은 B/2 보다 작아야하며 목적지 포트가 다른 경우라도 공유 시스템 버스를 통해 한 번에 하나의 메모리 읽기/쓰기 작업을 수행할 수 있기 때문에 두 패킷을 동시에 전달할 수 없다.<br>최근의 메모리를 통해 스위칭하는 라우터는 목적지 주소를 검색하고 해당 메모리 위치에 패킷을 저장하는 것이 입력 라인 카드에서 처리함으로써 수행한다.<br><br><img alt="Pasted image 20240618014413.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618014413.png"><br>
입력 포트는 라우팅 프로세서의 개입 없이 공유 버스를 통해 직접 출력 포트로 패킷을 전송한다.<br>일반적으로 미리 준비된 입력 포트 스위치 내부 레이블이 로컬 출력 포트를 나타내는 패킷에게 전송되거나 버스에 패킷을 전송하여 수행된다.<br>모든 출력 포트에 패킷이 수신되지만 레이블과 매치되는 포트만 패킷을 유지한다.<br>레이블은 버스를 통과하기 위해서만 사용되므로 출력 포트에서 제거된다.<br>동시에 여러 패킷이 다른 입력 포트에 있는 라우터에 도착하면 한 번에 하나의 패킷만 버스를 통과할 수 있기 때문에 하나를 제외한 모든 패킷이 대기 해야한다.<br>모든 패킷이 하나의 버스를 통과해야하므로 라우터의 교환 속도는 버스 속도에 의해 제한된다.<br><br><img alt="Pasted image 20240618014341.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618014341.png"><br>
크로스바 스위치는 N개의 입력 포트를 N개의 출력 포트에 연결하는 2N 버스로 구성된 상호연결 네트워크다.<br>각 수직 버스는 교차점에서 각 수평 버스와 교차하며 스위치 구조 컨트롤러에 의해 언제든지 열거나 닫을 수 있다.<br>이를 통해 앞의 두가지 방식과 달리 크로스바 스위치는 여러 패킷을 병렬로 전달할 수 있다.<br>그러나 두개의 서로 다른 입력 포트에서 나오는 2개의 패킷이 동일한 출력 포트로 보내지는 경우 한번에 하나의 패킷만 특정 버스에서 전송될 수 있기 때문에 입력을 기다려야한다.<br>좀 더 정교한 상호연결 네트워크는 다단계 스위치 구조를 통해 각기 다른 입력 포트의 패킷이 동일한 출력 포트를 향해 동시에 전달할 수 있도록 여러 단계의 스위칭 요소를 사용한다.<br><br><img alt="Pasted image 20240618015505.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618015505.png"><br>
위 그림의 출력 포트 처리는 출력 포트의 메모리에 저장된 패킷을 가져와서 출력 링크를 통해 전송한다. 여기에는 전송을 위한 패킷 선택 및 큐 제거, 필요한 링크 계층 및 물리 계층 전송 기능을 수행하는 것이 포함된다.<br><br>패킷 큐는 입력 포트와 출력 포트 모두에서 형성될 수 있다.<br>큐의 위치와 범위는 트래픽 로드, 스위치 구조의 상대 속도 및 라인 속도에 따라서 달라진다.<br>이 큐가 커지면 라우터의 메모리가 결국 소모될 수 있고 도착하는 패킷을 저장할 수 있는 메모리가 없을 때 패킷 손실이 발생한다.<br><br>지연 없이 구조를 통해 도착하는 모든 패킷을 전송하기에 스위치 구조가 충분히 빠르지 않으면 어떻게 될까?<br>이 경우에는 패킷이 스위치 구조를 통해 출력 포트로 전송되기 위해 차례를 기다려야 한다.<br>이 큐잉의 결과를 살펴보기 위해 크로스바 스위치 구조를 가정해보자.<br>
<br>모든 링크의 속도는 같다.
<br>입력 링크가 패킷을 받는 것과 같은 속도로 하나의 패킷을 입력 포트에서 주어진 출력 포트로 전달한다.
<br>FCFS (First-Come-First-Served) 방식으로 패킷은 입력 큐에서 출력 큐로 이동된다.
<br>출력 포트가 다르다면 여러 패킷이 병렬로 전달 가능하지만, 같다면 하나의 패킷만 지정된 출력 포트로 전송이 가능하고 나머지 패킷은 기다려야한다.<br><img alt="Pasted image 20240618020508.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618020508.png"><br>
위 그림에서 왼쪽 상단 큐의 앞쪽에서 먼저 패킷을 전송한다고 가정해보자.<br>왼쪽 하단 큐의 가장 앞쪽의 패킷은 출력 포트가 같으므로 대기하여야 하고, 두 번째 패킷은 출력 포트가 다름에도 앞의 패킷 때문에 대기하여야 한다.<br>이 현상은 입력 대기 중인 스위치에서의 HOL(Head-of-the-line) 차단 이라고 한다.<br><br>입력 포트와 출력 포트의 개수가 각각 N개이고 속도가 R이라 할 때, 스위치의 속도가 R보다 N배 빠르고 모든 입력 포트의 패킷이 동일한 출력 포트로 향한다고 가정해보자.<br>이 경우, 출력 링크에서 단일 패킷을 보내는 데 걸리는 시간에 N개의 새로운 패킷이 출력 포트에 도착한다. 출력 포트는 시간 단위에 단일 패킷만을 전송할 수 있기 때문에 N개의 도착 패킷은 출력 링크를 통한 전송 큐에서 대기 해야 한다.<br>이때 큐의 공간이 충분하지 않을 때, 즉 메모리가 충분하지 않을 때 도착한 패킷을 삭제하거나 이미 대기 중인 하나 이상의 패킷을 제거하여 새로 도착한 패킷을 저장하기 위한 공간을 확보해야 한다. <br><img alt="Pasted image 20240618021412.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618021412.png"><br>위 그림은 출력 포트 큐잉의 예시이다.<br>이러한 큐잉의 결과는 출력 포트의 패킷 스케줄러가 전송 대기 중인 패킷 중 하나의 패킷을 선택하여 큐에서 제거 해야한다는 것이다. (다음 절에서 다룬다.)<br><br>몇 년 동안 [RFC3439]의 버퍼의 크기에 대한 규칙은 링크 용량이 C일 때, 버퍼링의 양은 평균 왕복 시간(RTT)와 같아야 한다는 것이다.<br>즉, B = RTT x C 와 같은 버퍼의 양이 필요하다.<br>최근의 실험과 이론에서는 많은 수의 독립적인 TCP 흐름 N이 링크를 통과할 때, 필요한 버퍼링은 B = RTT x C / √N 이라고 제안하고 있다.<br>버퍼링이 클수록 라우터가 패킷 도착 속도의 큰 변동을 흡수하여 라우터의 패킷 손실률을 감소 시킬 수 있기 때문에 버퍼링이 낫다고 생각하는 것보다 버퍼가 클수록 큐잉 지연이 길어진다고 생각하는 편이 좋다.<br>예를 들어, 패킷 손실을 줄이기 위해 홉당 버퍼의 양을 10배 늘리면 종단 간 지연이 10의 배만큼 증가한다.<br>즉, 버퍼의 크기 증가는 패킷 손실율을 줄일 수 있지만 종단 간 지연을 증가시킬 수 있는 양날의 검이다.<br><img alt="Pasted image 20240618022356.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618022356.png"><br>
네트워크 가장자리의 라우터를 생각해보자.<br>a는 TCP 세그먼트를 원격 게임 서버로 보내는 홈 라우터에 대한 설명이다. 게이머의 TCP 세그먼트를 포함하는 패킷을 전송하는 데 20ms가 소요되며, 큐잉 지연이 무시해도 될 정도라고 가정한다.<br>게임 서버 경로의 다른 곳에서 지연되며 RTT는 200ms다.<br>b에서와 같이 t = 0 에서 25개 패킷의 버스트가 큐에 도착한다고 가정한다.<br>대기 중인 패킷들 중 하나는 20ms 마다 한 번씩 전송되므로, 21 번째 패킷이 전송되고 있는 것처럼 t = 200ms에서 첫 번째 ACK가 도착한다. 이 ACK 도착은 송신자가 다른 패킷을 보내게 한다.<br>홈 라우터의 송신 링크 t = 220에서 다음 ACK가 도착하고, 또 다른 ACK가 도착한다. TCP 세그먼트는 게이머에 의해 해제되며, 22번째 패킷은 전송되는 큐에 놓인다.<br>위 과정에서 ACK 클록은 대기 중인 패킷이 있을 때마다 새 패킷이 큐에 도착하게 되고, 전송되어 홈 라우터의 송신 링크에서 큐 크기가 항상 5 패킷이 된다.<br>즉, 종단 간 파이프는 꽉 찼지만 큐잉 지연의 양은 일정하고 지속적이다.<br>결과로 게이머는 홈 네트워크에 다른 트래픽이 존재하지 않는 경우에도 지연이 지속적으로 지나치게 긴 이유를 이해하지 못하게 된다.<br>이러한 지속적 버퍼링으로 인한 긴 지연에 대한 위 과정을 버퍼블로트(bufferbloat)라고 한다.<br>이를 극복하기 위해 6장에서 연구할 케이블 네트워크용 DOCIS 3.1 표준은 AQM 메커니즘을 추가하여 대량 처리 성능을 보존했다.<br><br><br><img alt="Pasted image 20240618023140.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618023140.png"><br>
링크가 현재 다른 패킷을 전송 중이면, 출력 링크 큐에 도착한 패킷은 전송을 기다린다.<br>도착한 패킷을 담을 버퍼 공간이 충분하지 않은 경우 도착 패킷의 공간을 확보하기 위해 큐의 패킷 폐기 정책은 패킷 손실 여부 또는 다른 패킷을 큐에서 제거할 것인지 여부를 결정한다.<br><img alt="Pasted image 20240618023208.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618023208.png"><br>
FIFO 스케줄링 규칙은 출력 링크 큐에 도착한 순서와 동일한 순서로 출력 링크에서 전송할 패킷을 선택한다. <br>위 그림에서는 FIFO 큐의 동작을 보여준다.<br><br><img src="https://user-images.githubusercontent.com/76640167/212632896-9184e337-91f4-4277-9b70-31d4ab83794d.png" alt="우선순위 큐 개념도" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;">
![[Pasted image 20240618025704.png]]
우선순위 큐잉에서 출력 링크에 도착한 패킷은 우선순위 클래스로 분류된다.<br>실제로 네트워크 오퍼레이터는 네트워크 관리 정보를 운반하는 패킷이 사용자 트래픽보다 우선순위를 수신하도록 큐를 구성할 수 있다.<br>전송할 패킷을 선택할 때 전송 대기 중인 패킷으로 차 있는 상태이고 가장 높은 우선순위 클래스에서 패킷을 전송한다.<br>우선순위가 동일한 패킷들 중에서의 선택은 FIFO 방식으로 행해진다.<br>
<img alt="Pasted image 20240618030307.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618030307.png"><br>위 그림은 우선순위 클래스가 2개인 경우의 큐 동작을 보여준다.<br>패킷 1,3,4가 우선순위가 높기 때문에 먼저 전송된다.<br>이때는 비선점 우선순위 큐잉이기 때문에 패킷 4의 우선순위가 높더라도 패킷 2의 전송이 시작되면 선점하지 않고 전송이 끝난 후에야 전송이 시작된다.<br><br>라운드 로빈 큐잉 큐칙에서는 패킷은 우선순위 큐잉과 같이 클래스로 분류되지만 클래스 간에는 엄격한 서비스 우선순위가 존재하지 않으며, 라운드 로빈 스케줄러가 클래스 간에 서비스를 번갈아서 제공한다.<br>가장 단순한 라운드 로빈 스케줄링에서는 그저 클래스를 번갈아가면서 패킷을 전송한다.<br>작업 보존 큐잉(work-conserving queuing) 규칙의 경우 전송을 위해 큐에서 기다리는 패킷이 있다면 링크는 유휴 상태가 되는 것을 허용하지 않는다.<br>즉, 클래스에 패킷이 없다면 바로 시퀀스의 다음 클래스를 검사한다.<br>
<img alt="Pasted image 20240618030554.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618030554.png"><br>위 그림은 라운드 로빈 큐의 동작을 보여준다.<br>
<img alt="Pasted image 20240618031441.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\attachments\pasted-image-20240618031441.png"><br>
라우터에서 널리 구현된 라운드 로빈 큐잉의 일반화된 형태는 소위 WFQ(Weighted Fair Queueing) 규칙이다.<br>도착하는 패킷은 적절한 클래스별 대기 영역에서 분류되며 대기한다. <br>WFQ 스케줄러는 라운드 로빈과 같이 순환식으로 동작한다.<br>또한, 작업 보존 큐잉 규칙을 따른다.<br>WFQ는 각 클래스 i 는 가중치 w(i)를 할당 받는다.<br>WFQ에서는 전송할 클래스 i 패킷이 있는 동안에 클래스 i는 w(i) / ∑w(i) 만큼의 서비스 시간을 보장받으며, 이 식에서 분모 부분은 전송을 위해 큐에 패킷이 있는 모든 클래스의 합이다.<br>즉, 최악의 경우 모든 큐에 패킷이 있을 때도 위의 시간을 보장 받는다.<br>따라서 전송률 R인 링크에 대해 클래스 i는 항상 최소한 R x w(i) / ∑w(i)의 처리율을 갖는다.<br>패킷이 이상적인 단위 데이터라는 것과 패킷 전송이 다른 패킷을 전송하기 위해 방해되지 않는다는 사실을 고려하지 않았기 때문에 위 설명은 이상적이다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.2-라우터-내부에는-무엇이-있을까_\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_4/4.2 라우터 내부에는 무엇이 있을까_/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Mon, 17 Jun 2024 18:24:09 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/212551546-16b6533b-58ec-421a-9863-e7d581e0cb41.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/212551546-16b6533b-58ec-421a-9863-e7d581e0cb41.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.3 인터넷 프로토콜(IP): IPv4, 주소체계, IPv6 등]]></title><description><![CDATA[ 
 <br><br><br>인터넷 네트워크 계층 패킷을 데이터그램(datagram)이라고 부른다.<br><br><img src="https://user-images.githubusercontent.com/76640167/212647972-acc5a773-a64c-4cd9-adb8-13f3f02876b9.png" alt="데이터그램" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;">
![[Pasted image 20240618032622.png]]
- `버전 번호`
    - 4비트로 데이터그램의 IP 프로토콜 버전을 명시한다.
    - 라우터는 버전 번호를 확인하여 데이터그램의 나머지 부분을 어떻게 해석할지 결정한다.
    - 다른 버전의 IP는 다른 데이터그램 포맷을 사용한다.
- `헤더 길이`
    - IPv4 데이터그램은 헤더에 가변 길이의 옵션을 포함하므로 이 네 비트로 IP 데이터그램에서 실제 페이로드가 시작하는 곳을 결정한다.
    - 대부분의 IPv4는 옵션을 포함하지 않으므로 대체로 IPv4 데이터그램 헤더는 20바이트다.
- `서비스 타입`
    - IPv4 헤더에 포함된 서비스 타입 비트는 각기 다른 유형의 IP 데이터그램을 구별한다. 예를 들어, 실시간 데이터그램과 비실시간 트래픽을 구분하는 데 유용하다.
- `데이터그램 길이`
    - 바이트로 계산한 IP 데이터그램의 전체 길이다. 총 16비트를 차지하므로 IP 데이터그램의 최대 길이는 65,535 바이트이지만 1,500보다 큰 경우는 거의 없다.
- `식별자`, `플래그`, `단편화 오프셋`
    - IP 단편화와 관련이 있는 필드들이다.
    - 큰 IP 데이터그램이 여러 개의 작은 IP 데이터그램으로 분할된 다음 목적지로 독립적으로 전달되며, 여기서 페이로드 데이터가 최종 호스트의 트랜스포트 계층으로 전달되기 전에 다시 모인다.
- `TTL(time to live)`
    - 이 필드는 네트워크에서 데이터그램이 무한히 순환하지 않도록 한다(라우팅 루프). 라우터가 데이터그램을 처리할 때마다 감소하고, 이 필드가 0이 되면 데이터그램을 폐기한다.
- `프로토콜`
    - 이 필드는 일반적으로 IP 데이터그램이 최종목적지에 도착했을 때만 사용된다. 이 필드값은 IP 데이터그램에서 데이터 부분이 전달될 목적지의 트랜스포트 계층의 특정 프로토콜(TCP, UDP)을 명시한다.
    - IP 데이터그램에서 이 필드는 트랜스포트 계층에서 포트 번호 필드와 역할이 유사하다.
- `헤더 체크섬`
    - 헤더 체크섬은 라우터가 수신한 IP 데이터그램의 비트 오류를 탐지하는데 도움을 준다.
    - 라우터는 오류 검출된 데이터그램을 폐기한다.
    - TTL 필드와 옵션 필드의 값은 변경되므로 체크섬은 각 라우터에서 재계산되고 저장되어야 한다.
    - 트랜스 포트 계층과 네트워크 계층에서 오류 검사를 수행하는 이유
        - IP 헤더만 IP 계층에서 체크섬을 수행하지만 TCP/UDP 체크섬은 전체 TCP/UDP 세그먼트를 계산한다.
        - TCP/UDP와 IP는 동일한 프로토콜 스택에 속할 필요가 없다. 원리상 TCP는 IP가 아닌 곳 위에서도 운영될 수 있다.
- `출발지와 목적지 IP 주소`
    - 출발지가 데이터그램을 생성할 때, 자신의 IP 주소를 출발지 IP 주소 필드에 삽입하고 목적지 IP 주소를 목적지 IP 주소 필드에 삽입한다.
- `옵션`
    - IP 헤더 필드를 확장한다.
    - 모든 데이터그램 헤더 옵션 필드에 정보를 포함하지 않는 방법으로 오버헤드를 해결하기 위해 헤더 옵션은 거의 사용되지 않는다.
    - 데이터그램 헤더가 가변 길이로 데이터 필드 시작점을 초기에 결정할 수 없어 문제를 복잡하게 만든다.
- `데이터(페이로드)`
    - 데이터그램이 존재하는 이유이자 가장 중요한 마지막 필드이다. 대부분의 경우 목적지에 전달하기 위해 트랜스포트 계층 세그먼트를 포함한다.<br>대부분의 IP 데이터그램은 총 20바이트(옵션은 없다고 가정)의 헤더를 갖는다.<br>TCP 세그먼트를 전송한다면 단편화가 되지 않은 각 데이터그램은 애플리케이션 계층의 메시지와 더불어 총 40바이트의 헤더(IP 헤더 20, TCP 헤더 20)을 전송한다.<br><br>호스트는 일반적으로 네트워크와 연결되는 하나의 링크를 갖는다.<br>호스트 IP가 데이터그램을 보낼 때 이 링크를 통해 데이터링크를 보낸다.<br>호스트와 물리적 링크 사이의 경계를 인터페이스(interface)라고 부른다.<br>라우터는 여러 개의 링크와 연결되고, 링크와 라우터 사이도 인터페이스(interface)로 이루어져있어 여러개의 인터페이스(interface)를 갖는다.<br>모든 호스트와 라우터는 IP 데이터그램을 송수신할 수 있으므로 IP는 각 호스트와 라우터 인터페이스가 IP 주소를 갖도록 요구한다.<br>이러한 각 인터페이스는 고유한 IP 주소를 갖는다.<br>따라서 기술 면에서 IP 주소는 인터페이스(interface)를 포함하는 호스트 라우터보다는 인터페이스(interface)와 관련이 있다.<br><br>각 IP 주소는 32비트 길이다. 따라서 2^32개의 주소를 사용할 수 있다. 일반적으로 주소의 각 바이트를 십진수로 표현하고 주소의 다른 바이트와 점으로 구분하는 십진 표기법을 사용한다.<br>인터페이스의 IP는 마음대로 선택할 수 없다. IP 주소의 일부는 연결된 서브넷이 결정한다.<br>
<img alt="Pasted image 20240618040414.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.3-인터넷-프로토콜(ip)_-ipv4,-주소체계,-ipv6-등\attachments\pasted-image-20240618040414.png"><br>
왼쪽 3개의 호스트와 라우터 인터페이스는 모두 223.1.1.xxx 형식의 IP 주소를 갖는다. 또, 4개의 인터페이스가 중계하는 라우터 없이 하나의 네트워크에 서로 연결되어 있다.<br>이 네트워크는 이더넷 LAN으로 상호연결되고 이 경우 인터페이스는 이더넷 허브나 이더넷 스위치 또는 무선 AP로 상호연결된다.<br>IP 용어로 세 호스트 들의 인터페이스들과 하나의 라우터 인터페이스로 연결된 네트워크는 서브넷(subnet)을 구성한다고 말한다.<br>IP 주소체계는 이 서브넷에 223.1.1.0/24 라는 주소를 할당하는데 여기서 /24는 서브넷 마스크라 부르는데, 왼쪽 24비트가 서브넷 주소라는 것을 가리킨다.<br>위 그림에서는 3개의 서브넷을 볼 수 있다.<br><img src="https://user-images.githubusercontent.com/76640167/212667479-eb056442-26a3-4e8f-8bf7-97a1e864981a.png" alt="6개의 서브넷" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>서브넷 IP의 정의는 여러 호스트를 라우터 인터페이스에 연결하는 이더넷 세그먼트만을 의미하는 것은 아니다.<br>위 그림을 보면 3개의 라우터도 점대점으로 연결되어있는 것을 볼 수 있다.<br>여기서는 호스트와 라우터의 연결 뿐만 아니라 라우터 간의 연결에서도 서브넷을 볼 수 있다.<br>총 6개의 서브넷을 찾을 수 있다.<br>서브넷의 정의<br>
💡서브넷을 결정하려면 먼저 호스트나 라우터에서 각 인터페이스를 분리하고 고립된 네트워크를 만든다. 이 고립된 네트워크의 종단점은 인터페이스의 끝이 된다. 이렇게 고립된 네트워크 각각을 서브넷이라고 부른다.
<br>위에 의하면 다수의 이더넷 세그먼트와 종단 간의 링크를 갖는 기관은 한 서브넷에서 모든 장비가 같은 서브넷 주소를 갖는 그런 서브넷을 여러개 가질 수 있다.<br>서로 다른 서브넷은 다른 주소를 가져야 하지만 실제로 서브넷 주소는 같은 부분이 많다.<br><br>인터넷 주소 할당 방식 중 하나다.<br>CIDR는 서브넷 주소 체계 표기를 일반화하고 있다.<br>a.b.c.d/x 형식 주소에서 최상위 비트(Most significant bit)를 의미하는 x는 IP 주소의 네트워크 부분을 구성한다.<br>이를 해당 주소의 프리픽스 또는 네트워크 프리픽스라고 부른다.<br>한 기관은 통상 연속적인 주소의 블록(공통 프리픽스를 갖는 주소 범위)을 할당 받고 기관 장비들의 IP 주소는 공통 프리픽스를 공유한다.<br>외부 기관의 라우터는 목적지 주소가 내부 기관인 데이터그램을 전달할 때, 단지 앞의 x 비트들만 고려한다.<br>a.b.c.d/x 형태의 한 엔트리만으로 기관 목적지로 패킷을 전달하는 데 충분하므로, 이런 라우터들에서 포워딩 테이블의 크기를 상당히 줄여준다.<br>주소의 나머지 32-x 비트들은 기관 내부에 같은 네트워크 프리픽스를 갖는 모든 장비를 구별한다.<br>이 비트들은 기관 내부의 라우터에서 패킷을 전달할 때 사용되며 이 하위 비트들은 추가적으로 서브넷 구조를 가질 수도 있다.<br><br>CIDR가 채택되기 전에는 IP 주소의 네트워크 부분을 8, 16, 24 비트로 제한했고 각각의 비트를 서브넷 주소로 갖는 서브넷을 각각 A, B, C 클래스 네트워크로 분류했기 때문에 이러한<br>
주소체계는 클래스 주소체계라고 알려졌다.<br>그러나 서브넷 부분이 정확히 1, 2, 3 바이트여야 하는 요구사항은 중소형 크기의 네트워크로 급속히 증가하는 기관의 수를 지원하기엔 문제가 있었다.<br>예를 들어 클래스(/24) 서브넷은 254개의 호스트만을 제공하므로 많은 조직을 위해서는 턱없이 부족하고, 클래스(/16) 서브넷은 65634개의 호스트를 제공하여 너무 크다.<br><br>IP의 또 다른 형태인 브로드캐스트 주소 255.255.255.255가 있다.<br>호스트가 목적지 주소가 255.255.255.255인 데이터그램을 보내면, 이 메시지는 같은 서브넷에 있는 모든 호스트에게 전달된다.<br>다음으로는 한 기관에서 그들의 장비를 위한 주소 블록을 어떻게 획득하는지 알아본 후에, 이 획득한 주소 블록의 주소를 어떻게 장비에 할당하는지 살펴보겠다.<br><br>기관의 서브넷에서 사용하기 위한 IP 주소 블록을 얻기 위해, 네트워크 관리자는 먼저 이미 할당받은 주소의 큰 블록에서 주소를 제공하는 ISP와 접촉해야 한다.<br><img src="https://user-images.githubusercontent.com/76640167/212675085-61430550-15e6-4fb9-a909-1a7bb8bac116.png" alt="IP 주소 블록" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;">
![[Pasted image 20240618041549.png]]
ISP가 위와 같은 블럭을 할당 받았다고 할 때, ISP는 블록을 다음처럼 같은 크기의 작은 주소 블록 8개로 나누고, 이것으로 8개 조직을 지원할 수 있다.<br>ISP는 비영리 단체인 ICANN으로 부터 주소 블록을 할당 받는다.<br>ICANN의 역할은 IP 주소 할당과 DNS 루트 서버 관리다.<br><br>한 기관은 ISP로부터 주소 블록을 획득하여, 개별 IP 주소를 기관 내부의 호스트와 라우터 인터페이스에 할당한다.<br>라우터 인터페이스 주소에 대해, 시스템 관리자는 라우터 안에 IP 주소를 할당한다.<br>호스트에 IP 주소를 할당하는 것은 수동으로 구성이 가능하지만 일반적으로 동적 호스트 구성 프로토콜(DHCP)을 많이 사용한다.<br>DHCP는 호스트가 IP 주소를 자동으로 얻을 수 있게 하고, 서브넷 마스크, 첫 번째 홉 라우터 주소나 로컬 DNS 서버 주소 같은 추가 정보를 얻게 해준다.<br>DHCP는 자동으로 호스트와 연결해주는 능력 때문에 플러그 앤 플레이 프로토콜 또는 제로 구성 프로토콜이라고도 한다.<br><img alt="Pasted image 20240618042542.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.3-인터넷-프로토콜(ip)_-ipv4,-주소체계,-ipv6-등\attachments\pasted-image-20240618042542.png"><br>
DHCP는 클라이언트-서버 프로토콜이다.<br>클라이언트는 일반적으로 IP 주소를 포함하며 네트워크 설정을 위한 정보를 얻고자 새롭게 도착한 호스트다.<br>각 서브넷은 DHCP 서버를 갖거나 없다면 해당 네트워크에 대한 DHCP 서버 주소를 알려줄 DHCP 연결 에이전트(일반적으로 라우터)가 필요하다.<br><img src="https://user-images.githubusercontent.com/76640167/212680264-a3e3a046-d66c-46d3-b09f-2961a5717062.png" alt="DHCP 동작" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;">
![[Pasted image 20240618042605.png]]
위 그림은 새로운 호스트가 도착할 경우, DHCP 프로토콜의 4단계 과정을 보여준다.<br>
<br>DHCP 서버 발견

<br>먼저 새롭게 도착한 호스트는 상호작용할 DHCP를 발견한다. 이것은 DHCP 발견 메시지를 사용하여 수행되며, 클라이언트는 포트 67번으로 UDP 패킷을 보낸다.
<br>DHCP 클라이언트는 DHCP 발견 메시지를 포함하는 IP 데이터 그램을 생성하는데, 이 메시지 내의 목적지 IP 주소를 브로드캐스트 IP 주소 255.255.255.255로 설정하고 출발지 IP<br>
주소는 0.0.0.0으로 설정한다.
<br>링크 계층으로 IP 데이터그램을 보내며 이 프레임은 서브넷에 연결된 모든 노드로 브로드캐스트된다.


<br>DHCP 서버 제공

<br>DHCP 발견 메시지를 받은 DHCP 서버는 DHCP 제공 메시지를 클라이언트로 응답한다.
<br>이때에도 IP 브로드캐스트 주소를 사용하여 서브넷의 모든 노드로 이 메시지를 브로드캐스트한다.
<br>서브넷에는 여러 DHCP 서버가 존재하기 때문에, 클라이언트는 여러 DHCP 제공 메시지로부터 가장 최적의 위치에 있는 DHCP 서버를 선택한다.
<br>각각의 서버 제공 메시지는 수신된 발견 메시지의 트랜잭션 ID, 클라이언트에 제공된 IP 주소, 네트워크 마스크, IP 주소 임대 기간을 포함한다.


<br>DHCP 요청

<br>새롭게 도착한 클라이언트는 하나 또는 그 이상의 서버 제공자 중에서 선택할 것이고 선택된 제공자에게 파라미터 설정으로 되돌아오는 DHCP 요청 메시지로 응답한다.


<br>DHCP ACK

<br>서버는 DHCP 요청 메시지에 대해 요청된 파라미터를 확인하는 DHCP ACK 메시지로 응답한다.


<br>클라이언트가 DHCP ACK을 받으면 상호작용이 종료되고 클라이언트는 임대 기간동안 할당 IP 주소를 사용할 수 있다.<br>DHCP는 노드가 새로운 서브넷에 연결하고자 할 때마다 새로운 IP 주소를 DHCP로부터 얻기 때문에, 이동 노드가 서브넷 사이를 이동할 때 원격 애플리케이션에 대한 TCP 연결이 유지될 수 없다는 결점이 있다.<br><br>모든 호스트가 서브넷으로부터 IP를 할당받고 할 때 네트워크가 현저하게 커지면 큰 주소 블록이 할당되어야 한다.<br>ISP가 이미 해당 주소 범위의 인접한 부분을 할당해버리는 등의 문제가 발생할 수 있는데 이런 경우에는 네트워크 주소 변환(NAT)으로 주소를 할당할 수 있다.<br><img alt="Pasted image 20240618043336.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.3-인터넷-프로토콜(ip)_-ipv4,-주소체계,-ipv6-등\attachments\pasted-image-20240618043336.png"><br>
NAT 가능 라우터는 위 그림의 오른쪽처럼 홈 네트워크의 일부인 인터페이스를 갖는다.<br>홈 네트워크의 4개 인터페이스 모두 같은 네트워크 주소 10.0.0.0/24를 갖는다.<br>주소 공간 10.0.0.0/8은 사설망 또는 그림의 홈 네트워크와 같은 사설 개인 주소를 갖는 권역(realm)을 위해 RFC에 예약된 IP 주소 공간 세 부분 중의 하나다.<br>
💡 사설 개인 주소를 갖는 권역(realm)이란 네트워크 주소들이 그 네트워크 내부에 있는 장비에게만 의미가 있는 그런 네트워크를 의미한다.
<br>사설 개인 주소를 갖는 권역은 홈 네트워크 내부에서만 의미가 있다. 즉, 글로벌 인터넷과는 송수신할 수 없다.<br>NAT 가능 라우터는 외부 세계로는 하나의 IP 주소를 갖는 하나의 장비로 동작한다.<br>그림을 보면 홈 라우터를 떠나 인터넷으로 가는 트래픽의 출발지 IP 주소는 138.76.29.7 즉, 라우터의 출력 라우터 인터페이스의 IP 주소를 갖는다.<br>홈으로 들어오는 트래픽의 목적지 주소는 마찬가지로 138.76.29.7을 가져야한다.<br>본질적으로 NAT 가능 라우터는 외부에서 들어오는 홈 네트워크의 상세한 사항을 숨긴다.<br>WAN에서 같은 목적지 IP 주소를 갖는 NAT 라우터에 모든 데이터 그램이 도착하면, 라우터가 주어진 데이터그램을 전달하는 내부 호스트를 어떻게 알 수 있을까?<br>NAT 라우터에서 NAT 변환 테이블을 사용하고, 그 테이블에 IP 주소와 포트 번호를 포함하여 알 수 있다.<br>위 그림의 NAT 변환 테이블을 보며 순서대로 잘 따라가보길 바란다.<br>웹 서버는 내부 호스트를 모른채 WAN side의 라우터를 목적지 IP로 하여 응답하고, 라우터는 이 응답을 NAT 변환 테이블을 사용하여 알맞은 내부 호스트에 전달한다.<br>포트 번호는 호스트 주소 지정이 아닌 프로세스 주소 지정에 사용된다.<br>서버 프로세스는 잘 알려진 포트 번호에서 요청이 올 때까지 기다리고 P2P 프로토콜의 피어는 서버로서의 역할을 할 때 들어오는 연결을 수락해야 하기 때문에 홈 네트워크에서 실행되는 서버에 문제가 발생할 수 있다.<br>이 문제의 기술적인 해결책으로는 NAT 순회 도구가 있다.<br><br>IPv4 주소 공간이 빠르게 고갈되어가면서 IPv6 주소 체계가 개발되었다.<br><br>IPv6 중요한 변화<br>
<br>확장된 주소 기능

<br>IPv6는 IP 주소 크기를 32비트에서 128비트로 확장했으므로 IP 주소가 고갈되는 일은 발생하지 않을 것이다.
<br>IPv6는 유니캐스트, 멀티캐스트 주소뿐만 아니라 새로운 주소 형태인 애니캐스트 주소가 도입되었다. 애니 캐스트 주소로 명시된 데이터그램은 호스트 그룹의 어떤 이에게든 전달될 수 있다.


<br>간소화된 40 바이트 헤더

<br>40 바이트 고정 길이 헤더는 라우터가 IP 데이터그램을 더 빨리 처리하게 해준다.
<br>새로운 옵션 인코딩은 유연한 옵션 처리를 가능하게 한다.


<br>흐름 레이블링

<br>정의하기 어려운 흐름을 갖고있다. RFC는 "비 디폴트 품질 서비스나 실시간 서비스 같은 특별한 처리를 요청하는 송신자에 대해 특정 흐름에 속하는 패킷 레이블링"을 가능하게 한다고 설명한다.<br>
아직 정확한 의미는 정의되지 않았지만, 언젠가 필요할 흐름 차별화를 예견하여 구현하였다.


<br><img src="https://user-images.githubusercontent.com/76640167/212698226-9bf18f85-3111-4434-9202-f2ed45aabd28.png" alt="IPv6 데이터그램 포맷" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>IPv6 데이터그램 포맷은 그림과 같다.<br>
<br>버전

<br>4비트 필드는 IP 버전 번호를 인식한다. IPv6라면 6이다.


<br>트래픽 클래스

<br>IPv4의 TOS 필드와 비슷한 의미로 만든 8비트 필드는 흐름 내의 SMTP 이메일 같은 애플리케이션의 데이터그램보다 Volp 같은 특정 애플리케이션 데이터그램에 우선순위를 부여하는데 사용된다.


<br>흐름 레이블

<br>데이터그램의 흐름을 인식하는데 사용된다.


<br>페이로드 길이

<br>이 16비트 값은 IPv6 데이터그램에서 고정 길이 40바이트 패킷 헤더 뒤에 나오는 바이트 길이이며, 부호 없는 정수다.


<br>다음 헤더

<br>이 필드는 데이터그램의 내용이 전달될 프로토콜을 구분한다.(TCP, UDP)


<br>홉 제한

<br>라우터가 데이터그램을 전달할 때 마다 1씩 감소하고, 0이되면 데이터그램이 라우터에 의해 버려진다.


<br>출발지와 목적지 주소

<br>출발지와 목적지 주소를 담고 있다.


<br>데이터

<br>IPv6 데이터그램의 페이로드 부분이다. 데이터그램이 목적지에 도착하면 IP 데이터그램에서 페이로드를 제거한 후, 다음 헤더 필드에 명시한 프로토콜에 전달한다.


<br>IPv4에는 있지만 IPv6에는 없는 필드<br>
<br>단편화/재결합

<br>IPv6에서는 단편화와 재결합을 출발지와 목적지만이 수행한다.
<br>라우터가 받은 IPv6 데이터그램이 너무 커서 출력 링크로 전달할 수 없다면 라우터는 데이터그램을 폐기하고 너무 크다는 ICMP 오류 메시지를 송신자에게 보낸다.
<br>송신자는 데이터를 IP 데이터그램 크기를 줄여서 다시 보낸다.
<br>라우터에서 이 기능을 수행하는 것은 시간이 오래 걸리므로 이 기능을 삭제하여 IP 전달 속도를 증가시켰다.


<br>헤더 체크섬

<br>트랜스포트 계층 프로토콜과 데이터 링크 프로토콜은 체크섬을 수행하므로 IP 설계자는 네트워크 계층의 체크섬 기능이 반복되는 것으로 생략해도 될 것이라 생각하여 삭제했다.


<br>옵션

<br>IPv4에서도 잘 사용되지 않았던 필드가 사라지고 고정 헤더의 길이를 갖게되었다.
<br>다대신 옵션 필드는 IPv6 헤더에서 다음 헤더 중 하나가 될 수 있다.


<br><br>IPv6는 IPv4 데이터그램을 보내고 라우팅하며 받을 수 있는 새 IPv6 시스템이 있는 반면에, IPv4로 구축된 시스템은 IPv6 데이터그램을 처리할 수 없다는 것에서 발생한다.<br><br>모든 인터넷 장비를 끄고 IPv4를 IPv6로 업그레이드하는 시간과 날짜를 정하는 것으로 40년 전에 실제로 NCP를 TCP로 전이하였다.<br>그러나 수억개의 장비가 관련된 플레그 데이는 오늘날에는 절대 불가능하다.<br><br><img src="https://user-images.githubusercontent.com/76640167/212711125-cbde816b-a934-4a2e-a404-92665e9e93ea.png" alt="터널링" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br>실제로 널리 사용하는 방법이다.<br>두 IPv6 노드(그림에서는 B와 E)가 IPv6 데이터그램을 사용해서 작동한다고 가정해보자.<br>물론 이들은 IPv4 라우터를 통해 연결되어있다. 이렇게 IPv6 노드 사이에 연결되어있는 IPv4 라우터들을 터널(tunnel)이라고 한다.<br>IPv6 송신 과정<br>
<br>터널의 송신 측에 있는 IPv6 노드는 IPv6 데이터그램을 받고 IPv4 데이터그램의 데이터 필드에 이것을 넣는다.
<br>IPv4 데이터그램에 목적지 주소를 터널의 수신 측에 IPv6 노드로 적어서 터널의 첫 번째 노드에 보낸다.
<br>터널 내부에 있는 IPv4라우터는 IPv4 라우터는 IPv4 데이터그램이 IPv6 데이터그램을 갖고 있다는 사실을 모른채 다른 데이터그램을 처리하는 방식으로 IPv4 데이터 그램을 처리한다.
<br>터널 수신 측에 있는 IPv6 노드는 IPv4 데이터그램을 받고 이 IPv4 데이터그램이 실제 IPv6 데이터그램임을 결정한다.
<br>다음 노드에 IPv6 데이터그램을 보낸다.
<br>기초적인 IPv6 수용은 이루어지고 있지만 최근에 이루어진 것은 없다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.3-인터넷-프로토콜(ip)_-ipv4,-주소체계,-ipv6-등\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_4/4.3 인터넷 프로토콜(IP)_ IPv4, 주소체계, IPv6 등/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Mon, 17 Jun 2024 19:56:16 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/76640167/212647972-acc5a773-a64c-4cd9-adb8-13f3f02876b9.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/76640167/212647972-acc5a773-a64c-4cd9-adb8-13f3f02876b9.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.4 일반화된 포워딩 및 소프트웨어 기반 네트워크(SDN)]]></title><description><![CDATA[ 
 <br><br>목적지 IP 주소를 찾은(매치) 후 패킷을 스위치 구조로 지정된 출력 포트로 전송(액션)하는 두 단계의 목적지 기반 포워딩을 앞서 설명했다.<br>프로토콜 스택의 다른 계층에서 다른 프로토콜과 관련된 여러 헤더 필드에 대해 매치를 수행할 수 있는 일반적인 매치 플러스 액션 방법을 생각해보자.<br>액션은 하나 이상의 출력 포트로 패킷을 전달하고, 인터페이스에서 나가는 패킷을 로드 밸런싱(load balancing)하고 헤더값을 다시 쓰고, 의도적으로 패킷을 차단/삭제 및 추가 처리 작업을 위해 특수 서버로 패킷을 보내는 등의 작업을 수행한다.<br>일반화된 포워딩에서는 각각의 패킷 스위치는 원격 컨트롤러에 의해 계산 및 분포된 매치 플러스 액션 테이블을 포함하고 있다.<br><img alt="Pasted image 20240618050117.png" src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.4-일반화된-포워딩-및-소프트웨어-기반-네트워크(sdn)\attachments\pasted-image-20240618050117.png"><br>
위 그림은 매치 플러스 액션 테이블을 보여준다. <br><br>명확하고 간결한 방식으로 SDN 개념 및 기능을 도입한 OpenFlow 1.0을 살펴보자.<br>OpenFlow의 플로우 테이블로 알려진 매치 플러스 액션 포워딩 테이블의 각 엔트리는 다음을 포함한다.<br>
<br>들어오는 패킷에 대한 헤더값들의 세트가 매치될 것이다. 하드웨어 기반 매치는 TCAM 메모리에서 가장 신속하게 수행되며, 백만 개가 넘는 목적지 주소를 동반한다. 플로우 테이블 엔트리와 매치되지 않는 패킷은 더 많은 처리를 위해 원격 컨트롤러로 전송될 수 있다.
<br>패킷들에 의해 갱신되는 카운터 세트는 플로우 테이블 엔트리들과 매치된다. 이러한 카운터는 플로우 테이블 엔트리와 마지막으로 갱신된 테이블 엔트리 이후에 매치된 다수의 패킷을 포함하고 있다.
<br>패킷이 플로우 테이블 엔트리와 매치될 때 여러가지 액션이 가능해진다. 이러한 액션은 패킷을 지정된 출력 포트로 전달하고, 패킷을 삭제하고, 패킷의 복사본을 만들어 여러 출력 포트로 보내거나 선택한 헤더 필드를 다시 쓰는 것일 수 있다.
<br><br><img src="https://user-images.githubusercontent.com/76640167/213117975-972cdf56-575f-4e0d-b9b2-662f3ea2278f.png" alt="매치 인 액션 매치" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br>위 그림은 OpenFlow 1.0 매치 플러스 액션 규칙에서 매치될 수 있는 11개의 패킷 헤더 필드와 수신 포트 ID를 보여준다.<br>진입 포트는 패킷이 수신되는 패킷 스위치의 입력 포트를 나타낸다.<br>플로우 테이블 엔트리에는 와일드카드도 있을 수 있다. 예를 들어, 플로우 테이블의 128.119.*.* 의 주소는 128.119를 주소의 첫 번째 16 비트로 갖는 데이터그램의 해당 주소 필드와 매치된다.<br>또한 각 플로우 테이블 엔트리에는 우선순위가 있어 여러 플로우 테이블 엔트리와 매치되면, 선별된 매치 엔트리에 해당하는 패킷이 가장 높은 우선순위가 된다.<br>IP 헤더의 모든 필드가 매치될 수 있는 것은 아니다.<br>예를 들어 OpenFlow에서는 TTL 필드 또는 데이터그램 길이 필드에 기반한 매치를 허용하지 않는다.<br><br>플로우 테이블 엔트리는 플로우 테이블 엔트리와 매치되는 패킷 처리를 결정하는 0개 이상의 액션 목록을 갖고 있다.<br>여러 액션이 있는 경우 목록에 지정된 순서대로 수행된다.<br>가장 중요한 액션들은 다음과 같다.<br>
<br>포워딩

<br>들어오는 패킷은 특정 실제 출력 포트로 전달되거나 모든 포트를 통해 브로드캐스트되거나 선택된 포트 세트를 통해 멀티캐스트될 수 있다.
<br>패킷은 캡슐화되어 원격 컨트롤러로 전송될 수 있다.
<br>컨트롤러는 새 플로우 테이블 엔트리를 설치하고 해당 패킷에 대한 조치를 취하거나 갱신된 플로우 테이블 규칙에 따라 포워딩을 위해 패킷을 장치로 반환할 수 있다.


<br>삭제

<br>아무 액션이 없는 플로우 테이블 엔트리는 매치된 패킷을 삭제해야함을 나타낸다.


<br>필드 수정

<br>패킷이 선택된 출력 포트로 전달되기 전에 10개의 패킷 헤더 필드의 값을 다시 쓸 수 있다.


<br><br><img src="https://user-images.githubusercontent.com/76640167/212724509-ca68b882-f24f-4393-9034-e7fa6bce256d.png" alt="OpenFlow exam" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>위 그림의 상황을 가정하고 다음 예시들을 보자.<br><br>아주 간단한 예로 포워딩 동작이 h3 또는 h4로 예정된 h5 또는 h6 패킷이 s3에서 s1으로 전달된 다음 s1에서 s2로 전달된다고 가정한다.<br>위 상황에서 s1의 플로우 테이블 엔트리는 다음과 같다.<br><img src="https://user-images.githubusercontent.com/76640167/212725481-048ae901-3c53-4e3c-a86a-d6f6d53fab09.png" alt="간단한 포워딩 s1" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>s3에 플로우 테이블 엔트리가 필요하므로 h5 또는 h6에서 전송된 데이터그램은 인터페이스 3을 통해 s1으로 전달된다.<br><img src="https://user-images.githubusercontent.com/76640167/212725550-5273ec3e-4800-44d1-b038-177fd36a96ad.png" alt="간단한 포워딩 s2" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>마찬가지로, s1에 도착한 데이터그램을 호스트 h3 또는 h4로 전달할 수 있도록 s2에 플로우 테이블 엔트리가 필요하다.<br>위를 바탕으로 직접 채워보길 바란다.<br><br><br><br>두 번째 예로 h3에서 10.1.*.*로 향하는 데이터그램이 s2와 s1 사이의 링크를 통해 전달되는 반면, h4에서 10.1.*.* 로의 데이터그램은 s2와 s3 사이의 링크를 통해 전달되는 로드 밸런싱 시나리오를 고려해보자.<br>이 동작은 IP의 목적지 기반 포워딩으로 수행될 수 없다.<br>이 경우 s2의 포워딩 테이블은 다음과 같다.<br><img src="https://user-images.githubusercontent.com/76640167/212727669-ff3f78b5-625c-410c-b873-c0b37ac82a51.png" alt="로드 밸런싱" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>s2에서 수신한 데이터그램을 h1 또는 h2로 전달하려면 s1에서 플로우 테이블 엔트리가 필요하다.<br>인터페이스 4에서 수신한 데이터그램을 s3에서 인터페이스 3을 통해 s1로 전달하려면 s3에서 플로우 테이블 엔트리가 필요하다. s1및 s3에서 이러한 플로우 테이블 엔트리를 파악할 수 있는지 확인하자.<br><br><br><br><img src="https://user-images.githubusercontent.com/76640167/212728865-3eefb52a-15fd-4555-927e-911971ce3725.png" alt="방화벽" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>s2가 s3에 연결된 호스트에서 보낸 트래픽만 수신하려고 하는 방화벽 시나리오를 생각해보자.<br>s2 플로우 테이블에 다른 엔트리가 없으면 10.3.*.*의 트래픽만 s2에 연결된 호스트로 전달된다.<br><br><br>매치 플러스 액션 플로우 테이블은 제한된 형태의 프로그래밍 가능성이다.<br>데이터그램의 헤더값과 매치 조건 사이의 매치를 기반으로 라우터가 데이터그램을 전달하고 조작하는 방법을 명시한다.<br>따라서 더 풍부한 형태의 프로그래밍 가능성을 상상할 수 있다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.4-일반화된-포워딩-및-소프트웨어-기반-네트워크(sdn)\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_4/4.4 일반화된 포워딩 및 소프트웨어 기반 네트워크(SDN)/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Mon, 17 Jun 2024 20:45:47 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.4-일반화된-포워딩-및-소프트웨어-기반-네트워크(sdn)\attachments\pasted-image-20240618050117.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.4-일반화된-포워딩-및-소프트웨어-기반-네트워크(sdn)\attachments\pasted-image-20240618050117.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.5 미들박스]]></title><description><![CDATA[ 
 <br><br>미들 박스의 정의<br>
💡출발지 호스트와 목적지 호스트 사이의 데이터 경로에서 IP 라우터의 정상적이고 표준적인 기능과는 별도로 기능을 수행하는 모든 미들박스
<br>미들 박스가 수행하는 세 가지 유형의 서비스를 광범위하게 식별할 수 있다.<br>
<br>NAT 변환 : NAT 박스는 사설 네트워크 주소체계를 구현하여 데이터그램 헤더 IP 주소 및 포트 번호를 다시 작성한다.
<br>보안 서비스 : 방화벽은 헤더 필드 값을 기준으로 트래픽을 차단하거나 DPI(Deep Packet Inspection) 같은 추가 처리를 위해 패킷을 리다이렉션한다. 침입 탐지 시스템(IDS)은 미리 결정된 패턴을 탐지하고 그에 따라 패킷을 필터링할 수 있다.
<br>성능 향상 : 미들박스는 압축과 같은 서비스를 수행한다. 즉, 원하는 서비스를 제공할 수 있는 서버 집합 중 하나에 대한 서비스 요청의 로드 밸런싱을 하는 주체다.
<br>미들 박스는 네트워크 계층과 트랜스포트계층, 애플리케이션 계층을 명확히 구분하는 이전 네트워크의 분리를 명백히 위반한다.<br>예를 들어, 라우터와 호스트 사이에 위치한 NAT 박스는 네트워크 계층 IP 주소와 트랜스포트 계층 포트 번호를 다시 쓴다.<br>네트워크 내의 방화벽 블록은 IP 데이터그램 헤더 뿐만 아니라 애플리케이션 계층, 트랜스포트 계층 헤더까지 사용하여 데이터그램을 의심한다.<br>미들박스를 아키텍처적으로 혐오스럽다고 간주하는 사람들도 있지만, 다른 이들은 이러한 미들 박스가 '중요하고 영구적으로 존재한다'는 철학을 채택하고 있다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_4\4.5-미들박스\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_4/4.5 미들박스/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:23 GMT</pubDate></item><item><title><![CDATA[5.1 개요]]></title><description><![CDATA[ 
 <br><br>포워딩 테이블(목적지 기반 포워딩의 경우)과 플로우 테이블(일반화된 포워딩의 경우)이 네트워크 계층의 데이터 평면과 제어 평면을 연결하는 수요 요소였는데,<br>
이 테이블들이 라우터의 로컬 데이터 평면에서의 포워딩을 지정했다.<br>바로 이전 장에서의 그림을 상기해보자.<br><img src="https://user-images.githubusercontent.com/86337233/213144150-84a7748e-3547-47c6-86d5-c454686cb6e6.png" alt="포워딩 테이블 1" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><img src="https://user-images.githubusercontent.com/86337233/213144144-816658f9-54f9-4782-afc5-016e19310c12.png" alt="포워딩 테이블 2" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br>일반화된 포워딩의 경우에 라우터가 취하는 행동은 다양한 형태로 나타날 수 있었다.<br>
<br>라우터의 출력 포트로 패킷을 전달
<br>패킷을 버리거나 복제
<br>2, 3, 4계층의 헤더 필드를 재작성
<br>이 장에서는 포워딩 테이블이나 플로우 테이블이 어떻게 만들어지고 유지 및 설치되는지를 알아볼 것이다.<br><br>
💡 개별 라우팅 알고리즘들이 제어 평면에서 상호작용한다.
<br>아래 그림은 라우팅 알고리즘들이 모든 라우터 각각에서 동작하는 경우를 나타낸다.<br><img src="https://user-images.githubusercontent.com/86337233/213144138-0baa9de9-c18c-4349-ad2a-6198a6dce222.png" alt="라우터별 제어" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br>
<br>포워팅과 라우팅 기능이 모두 개별 라우터에 포함되어 있다.
<br>각 라우터는 다른 라우터의 라우팅 구성요소와 통신하여<br>
자신의 포워딩 테이블의값을 계산하는 라우팅 구성요소를 갖고 있다.
<br>OSPF, BGP 프로토콜이 이 라우터별 제어 방식을 기반으로 한다.
<br><br>
💡 일반적으로 원격에 위치한 별개의 컨트롤러가 지역의 제어 에이전트(CA)와 상호작용한다.
<br>아래 그림은 논리적 중앙 집중형 컨트롤러가 포워딩 테이블을 작성하고, 이를 모든 개별 라우터가 사용할 수 있도록 배포한 경우를 나타낸다.<br>
<img src="https://user-images.githubusercontent.com/86337233/213144125-6428c97b-0b2c-4579-8074-dc12785f9361.png" alt="논리적 중앙 집중형 제어" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br>일반화된 ‘매치 플러스 액션(match plus action)’ 추상화를 통해<br>
라우터는 기존에는 별도로 장치로 구현되었던 다양한 기능(부하 분산, 방화벽, NAT) 뿐만 아니라 전통적인 IP 포워딩을 수행할 수 있다.<br>컨트롤러는 프로토콜을 통해 각 라우터의 제어 에이전트(control agent, CA)와 상호작용하여 라우터의 플로우 테이블을 구성 및 관리한다.<br>라우터별 제어 방식과는 다르게, CA는 서로 직접 상호작용하지 않으며, 포워딩 테이블을 계산하는 데도 적극적으로 참여하지 않는다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.1-개요\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.1 개요/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Mon, 17 Jun 2024 20:52:43 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/213144150-84a7748e-3547-47c6-86d5-c454686cb6e6.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/213144150-84a7748e-3547-47c6-86d5-c454686cb6e6.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.2 라우팅 알고리즘]]></title><description><![CDATA[ 
 <br><br>
💡 라우팅 알고리즘(routing algorithm)의 목표 : 송신자부터 수신자까지 라우터의 네트워크를 통과하는 좋은 경로(루트)를 결정하는 것
<br>일반적으로 ‘좋은’ 경로란 최소 비용 경로(least-cost path)를 말한다.<br>그러나 현실적으로는 네트워크 정책과 같은 실제 문제가 고려된다.<br>
(e.g., Y 기관에 속해 있는 라우터 x는 Z 기관이 소유한 네트워크가 보낸 패킷을 전달해서는 안 됨)<br><br>라우팅 문제를 나타내는 데는 그래프가 사용된다.<br>
<img src="https://user-images.githubusercontent.com/86337233/213212557-7f4721cc-104d-4102-9c13-b4d45e4ae79d.png" alt="그래프" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br>그래프(graph), G(N, E)<br>
<br>
N

<br>노드(node)의 집합
<br>네트워크 계층 라우팅 상황에서 그래프상의 노드는 패킷 전달 결정이 이루어지는 지점인 라우터를 나타낸다.


<br>
E

<br>에지(edge)의 집합
<br>네트워크 계층 라우팅 상황에서 그래프상의 에지는 라우터들 간의 물리 링크를 나타낸다.
<br>에지는 그 비용을 나타내는 값을 가진다.<br>
(일반적으로 해당 링크의 물리적인 거리, 링크 속도, 링크와 관련된 금전 비용 등을 반영)
<br>집합 E에 포함된 어떤 에지 (x, y)에 대해 c(x, y)는 노드 x와 y 간의 비용을 의미한다.
<br>에지 (x, y)가 집합 E에 속하면, 노드 y는 노드 x의 이웃(neighbor)이라고 한다.


<br>
하나의 에지는 집합 N에 속하는 한 쌍의 노드로 표시된다.

<br>그래프 G(N, E)에서의 경로(path)는 노드의 연속(x1, x2, x3, …, xp)이고,<br>
노드 쌍 (x1, x2), (x2, x3), … , (xp-1, xp)는 집합 E에 속한 에지들이다.<br>경로 (x1, x2, x3, … , xp)의 비용은 경로상 모든 에지 비용의 단순 합이다.<br>
c(x1, x2) + c(x2, x3) + … + c(xp-1, xp)<br><br>라우팅 알고리즘을 분류하는 일반적인 방법 한 가지는 알고리즘이 중앙 집중형인지 분산형인지다.<br><br>
💡 네트워크 전체에 대한 완전한 정보를 가지고 출발지와 목적지 사이의 최소 비용 경로를 계산한다.
<br>계산 자체는 한 장소에서 수행되거나 모든 라우터 각각의 라우팅 모듈로 복사될 수 있다.<br>전체 상태 정보를 갖는 알고리즘을 링크 상태(link-state, LS) 알고리즘이라고 하는데,<br>
이는 이 알고리즘이 네트워크 내 각 링크의 비용을 알고 있어야 하기 때문이다.<br><br>최소 비용 경로의 계산이 라우터들에 의해 반복적이고 분산된 방식으로 수행된다.<br>
💡 각 노드는 자신에게 직접 연결된 링크에 대한 비용 정보만을 가지고 시작한다.
<br>이후 반복된 계산과 이웃 노드와의 정보 교환을 통해 노드는 점차적으로 목적지 또는 목적지 집합까지의 최소 비용 경로를 계산한다.<br>분산 라우팅 알고리즘은 거리 벡터(distance-vector, DV) 알고리즘이라고도 하는데,<br>
이는 각 노드가 네트워크 내 다른 모든 노드까지 비용(거리)의 추정값을 벡터 형태로 유지하기 때문이다.<br><br>라우팅 알고리즘을 분류하는 일반적인 두 번째 방식은 정적 알고리즘과 동적 알고리즘으로 분류하는 것이다.<br><br>사람이 직접 링크 비용을 수정하는 경우와 같은 종종 사람이 개입하는 상황 때문에 정적 라우팅 알고리즘에서 경로는 아주 느리게 변한다.<br><br>네트워크 트래픽 부하(load)나 토폴로지 변화에 따라 라우팅 경로를 바꾼다.<br>동적 알고리즘은 주기적으로, 혹은 토폴로지나 링크 비용의 변경에 직접적으로 응답하는 방식으로 수행된다.<br>
<br>장점 : 네트워크 변화에 빠르게 대응한다.
<br>단점 : 경로의 루프(loop)나 경로 진동(oscillation) 같은 문제에 취약하다.
<br>[참고] 토폴로지(topology, 망구성방식) : 컴퓨터 네트워크의 요소들(링크, 노드 등)을 물리적으로 연결해 놓은 것, 또는 그 연결 방식<br><br>라우팅 알고리즘을 분류하는 세 번재 방식은 라우팅 알고리즘이 부하에 민감한지 아닌지에 따른다.<br><br>링크 비용은 해당 링크의 현재 혼잡 수준을 나타내기 위해 동적으로 변한다.<br>현재 혼잡한 링크에 높은 비용을 부과한다면, 라우팅 알고리즘은 혼잡한 링크를 우회하는 경로를 택하는 경향을 보일 것이다.<br>초기 ARPAnet 라우팅 알고리즘이 부하에 민감해서 많은 어려움이 있었다.<br><br>오늘날 인터넷 라우팅 알고리즘(RIP, OSPF, BGP 등)은 링크 비용이 현재(또는 가장 최근)의 혼잡을 반영하지 않기 때문에 부하에 민감하지 않다.<br><br>
링크 상태 알고리즘에서는 네트워크 토폴로지와 모든 링크 비용이 알려져 있어서 링크 상태 알고리즘의 입력값으로 사용될 수 있다.
<br>이것은 각 노드가 자신과 직접 연결된 링크의 식별자와 비용 정보를 담은 링크 상태 패킷을<br>
네트워크상의 다른 모든 노드로 브로드캐스트하게 함으로써 가능하며,<br>이는 종종 인터넷 OSPF 라우팅 프로토콜 같은 링크 상태 브로드캐스트(link-state broadcast) 알고리즘에 의해 수행된다.<br><br>
💡 다익스트라 알고리즘은 하나의 노드(출발지, u라고 지칭)에서 네트워크 내 다른 모든 노드로의 최소 비용 경로를 계산한다.
<br>알고리즘의 k번째 반복 이후에는 k개의 목적지 노드에 대해 최소 비용 경로가 알려지며,<br>
이들은 모든 목적지 노드로의 최소 비용 경로 중에서 가장 낮은 비용을 갖는 k개의 경로다.<br>기호 정의<br>
<br>D(v) : 알고리즘의 현재 반복 시점에서 출발지 노드부터 목적지 v까지의 최소 비용 경로의 비용
<br>p(v) : 출발지에서 v까지의 현재 최소 비용 경로에서 v의 직전 노드
<br>N’ : 노드의 집합
<br>출발지에서 v까지의 최소 비용 경로가 명확히 알려져 있다면, v는 N’에 포함된다.<br><br>중앙 집중형 라우팅 알고리즘은 2단계로 구성된다.<br>
<br>초기화 단계(Initialization)
<br>반복 부분(Loop) : 수행 횟수는 네트워크의 노드 수와 같다.
<br><img src="https://user-images.githubusercontent.com/86337233/213212565-e58f1ba9-0003-4caf-8a94-dd836d0a7dad.png" alt="링크 상태 알고리즘" referrerpolicy="no-referrer" style="width: 680px; max-width: 100%;"><br>아래 그래프의 네트워크에서 링크 상태 알고리즘을 수행한 결과는 다음과 같다.<br>
<img src="https://user-images.githubusercontent.com/86337233/213212557-7f4721cc-104d-4102-9c13-b4d45e4ae79d.png" alt="그래프" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br>
<img src="https://user-images.githubusercontent.com/86337233/213212575-f2a19606-b0c5-4b5b-b5cf-d7dc806ede6d.png" alt="링크 상태 알고리즘 수행 결과" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>링크 상태 알고리즘이 종료된 후에 우리는 각 노드에 대해 출발지 노드로부터의 최소 비용 경로상의 직전 노드를 알게 된다.<br>노드 u의 포워딩 테이블은 각 목적지에 대해 / 노드 u에서 그 목적지까지의 최소 비용 경로상의 다음 홉 노드 정보를 저장하여 구성한다.<br>아래 그림은 최소 비용 경로의 결과와 노드 u의 포워딩 테이블을 보여준다.<br><img src="https://user-images.githubusercontent.com/86337233/213212579-440664b4-0be5-4e54-bca0-023029c6f39c.png" alt="링크 상태 알고리즘 포워딩 테이블" referrerpolicy="no-referrer" style="width: 550px; max-width: 100%;"><br><br>n개의 노드(출발지 노드 제외)가 있다면 출발지에서 모든 목적지까지 최단 비용 경로를 찾기 위해 최악의 경우 얼마나 많은 계산이 필요한가?<br>첫 번째 반복에서 최소 비용이 이미 계산된 노드의 집합 N’에 포함되지 않은 노드 w를 결정하기 위해 모든 n개의 노드를 검사해야 하며,<br>
두 번째 반복에서는 n-1개의 노드를, 세 번째 반복에서는 n-1개의 노드를 검사해야 한다.<br>따라서 찾아야 하는 노드의 총수는 n(n+1)/2가 되며,<br>
링크 상태 알고리즘은 최악의 경우 O(n^2)의 복잡성을 갖는다.<br><br>진동 문제는 링크 상태 알고리즘뿐만 아니라 혼잡이나 지연 시간을 기반으로 링크 비용을 산출하는 모든 알고리즘에서 발생할 수 있다.<br>아래의 과정을 통해 진동 문제에 대하여 살펴보자.<br>초기의 라우팅은 다음과 같다.<br>링크의 비용은 통과하는 트래픽 양에 따른다.<br><img src="https://user-images.githubusercontent.com/86337233/213212582-bad1ee34-70c9-4ec3-babd-1240b362fd9d.png" alt="최초 라우팅" referrerpolicy="no-referrer" style="width: 300px; max-width: 100%;"><br>링크 상태 알고리즘이 다시 수행되면 노드 y는 w로 가는 시계 방향의 경로 비용이 1인 반면,<br>
지금까지 사용해왔던 반시계 방향으로의 경로 비용은 1+e임을 알게 된다.<br>따라서 w로 가는 y의 최소 비용 경로는 시계 방향이며,<br>
x도 마찬가지로 w로 가는 시계 방향 경로를 새로운 최소 비용 경로로 결정한다.<br>
<img src="https://user-images.githubusercontent.com/86337233/213212586-a123652a-3701-44a0-b822-1801901397d4.png" alt="시계 방향" referrerpolicy="no-referrer" style="width: 300px; max-width: 100%;"><br>링크 상태 알고리즘이 다시 한번 수행되면<br>
노드 x, y, z 모두 w로 가는 반시계 방향의 경로 비용이 0임을 알게 되어 모든 트래픽을 반시계 방향 경로로 보낸다.<br><img src="https://user-images.githubusercontent.com/86337233/213212593-8b7fcd6f-ee6b-4118-ab94-e1f995c93b22.png" alt="반시계 방향" referrerpolicy="no-referrer" style="width: 300px; max-width: 100%;"><br>다음번 링크 상태 알고리즘 수행 시에는 x, y, z 모두 시계 방향으로 트래픽을 전송한다.<br><img src="https://user-images.githubusercontent.com/86337233/213212599-fb4216f6-277b-491e-ac4c-455f0a6cf810.png" alt="w로의 더 나은 경로, 시계 방향" referrerpolicy="no-referrer" style="width: 300px; max-width: 100%;"><br>이러한 진동 문제를 방지하기 위한 방법들 중 하나는 모든 라우터가 동시에 링크 상태 알고리즘을 실행하지 못하도록 하는 것이다.<br>라우터들이 동일한 주기 간격으로 링크 상태 알고리즘을 수행한다 하더라도<br>
각 노드에서의 알고리즘의 실행 시각은 같지 않을 것이기 때문에 합리적인 방법이라고 생각된다.<br>하지만 연구자들은 라우터들이 알고리즘을 처음에는 각기 다른 시작 시각에, 그러나 같은 주기를 갖도록 해서 실행하더라도<br>
점진적으로 결국엔 서로 동기화된다는 것을 발견하였다.<br>이러한 자기 동기화는 각 노드가 링크 상태 정보를 송신하는 시각을 임의로 결정하게 함으로써 회피할 수 있다.<br><br>오늘날 실제로 사용되는 알고리즘은 거리 벡터(distance-vector, DV) 라우팅 알고리즘이다.<br>링크 상태 알고리즘이 네트워크 전체 정보를 이용하는 알고리즘인 반면,<br>
거리 벡터 알고리즘은 반복적이고 비동기적이며 분산적이다.<br>
<br>분산적(distributed) : 각 노드는 하나 이상의 직접 연결된 이웃으로부터 정보를 받고, 계산을 수행하며, 계산된 결과를 다시 이웃들에게 배포한다.
<br>반복적(iterative) : 이웃끼리 더 이상 정보를 교환하지 않을 때까지 프로세스가 지속된다.
<br>비동기적(asynchronous) : 모든 노드가 서로 정확히 맞물려 동작할 필요가 없다.
<br><br>노드 x부터 y까지 최소 비용 경로의 비용은 다음과 같이 나타낼 수 있다.<br><img src="https://user-images.githubusercontent.com/86337233/213212603-bad1ae1e-7838-4623-b3dc-226725c24f1a.png" alt="벨만-포드 식" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
<br>min.v는 x의 모든 이웃에 적용된다.
<br>x에서 v로 이동한 후, v에서 y까지의 최소 비용 경로를 택한다면, 경로 비용은 c(x, v) + d.v(y)일 것이다.
<br>반드시 하나의 이웃 v로 가는 것부터 시작해야 하므로,
<br>x에서 y까지의 최소 비용은 모든 이웃 노드 v에 대해 계산된 c(x, v) + d.v(y) 중 최솟값이 된다.
<br>벨만-포드 식의 해답은 각 노드 포워딩 테이블의 엔트리를 제공한다.<br>
<br>위의 식을 최소로 만드는 이웃 노드를 v*라고 해보자.
<br>만약 노드 x가 노드 y에게 최소 비용 경로로 패킷을 보내기 원한다면, 노드 x는 패킷을 노드 v*로 전달해야 한다.
<br>그러므로 노드 x의 포워딩 테이블에는 최종 목적지 y로 가기 위한 다음 홉 라우터로 v*가 지정되어 있어야 한다.<br><br>따라서 거리 벡터 라우팅 알고리즘의 기본 아이디어는 다음과 같다.<br>
출발지 노드를 x라고 가정하면, 노드 x는 자신으로부터 집합 N에 속한 다른 모든 노드 y까지의 최소 비용 경로의 비용 D.x(y)를 추정한다.
<br>D.x을 노드 x에서부터 N에 속한 모든 다른 노드 y까지의 비용 추정값의 벡터라고 하자.<br><img src="https://user-images.githubusercontent.com/86337233/213212608-4d28a058-01a6-40a4-a863-04ad2c5f4b5b.png" alt="Dx" referrerpolicy="no-referrer" style="width: 320px; max-width: 100%;"><br>DV 알고리즘으로 각 노드 x는 다음과 같은 라우팅 정보를 유지한다.<br>
<br>각 이웃 노드 v 중에서 x에 직접 접속된 이웃 노드까지의 비용 c(x, v)
<br>노드 x의 거리 벡터, 즉 x로부터 N에 있는 모든 목적지 y로의 비용 예측값을 포함하는 벡터 D.x
<br>이웃 노드들의 거리 벡터들, 즉 v가 x의 이웃이라고 하면 D.v = [D.v(y): y in N]
<br>
분산적이고 비동기적으로 동작하는 알고리즘에서는 때때로 각 노드가 자신의 거리 벡터를 이웃들에게 보낸다.
<br>노드 x가 이웃 w에게서 새로운 거리 벡터를 수신하면,<br>
x는 w의 거리 벡터를 저장하고 벨만-포드 식을 사용하여 다음처럼 자신의 거리 벡터를 갱신한다.<br>(N에 속하는 각 노드 y에 대해)<br>
<img src="https://user-images.githubusercontent.com/86337233/213212611-7301f712-e082-4894-a2de-2af2dbcadead.png" alt="벨만-포드 식 적용" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>만약 이 갱신으로 인해 노드 x의 거리 벡터가 변경된다면<br>
<br>노드 x는 이 수정된 거리 벡터를 자신의 이웃들에게 보내고
<br>그에 따라 이웃들도 자신의 거리 벡터를 갱신한다.
<br>
모든 노드가 자신의 거리 벡터를 비동기적으로 교환하는 동작을 계속하다 보면,<br>
비용 추정값 D.x(y)는 노드 x에서 노드 y까지의 실제 최소 비용 경로의 비용인 d.x(y)로 수렴하게 된다.
<br><br>각 노드 x에서,<br>
<img src="https://user-images.githubusercontent.com/86337233/213212614-4c524d17-1dbb-4518-b7b0-7014fa6f4413.png" alt="거리 벡터 알고리즘" referrerpolicy="no-referrer" style="width: 680px; max-width: 100%;"><br>특정 목적지 y에 대한 자신의 포워딩 테이블을 갱신하기 위해 노드 x가 알아야 하는 것은 y로의 최단 경로상의 다음 홉 라우터인 이웃 노드 v*(y)다.<br>다음 홉 라우터 v(y)는 위 DV 알고리즘의 14번째 줄에서 최솟값을 갖게 하는 이웃 v이기에,<br>
13~14번째 줄에서 각 목적지 y에 대해 노드 x는 v(y)를 결정하고 목적지 y에 대해 포워딩 테이블도 갱신한다.<br>
💡 DV 알고리즘에서 하나의 노드가 갖는 정보는 단지 자신에게 직접 연결된 이웃으로의 링크 비용과 그 이웃들로부터 수신하는 정보뿐이다.
<br>
<br>각 노드는 이웃으로부터의 갱신을 기다리고 (10~11번째 줄)
<br>업데이터를 수신하면 새로 거리 벡터를 계산하고 (14번째 줄)
<br>이 새로운 거리 벡터를 이웃들에게 배포한다. (16~17번째 줄)
<br>이 과정은 더 이상의 갱신 메시지가 없을 때까지 계속된다.<br>갱신 메시지가 더 이상 없으면 라우팅 테이블 계산도 더 이상 없고 알고리즘은 정지 상태가 된다.<br>
(10~11번째 줄 대기 명령을 수행)<br>이 알고리즘은 링크 비용이 변할 때까지 정지 상태로 있는다.<br>아래 그림은 세 노드로 이루어진 단순한 네트워크에서의 거리 벡터 알고리즘의 동작을 보여준다.<br>여기서는 모든 노드가 동기적 방식으로 동작하지만, 비동기적 방식으로도 알고리즘은 올바르게 동작한다.<br><img src="https://user-images.githubusercontent.com/86337233/213214084-e5a9f23c-f149-48b1-ad74-a19155d6dcbf.png" alt="거리 벡터 알고리즘 동작" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>거리 벡터 알고리즘을 수행하는 노드가<br>
<br>자신과 이웃 사이 링크의 비용이 변경된 것을 알게 되면
<br>자신의 거리 벡터를 갱신한 후
<br>최소 비용 경로의 비용에 변화가 있는 경우에는 이웃에게 새로운 거리 벡터를 보낸다.
<br>이때 최소 비용 경로의 비용이 감소한 상황과 증가한 상황 두 가지를 전부 살펴보자.<br><br>아래는 y에서 x로의 링크 비용이 4에서 1로 변한 상황을 나타낸 것이다.<br><img src="https://user-images.githubusercontent.com/86337233/213214090-baa35d20-b8c1-495e-b82d-c877001f6737.png" alt="비용 감소" referrerpolicy="no-referrer" style="width: 320px; max-width: 100%;"><br>이 상황에서의 DV 알고리즘은 다음과 같은 일련의 사건을 발생시킨다.<br>
<br>
시각 t0 : y가 링크 비용의 변화를 감지하고, 자신의 거리 벡터를 갱신한 후 이 변경값을 이웃에게 알린다.

<br>
시각 t1 : z는 y로부터 갱신 정보를 받고 자신의 테이블을 갱신한다.

<br>z는 x까지의 새로운 최소 비용을 계산한다.
<br>이웃에게 자신의 새로운 거리 벡터를 전송한다.


<br>
시각 t2 : y는 z로부터 갱신 정보를 받고 자신의 테이블을 갱신한다.

<br>y의 최소 비용은 변화가 없으므로 y는 z에게 아무런 메시지를 보내지 않는다.
<br>이에 알고리즘은 정지 상태가 된다.


<br><br><br>따라서 거리 벡터 알고리즘은 정지 상태가 될 때까지 두 번만 반복하면 된다.<br><br><br><br>아래는 y에서 x로의 링크 비용이 4에서 60로 변한 상황을 나타낸 것이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213214092-9b56f797-4182-43fa-baff-98f56be140a8.png" alt="비용 증가" referrerpolicy="no-referrer" style="width: 320px; max-width: 100%;"><br><br>
<br><br>이 상황에서의 DV 알고리즘은 다음과 같은 일련의 사건을 발생시킨다.<br>
<br>
시각 t0 : y가 링크 비용 변화를 감지하고 노드 x까지 다음의 비용을 갖는 새로운 최소 비용 경로를 계산한다.
<br>
 <img src="https://user-images.githubusercontent.com/86337233/213214096-1af1855b-1116-49ac-8873-1943c7727dc5.png" alt="비용 증가 계산식" referrerpolicy="no-referrer" style="width: 930px; max-width: 100%;">

<br>이때 우리는 네트워크 전체를 한눈에 볼 수 있기 때문에 z를 경유하는 이 새로운 비용이 잘못되었다는 사실을 알 수 있지만,<br>
노드 y의 입장에서는 아니다.


<br>
시각 t1

<br>
x로 가기 위해 y는 z로 경로 설정을 하고, z는 y로 경로 설정을 하는 라우팅 루프(routing loop)가 발생한다.

t1에 x를 목적지로 하는 패킷이 y나 z에 도착하면 포워딩 테이블이 변할 때까지 이 두 노드 사이에서 왔다 갔다 순환할 것이다.


<br>
노드 y는 x까지의 새로운 최소 비용을 계산했으므로 z에게 새로운 거리 벡터를 알린다.



<br>
시각 t2 : z는 y로부터 갱신 정보를 받고 새로운 최소 비용을 계산한다.

<br>D.z(x) = min{50+0, 1+6} = 7
<br>x까지의 z의 최소 비용이 증가했으므로, 새로운 거리 벡터를 y에 알린다.


<br>
시각 t3 : y는 z로부터 새로운 거리 벡터를 수신하고 새로운 최소 비용을 계산한다.

<br>Dy(x) = min{60+0, 1+7} = 8
<br>x까지의 y의 최소 비용이 증가했으므로, 새로운 거리 벡터를 z에 알린다.


<br>
…

<br><br><br>이렇게 계속 반복되는 문제를 무한 계수 문제(count-to-infinity)라고 한다.<br><br><br><br>방금 설명한 특정한 라우팅 루프 시나리오는 포이즌 리버스(poisoned reverse)라는 방법을 통해 방지할 수 있다.<br><br><br>즉, 만약 z가 y를 통해 목적지 x로 가는 경로 설정을 했다면, z는 y에게 x까지의 거리가 무한대라고 알린다.<br>z는 y를 통과해서 x로 가는 동안은 이러한 거짓말을 계속한다.<br>이에 y는 z에서 x로 가는 경로가 없다고 믿으므로,<br>
z가 계속해서 y를 통해 x로 가는 경로를 사용하는 동안은 y는 z를 통해 x로 가는 경로를 시도하지 않을 것이다.<br><br><br>하지만 포이즌 리버스는 모든 무한 계수 문제를 해결할 수는 없다.<br>단순히 직접 이웃한 2개의 노드가 아닌, 3개 이상의 노드를 포함한 루프는 포이즌 리버스로는 감지할 수 없다.<br><br>
<br><br><br><br>LS와 DV 알고리즘은 경로를 계산할 때 서로 대비되는 방법을 취한다.<br><br><br><br>
<br>전체 정보를 필요로 한다.
<br>각 노드는 다른 모든 노드와 (브로드캐스트를 통해) 통신한다.
<br>오직 자신에게 직접 연결된 링크의 비용만 알린다.
<br><br><br><br>
<br>각 노드는 오직 직접 연결된 이웃과만 메시지를 교환한다.
<br>자신으로부터 네트워크 내 (자신이 알고 있는) 모든 노드로의 최소 비용 추정값을 이웃들에게 제공한다.
<br><br><br><br><br>
<br>각 노드는 네트워크 내 각 링크 비용을 알아야 하며, 이를 위해서는 O(|N| |E|)개의 메시지가 전송되어야 한다.
<br>링크 비용이 변할 때마다 새로운 링크 비용이 모든 노드에게 전달되어야 한다.
<br><br><br><br>
<br>매번 반복마다 직접 연결된 이웃끼리 메시지를 교환한다.
<br>알고리즘의 결과가 수렴하는 데 걸리는 시간은 많은 요소에 좌우된다.
<br>링크 비용이 변하고, 이 새로운 링크 비용이 이 링크에 연결된 어떤 노드의 최소 비용 경로에 변화를 준 경우에만<br>
DV 알고리즘은 수정된 링크 비용을 전파한다.
<br><br><br><br>라우터가 고장나거나 오동작하거나 파손된다면 어떤 일이 발생할까?<br><br><br><br>
<br>라우터는 연결된 링크에 대해 잘못된 비용 정보를 브로드캐스트할 수 있다.
<br>노드는 링크 상태 브로드캐스트를 통해 받은 패킷을 변질시키거나 폐기할 수 있다.
<br>그러나 하나의 링크 상태 노드는 자신의 포워딩 테이블만 계산하기 때문에<br>
링크 상태 알고리즘에서 경로 계산은 어느 정도 분산되어 수행된다.<br>따라서 링크 상태 알고리즘은 어느 정도의 견고성을 제공한다.<br><br><br><br>
<br>노드는 잘못된 최소 비용 경로를 일부 혹은 모든 목적지에 알릴 수 있다.
<br>각 반복마다 한 노드의 거리 벡터 계산이 이웃에게 전달되고 다음 반복에서 이웃의 이웃에게 간접적으로 전달된다.<br>따라서 거리 벡터 알고리즘을 사용하는 네트워크에서 한 노드의 잘못된 계산은 전체로 확산될 수 있다.<br><br><br>실제로 1997년에 작은 ISP에서 오작동한 라우터가 잘못된 라우팅 정보를 전국망의 백본 라우터에 제공한 적이 있었다.<br>이는 다른 라우터들이 오작동한 라우터에게 대규모 트래픽을 보내게 만들었고,<br>
인터넷의 상당 부분이 여러 시간 동안 단절되었다고 한다.<br><br><br><br><br><br>결국 어떤 알고리즘이 다른 알고리즘보다 명백히 낫다고 말할 수는 없으며,<br>
실제로 두 알고리즘 모두는 인터넷에서 사용되고 있다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.2-라우팅-알고리즘\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.2 라우팅 알고리즘/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 00:02:05 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/213212557-7f4721cc-104d-4102-9c13-b4d45e4ae79d.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/213212557-7f4721cc-104d-4102-9c13-b4d45e4ae79d.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.3 인터넷에서의 AS 내부 라우팅: OSPF]]></title><description><![CDATA[ 
 <br><br>네트워크를 동일한 라우팅 알고리즘을 수행하는 동종의 라우터 집합으로 간주하는 관점은 다음의 두 가지 문제점이 존재한다.<br>
<br>
확장
라우터의 수가 증가함에 따라 라우팅 정보의 통신, 계산, 저장에 필요한 오버헤드가 걷잡을 수 없이 증가한다.

<br>
관리 자율성
ISP는 일반적으로 자신의 네트워크를 원하는 대로 운용하거나(e.g., 어떠한 라우팅 알고리즘이라도 수행할 수 있도록),<br>
네트워크 내부 구성을 외부에 감추기를 원한다.

<br><br><br><br>위의 문제점들은 라우터들을 자율 시스템(autonomous system, AS)으로 조직화하여 해결할 수 있다.<br>
<br>각 AS는 동일한 관리 제어하에 있는 라우터의 그룹으로 구성된다.
<br>자율 시스템은 전 세계적으로 고유한 AS 번호(autonomous system number, ASN)으로 식별된다.
<br>같은 AS 안에 있는 라우터들은 동일한 라우팅 알고리즘을 사용하고 상대방에 대한 정보를 갖고 있다.
<br>자율 시스템 내부에서 동작하는 라우팅 알고리즘을 AS 내부 라우팅 프로토콜(intra-autonomous system routing protocol)이라고 한다.
<br><br>
<br><br><br>개방형 최단 경로 우선(open shortest path first, OSPF) 라우팅과 IS-IS(Intermediate System to Intermediate System)는<br>
인터넷에서 AS 내부 라우팅에 널리 사용된다.<br><br><br>OSPF는 링크 상태 정보를 플러딩(flooding)하고 다익스트라 최소 비용 경로 알고리즘을 사용하는 링크 상태 알고리즘이다.<br>
<br>
OSPF를 이용하여 각 라우터는 전체 AS에 대한 완벽한 토폴로지 지도(그래프)를 얻는다.

<br>
각 라우터는 자신을 루트 노드로 두고 모든 서브넷에 이르는 최단 경로 트리를 결정하기 위해 혼자서 다익스트라의 최단 경로 알고리즘을 수행한다.

<br>
OSPF를 사용하는 라우터는 자율 시스템 내의 다른 모든 라우터에게 라우팅 정보를 브로드캐스팅한다.

<br>링크 상태가 변경될 때마다
<br>링크 상태가 변경되지 않았더라도 정기적으로(최소한 30분마다 한 번씩)


<br>
OSPF 메시지에 포함된 상태 정보는 인터넷 프로토콜에 의해 전달되며, 상위 계층 프로토콜 번호로는 OSPF를 의미하는 89를 갖는다.

<br>따라서 OSPF 프로토콜은 신뢰할 수 있는 메시지 전송과 링크 상태의 브로드캐스트와 같은 기능을 스스로 구현해야 한다.
<br>또한 OSPF 프로토콜은 링크가 동작하고 있는지 검사하고,<br>
OSPF 라우터가 네트워크 전반의 링크 상태에 대한 이웃 라우터의 데이터베이스를 얻을 수 있도록 해야 한다.


<br><br><br><br>링크 상태 라우팅을 설명하면서 우리는 순서를 묵시적으로 아래와 같이 가정했다.<br>
<br>링크 가중치가 설정되고,
<br>OSPF 같은 라우팅 알고리즘이 수행되며,
<br>LS 알고리즘에 의해 계산된 라우팅 테이블의 내용에 따라 트래픽이 흐른다.
<br><br><br>이를 원인과 결과 방식으로 설명하면,<br>
<br>원인 : 링크 가중치가 주어지고
<br>결과 : 이에 따라 전체 비용을 최소화하는 라우팅 경로가 결정된다.
<br><br><br>실제로는 링크 가중치와 라우팅 경로 간의 원인과 결과 관계는 반대가 될 수도 있다.<br>네트워크 운영자가 어떤 트래픽 관리 목표를 충족시키는 라우팅 경로를 얻기 위해 링크 가중치를 설정할 수 있다.<br>즉, 트래픽 흐름에 대한 바람직한 경로가 알려져 있고, OSPF 라우팅 알고리즘이 이 경로대로 구성하게 되도록 OSPF 링크 가중치를 찾아야 한다.<br><br><br>따라서 관리자는 모든 링크 비용을 1로 설정함으로써 최소 홉 라우팅이 이루어지게 하거나,<br>
적은 대역폭을 가진 링크 사용을 억제하기 위해 링크 용량에 반비례하게 링크 가중치를 설정할 수 있다.<br><br><br><br><br>OSPF 라우터들 간의 정보 교환(e.g., 링크 상태 갱신)을 인증할 수 있으며,<br>
인증을 통해 신뢰할 수 있는 라우터들만이 AS 내부의 OSPF 프로토콜에 참여할 수 있다.<br>원래 라우터 간의 OSPF 패킷은 인증을 하지 않으므로 위조될 수 있다.<br><br><br>두 종류의 인증<br>
<br>단순 인증 : 동일한 패스워드가 각 라우터에 설정되며, 라우터가 OSPF 패킷을 보낼 때 패스워드를 평문 그대로 포함하기 때문에 안전하지 않다.
<br>MD5 인증 : 모든 라우터에 설정된 공유 비밀키를 기반으로 한다. (8장 내용)
<br><br><br><br>하나의 목적지에 대해 동일한 비용을 가진 여러 개의 경로가 존재할 때 OSPF는 여러 개의 경로를 사용할 수 있도록 한다.<br>즉, 비용이 동일한 여러 개의 경로가 있을 때 모든 트래픽을 전달하기 위한 단 하나의 경로를 선택할 필요가 없다.<br><br><br><br>MOSPF(multicast OSPF)는 멀티캐스트 라우팅 기능을 제공하기 위해 OSPF를 단순 확장했다.<br>
<br>기존의 OSPF 링크 데이터베이스를 사용
<br>OSPF 링크 상태 브로드캐스트 메커니즘에 새로운 형태의 링크 상태 알림을 추가
<br><br><br>[참고]<br>
<br>MAC 주소 : 네트워크 상에서 서로를 구분하기 위해 디바이스마다 할당된 물리적 주소
<br>유니캐스트(Unicast) : 정보를 전송하기 위한 프레임에 자신의 MAC 주소와 목적지의 MAC 주소를 첨부하여 전송하는 방식  (일대일 통신)
<br>브로드캐스트(Broadcast) : 로컬 네트워크에 연결되어 있는 모든 시스템에게 프레임을 보내는 방식<br>
(송신 노드 하나가 네트워크에 연결된 수신 가능한 모든 노드에 데이터를 전송)
<br>멀티캐스트(Multicast) : 네트워크에 연결되어 있는 시스템 중 특정 그룹을 지정해서 해당 그룹원에게만 한 번에 정보를 전송하는 방식<br>
(라우터가 멀티캐스트를 지원해야만 사용 가능)
<br><br><br><br>OSPF의 자율 시스템(AS)는 계층적인 영역(area)으로 구성될 수 있다.<br>
<br>각 영역은 자신의 OSPF 링크 상태 라우팅 알고리즘을 수행한다.
<br>한 역역 내의 라우터는 같은 영역 내의 라우터들에게만 링크 상태를 브로드캐스트한다.
<br>각 영역 내에서 하나 혹은 그 이상의 영역 경계 라우터(area border router)가 영역 외부로의 패킷 라우팅을 책임진다.
<br>백본 영역의 주요 역할은 AS 내 영역 간의 트래픽을 라우팅하는 것이다.
<br><br><br>AS 내 영역 간 라우팅을 위해서는,<br>
<br>영역 경계 라우터로 패킷을 라우팅한다. (영역 내 라우팅)
<br>백본을 통과하여 목적지 영역의 영역 경계 라우터로 라우팅한다.
<br>그 후 최종 목적지로 라우팅한다.
]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.3-인터넷에서의-as-내부-라우팅_-ospf\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.3 인터넷에서의 AS 내부 라우팅_ OSPF/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 00:41:40 GMT</pubDate></item><item><title><![CDATA[5.4 인터넷 서비스 제공업자(ISP) 간의 라우팅: BGP]]></title><description><![CDATA[ 
 <br><br>패킷이 여러 AS를 통과하도록 라우팅할 때,<br>
(e.g., 한국에 있는 스마트폰이 실리콘 밸리에 있는 데이터 센터로 전송을 할 경우)<br>
자율 시스템 간 라우팅 프로토콜(inter-autonomous system routing protocol)이 필요하다.<br><br><br>통신하는 AS들은 같은 AS 간 라우팅 프로토콜을 수행해야만 한다.<br>실제로 인터넷의 모든 AS는 경계 게이트웨이 프로토콜(Border GateWay Protocol, BGP)을 사용하며,<br>
이는 거리 벡터 라우팅과 같은 줄기에서 나왔다고 볼 수 있는 분산형 비동기식 프로토콜이다.<br><br>
<br><br><br>같은 AS 내에 있는 목적지에 대해서는 라우터의 포워딩 테이블 엔트리들이 해당 AS의 AS 내부 라우팅 프로토콜에 의해 결정된다.<br><br><br>하지만 목적지가 AS 외부에 있는 경우, BGP가 필요하다.<br>BGP에서는 패킷이 CIDR(Classless Inter-Domain Routing) 형식으로 표현된, 주소의 앞쪽 프리픽스(prefix)를 향해 전달된다.<br>각 프리픽스는 서브넷이나 서브넷의 집합을 나타낸다. (e.g., 139.16.68/22)<br><br><br>라우터의 포워딩 테이블은 (x, I) 같은 형식의 엔트리들을 갖게 된다<br>
<br>x : 주소 프리픽스 (e.g., 139.16.68/22)
<br>I : 라우터 인터페이스의 인터페이스 번호
<br><br><br><br><br><br>AS 간 라우팅 프로토콜로서 BGP는 각 라우터에게 다음과 같은 수단을 제공한다.<br>
<br>
이웃 AS를 통해 도달 가능한 서브넷 프리픽스 정보를 얻는다.

<br>특히 각 서브넷이 자신의 존재를 인터넷 전체에 알릴 수 있도록 한다.


<br>
서브넷 주소 프리픽스로의 가장 좋은 경로를 결정한다.

<br>라우터는 특정한 주소 프리픽스를 향한 2개 이상의 경로를 알 수도 있다.
<br>가장 좋은 경로를 결정하기 위해 라우터는 BGP의 경로 결정 프로시저를 수행한다.


<br><br>
<br><br><br>아래의 단순한 네트워크는 3개의 자율 시스템 AS1, AS2, AS3를 가지며,<br>
AS3는 주소 프리픽스가 x인 서브넷을 포함한다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213658057-4bb81f7c-590e-4f60-ac3d-2e2bca19d361.png" alt="3개의 AS" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br>
<br><br>각 AS에서 각각의 라우터들은 게이트웨이 라우터(gateway router) 또는 내부 라우터(internal router)다.<br><br><br><br>
<br>AS의 경계에 있는 라우터
<br>다른 AS들에 있는 하나 또는 여러 개의 라우터와 직접 연결된다.
<br>e.g., AS1의 라우터 1c
<br><br><br><br>
<br>자신의 AS 내에 있는 호스트 및 라우터와만 연결된다.
<br>e.g., AS1의 라우터 1a, 1b, 1d
<br><br><br><br><br><br>자율 시스템은 서로 메시지를 보내지 않고 라우터가 보낸다.<br><br><br><br>
<br>BGP에서 라우터의 쌍들은 포트 번호가 179이고 반영구적인 TCP 연결을 통해 라우팅 정보를 교환한다.
<br>이 TCP 연결을 통해 모든 BGP 메시지가 전송된다.
<br><br><br><br>
<br>2개의 AS를 연결하는 BGP 연결
<br><br><br><br>
<br>같은 AS 내의 라우터를 연결하는 BGP 연결
<br><br><br>보통 각기 다른 AS에 속하는 게이트웨이 라우터들을 직접 연결하는 링크에는 eBGP 연결이 존재한다.<br>각 AS 내부 라우터 간에는 iBGP 연결도 존재하며,<br>
아래 그림은 한 AS 내 모든 라우터의 쌍 각각에 대해 하나씩의 BGP 연결을 두는 일반적인 설정 모습을 보인다.<br>
iBGP 연결은 물리적인 링크와 항상 일치하지는 않는다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213658044-5da300ad-148d-4477-80f7-4833cd79d1eb.png" alt="eBGP, iBGP" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br><br><br><br><br>위 예시에서 프리픽스 x에 대한 도달 가능성 정보를 AS1과 AS2의 모든 라우터에게 알리는 작업을 생각해보자.<br><br><br>아래의 과정이 완료되면 AS1과 AS2의 각 라우터들은 x의 존재와 x로 향하는 AS 경로를 알게 된다.<br>
<br>
먼저 게이트웨이 라우터 3a는 게이트웨이 라우터 2c에게 ‘AS3 x’라는 eBGP 메시지를 보낸다.<br>
(’x가 존재하고 AS3 내에 있다’는 의미)

<br>
게이트웨이 라우터 2c는 iBGP 메시지 ‘AS3 x’를 게이트웨이 라우터 2a를 포함한 AS2 내부의 모든 라우터에게 전송한다.

<br>
게이트웨이 라우터 2a는 eBGP 메시지 ‘AS2 AS3 x’를 게이트웨이 라우터 1c에게 보낸다.<br>
(’x가 존재하고 x에 도달하기 위해서는 먼저 AS2를 통과하고 그 후 AS3으로 갈 수 있다’는 의미)

<br>
마지막으로, 게이트웨이 라우터 1c는 iBGP를 사용하여 AS1 내의 모든 라우터에게 메시지 ‘AS2 AS3 x’를 전달한다.

<br><br><br>실제 네트워크에서는 주어진 라우터에서 특정 목적지까지 다른 많은 경로가 존재할 수 있고, 심지어 각기 다른 일련의 AS들을 통과하기도 한다.<br>아래 그림은 라우터 1d에서 3d로 연결되는 물리적인 링크를 추가한 것이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213658063-f56d6a18-67ac-40c4-9ed4-c0e025822fc5.png" alt="링크 추가" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br><br>이 경우에 AS1에서 x로는 2개의 경로가 존재한다.<br>
<br>라우터 1c를 통과하는 경로 ‘AS2 AS3 x’
<br>라우터 1d를 통과하는 새로운 경로 ‘AS3 x’
<br><br>
<br><br><br>
주어진 라우터에서 목적지 서브넷까지는 많은 경로가 있을 수 있는데,<br>
이런 경로들 중에서 라우터는 어떻게 선택을 할까? 그리고 어떻게 그에 따라 포워딩 테이블을 설정할까?
<br><br><br><br>라우터가 BGP 연결을 통해 주소 프리픽스를 알릴 때 몇몇 BGP 속성(attribute)을 함께 포함한다.<br>BGP의 용어로는 프리픽스와 그것의 속성을 경로(route)라고 한다.<br><br><br><br>
<br>
알림 메시지가 통과하는 AS들의 리스트를 담는다.

<br>프리픽스가 어떤 AS에 전달되었을 때
<br>그 AS는 자신의 ASN을 AS-PATH 내 현재 리스트에 추가한다.


<br>
메시지의 루프를 감지하고 방지하기 위해 활용한다.

<br>어떤 라우터가 자신의 AS가 경로 리스트에 포함되어 있는 것을 발견하면
<br>그 알림 메시지를 버린다.


<br><br><br><br>
<br>AS-PATH가 시작되는 라우터 인터페이스의 IP 주소
<br><br><br>e.g.,<br><img src="https://user-images.githubusercontent.com/86337233/213658063-f56d6a18-67ac-40c4-9ed4-c0e025822fc5.png" alt="링크 추가" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br><br>AS1에서 AS2를 통과하여 x로 가는 ‘AS2 AS3 x’ 경로의 NEXT-HOP 속성은 라우터 2a의 왼쪽 인터페이스의 IP 주소다.<br>AS1에서 AS2를 우회하여 x로 가는 ‘AS3 x’ 경로의 NEXT-HOP 속성은 라우터 3d의 맨 왼쪽 인터페이스의 IP 주소다.<br><br><br>즉, AS1의 각 라우터는 프리픽스 x로 가는 2개의 BGP 경로를 알게 된다.<br>
라우터 2a의 맨 왼쪽 인터페이스의 IP 주소; AS2 AS3; x
<br>
라우터 3d의 맨 왼쪽 인터페이스의 IP 주소; AS3; x
<br><br><br>NEXT-HOP 속성은 AS1에 속하지 않는 라우터의 IP 주소이다.<br>그러나 이 IP 주소를 포함하는 서브넷이 AS1에 직접적으로 연결된다.<br><br><br><br>
💡 가능한 모든 경로 중, 경로 각각의 시작점인 NEXT-HOP 라우터까지의 경로 비용이 최소가 되는 경로를 선택한다.
<br><br><br>
<br>
여러 게이트웨이를 통해 서브넷 x에 도달할 수 있다는 사실을 AS 간 프로토콜로부터 알게 된다.

<br>
각 게이트웨이까지의 최소 비용 경로를 정하기 위해 AS 내부 프로토콜을 통해 얻은 라우팅 정보를 이용한다.

<br>
뜨거운 감자 라우팅: 가장 적은 비용의 게이트웨이를 선택한다.

<br>
포워딩 테이블로부터 최소 비용 게이트웨이로의 인터페이스 I를 결정한 후 포워딩 테이블에 (x, I)를 추가한다.

<br>
포워딩 테이블에 AS 외부의 목적지를 추가할 때<br>
AS 간 라우팅 프로토콜(BGP)과 AS 내부 라우팅 프로토콜(e.g., OSPF) 둘 다가 사용된다.
<br><br><br>e.g.,<br><img src="https://user-images.githubusercontent.com/86337233/213658063-f56d6a18-67ac-40c4-9ed4-c0e025822fc5.png" alt="링크 추가" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br><br>
<br>
라우터 1b는 주소가 x로 시작하는 서브넷으로 가는 2개의 BGP 경로를 안다.

<br>
NEXT-HOP 라우터 2a와 3d 각각에 대해 최소 비용을 가진 AS 내부 경로를 찾기 위해 AS 내부 라우팅 정보를 조사한다.

<br>
이들 최소 비용 경로 중에서도 가장 적은 비용을 가진 경로를 선택한다.
<br>
비용을 거쳐가야 하는 링크의 수로 정의하면,

<br>라우터 1b에서 라우터 2a까지의 최소 비용 : 2
<br>라우터 1b에서 라우터 3d까지의 최소 비용 : 3

따라서 라우터 2a가 선택된다.
<br>

<br>
라우터 1b는 자신의 (AS 내부 알고리즘에 의해 설정된) 포워딩 테이블을 관찰하여 라우터 2a로 가기 위한 인터페이스 I를 찾아내고,<br>
엔트리 (x, I)를 자신의 포워딩 테이블에 추가한다.

<br><br><br><br><br><br>
💡 기본 아이디어<br>
라우터가 목적지까지의 경로 중 자신의 AS 바깥에 있는 부분에 대한 비용은 신경 쓰지 않고<br>
최대한 신속하게(가능한 한 최소의 비용으로) 패킷을 자신의 AS 밖으로 내보내는 것이다.
<br><br><br>즉, 뜨거운 감자 라우팅은 오로지 자신의 경로 중에서 자기 AS 내부 비용만 줄이려는 이기적인 알고리즘이다.<br>이를 사용하면 한 AS 내 2개의 라우터가 동일한 목적지 주소에 대해 각기 다른 AS 경로를 선택할 수도 있다.<br><br><br>e.g.,<br>
위의 예시에서 라우터 1b는 AS2를 통해 서브넷 x로 패킷을 보냈지만, 라우터 1d는 바로 AS3으로 보내 서브넷 x에 도달한다.<br><br><br><br>실제로 BGP는 뜨거운 감자 라우팅을 포함하는 더 복잡한 알고리즘을 사용한다.<br><br><br>목적지 주소의 프리픽스가 주어지면, 지금까지 라우터가 알아낸 해당 목적지까지의 모든 경로가 BGP의 경로 선택 알고리즘에 입력으로 주어진다.<br>
💡 하나의 목적지에 대해 2개 이상의 경로가 존재한다면 BGP는 하나의 경로가 남을 때까지 다음의 제거 규칙을 계속 수행한다.
<br><br><br>여기서 뜨거운 감자 라우팅에서 추가된 것은 속성 중의 하나로서 지역 선호도(local preference)가 경로에 할당되었다는 것이다.<br>한 경로의 지역 선호도는 라우터에 의해 설정되었거나 같은 AS 내부의 다른 라우터로부터 학습된 것이다.<br><br><br>
<br>
최고 지역 선호 값을 가진 경로가 선택된다.

<br>
최고 지역 선호 값을 가진 경로가 여러 개 있다면 이들 중에서 최단 AS-PATH를 가진 경로가 선택된다.

<br>만약 이 규칙이 경로 선택을 위한 유일한 규칙이라면, BGP는 경로 결정을 위해 DV 알고리즘을 사용할 것이다.
<br>여기서 거릿값으로는 AS 홉 수를 사용한다.


<br>
(같은 최고 지역 선호 값 및 같은 AS-PATH 길이를 가진) 모든 남은 경로들에 대해 뜨거운 감자 라우팅을 수행한다.

<br>
만일 아직도 하나보다 많은 경로가 남아 있다면 라우터는 BGP 식별자를 사용하여 경로를 선택한다.

<br><br><br>e.g.,<br>
<img src="https://user-images.githubusercontent.com/86337233/213658063-f56d6a18-67ac-40c4-9ed4-c0e025822fc5.png" alt="링크 추가" referrerpolicy="no-referrer" style="width: 650px; max-width: 100%;"><br><br>
<br><br>라우터 1b에서 서브넷 x로 가는 BGP 경로는 2가지가 존재했고(AS2를 통과 또는 우회),<br>
뜨거운 감자 라우팅이 바로 사용된다면 BGP는 AS2를 통과하는 경로로 패킷을 보내야 한다.<br>하지만 위의 경로 선택 알고리즘에서 규칙 2가 규칙 3보다 먼저 적용되므로, 더 짧은 AS-PATH를 가진 AS2 우회 경로가 선택된다.<br>따라서 이는 더이상 이기적인 알고리즘이 아니며, 결과적으로 종단 간 지연 시간이 줄어들 것이다.<br><br>
<br><br><br>BGP는 IP 애니캐스트(anycast) 서비스를 구현하는 데도 활용된다.<br>[참고] 애니캐스트(anycast) : 송신노드가 네트워크에 연결된 수신 가능한 노드 중에서 가장 가까운 한 노드에만 데이터를 전송한다. (IPv6 기반으로 작동)<br><br><br>많은 애플리케이션에서 (1) 같은 콘텐츠를 지리적으로 분산된 다른 많은 서버에 복제하고,<br>
(2) 각 사용자를 가장 가까운 서버의 콘텐츠로 접근하게 하려고 하는 경우를 생각해보자.<br>e.g., CDN은 비디오 등을 각기 다른 나라의 서버들에 복제해두며, DNS 시스템도 DNS 정보를 전 세계 DNS 서버에 복제할 수 있다.<br><br><br>이 경우, BGP의 경로 선택 알고리즘을 사용할 수 있다.<br><br><br>아래 그림은 사용자를 가장 가까운 CDN 서버로 보내기 위한 IP 애니캐스트의 활용을 보여주는 그림이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213658067-9be31c88-86d7-4752-86b0-548f34849ac4.png" alt="IP 애니캐스트" referrerpolicy="no-referrer" style="width: 670px; max-width: 100%;"><br><br>
<br><br>
<br>
IP 애니캐스트 설정 단계에서<br>
(1) CDN 사업자가 자신의 서버 여러 대에 동일한 IP 주소를 할당하고<br>
(2) 표준 BGP를 활용하여 이 주소를 서버 각각으로부터 알린다.
<br>

<br>라우터가 이 IP 주소에 대한 복수 개의 경로 알림 메시지를 받으면<br>
이를 동일한 물리적 위치로의 서로 다른 경로에 대한 정보를 제공받고 있는 것으로 생각한다.
<br>실제로는 서로 다른 물리적 위치로 가는 서로 다른 경로다.

 <br>

<br>
각 라우터는 라우팅 테이블을 설정하면서 BGP 경로 선택 알고리즘을 수행하여 해당 IP 주소로의 최고의 경로를 골라낸다.

<br><br><br>이러한 최초의 BGP 주소 알림 단계 이후에 CDN는 콘텐츠 배포를 할 수 있다.<br>
<br>
사용자가 비디오를 요청하면 CDN은 사용자가 어디에 위치해 있든 상관없이<br>
지리적으로 분산되어 있는 서버들이 공통적으로 사용하는 IP 주소를 사용자에게 돌려준다.

<br>
사용자가 그 주소로 요청을 보내면 인터넷 라우터는 그 요청 패킷을 BGP 경로 선택 알고리즘이 정의한 가장 ‘가까운’ 서버로 전달한다.

<br><br><br>실제로는 BGP 라우팅이 변경되면 하나의 TCP 연결에 속한 패킷들이 서로 다른 복제 웹 서버로 도착될 수 있기 때문에<br>
CDN은 위의 예처럼 IP 애니 캐스트를 사용하지 않으며,<br>DNS 시스템에서는 DNS 질의를 가장 가까운 루트 DNS 서버로 전달하기 위해 IP 애니캐스트를 광범위하게 사용된다.<br><br>
<br><br><br>라우터가 목적지까지의 경로를 선택하려고 할 때<br>
AS 라우팅 정책은 최단 AS-PATH나 뜨거운 감자 라우팅 등의 다른 모든 고려사항보다 우선시된다.<br><br><br>아래 그림에서는 A, B, C, W, X, Y 이렇게 6개의 자율 시스템(AS)이 서로 연결되어 있다.<br>
<br>
W, X, Y는 사용자 접속 ISP

<br>
A, B, C는 백본 제공자 네트워크

<br>트래픽을 서로에게 직접 보낸다.
<br>그들의 사용자 네트워크에 완전한 BGP 정보를 제공한다.


<br><img src="https://user-images.githubusercontent.com/86337233/213658073-8398ac03-a290-49be-8260-696b19d42110.png" alt="BGP 정책" referrerpolicy="no-referrer" style="width: 640px; max-width: 100%;"><br><br>
<br><br><br><br><br>
ISP 접속 네트워크로 들어오는 모든 트래픽은 그 네트워크를 목적지로 해야만 하고,<br>
ISP 접속 네트워크에서 나가는 트래픽은 그 네트워크 안에서 생성된 것이어야만 한다.
<br>
<br>W와 Y는 명백히 접속 ISP다.
<br>X는 각기 다른 두 제공자를 통해 네트워크의 다른 부분들과 연결되어 있으므로 다중 홈 접속 ISP(multi-homed access ISP)라고 한다.
<br><br><br>X도 W나 Y처럼 자신에게 들어오고 나가는 모든 트래픽의 목적지 또는 출발지여야 한다.<br>이 접속 네트워크의 동작을 구현하고 강제하며, X가 B와 C간 트래픽을 전달하는 것을 방지하는 것은<br>
BGP 경로의 알림 방식을 제어하는 것으로 가능하다.<br><br><br>즉, X는 이웃인 B와 C에게 자기 자신을 제외하고는 다른 어떤 목적지로도 경로가 없다고 알리는 것이다.<br>
(X가 Y까지 가는 XCY라는 경로를 알고 있더라도 이 경로를 B에게 알리지 않음)<br>따라서 B는 X가 Y로의 경로를 갖고 있음을 모르기 때문에 C 또는 Y로 가야 하는 트래픽을 X에게 절대 전달하지 않을 것이다.<br><br><br><br><br><br>서비스 제공자 네트워크 B는 (A로부터) A가 W까지의 경로 AW를 갖고 있음을 알게 되었다고 가정하자.<br>그러면 B는 경로 AW를 자신의 라우팅 정보 테이블에 기록하고,<br>
자신의 고객인 X가 B를 통해 W로 갈 수 있음을 알게 하기 위해 경로 BAW를 X에게 알리길 원할 것이다.<br><br><br>
하지만 B는 C에게도 BAW 경로를 알려야 할까?
<br>만약 그렇게 한다면, C는 해당 경로를 통해 W까지 트래픽을 보낼 수 있게 되는데,<br>
A, B, C가 모두 백본 제공자라면 B는 당연히 A와 C 사이의 트래픽을 전달하는 짐을 져서는 안 된다고 생각할 것이다.<br><br><br>현재는 백본 ISP들 사이의 경로를 결정하는 방법에 대한 공식적인 표준은 없지만,<br>상업적 ISP들이 따르는 대략적인 규칙은<br>
ISP 백본 네트워크를 통해 흐르는 트래픽은 해당 ISP의 고객 네트워크를 출발지로 하거나 목적지로 해야 한다는 것이다(또는 둘 다).<br>개별적인 상호 협정은 전통적으로 두 ISP 간에 협상되고 종종 기밀사항이다.<br><br>
<br><br><br>이는 AS 내부 라우팅과 AS 간 라우팅의 목적의 차이에 있다.<br><br><br><br>AS 간 라우팅은 정책 이슈가 지배한다.<br>특정 AS에서 시작된 트래픽이 다른 특정 AS를 통과할 수 없다는 것은 중요할 수 있으며,<br>
특정 AS가 다른 AS들 사이에서 어떤 트래픽을 전달할지 결장할 수 있기를 원하는 것 역시 당연하다.<br><br><br>반면, 하나의 AS 안에서는 모든 것이 동일한 관리 통제하에 있으므로 정책 문제는 경로 선택에 그리 중요하지 않다.<br><br><br><br>AS 간 라우팅에서 수많은 네트워크로, 또는 네트워크 간 경로 설정을 처리하기 위한 라우팅 알고리즘과 자료 구조의 능력은 매우 중요한 문제다.<br><br><br>반면, 한 AS 내에서는 확장성이 중요하지 않다.<br>하나의 ISP가 너무 커지면 이를 2개의 AS로 분리하고, 이 새로운 두 AS 사이에서 AS 간 라우팅을 수행할 수 있다.<br>
(OSPF가 하나의 AS를 여러 영역으로 나눔으로써 계층을 만드는 것을 허용함)<br><br><br><br>AS 간 라우팅은 정책 지향형이므로 사용하는 라우터의 품질(e.g., 성능)은 부수적인 관심사에 지나지 않는다.<br>단일 AS에서는 이러한 정책의 고려가 중요하지 않으므로, 경로의 성능 수준에 좀 더 초점을 두고 라우팅을 한다.<br><br>
<br><br><br>이 절은 본질적으로 BGP에 관한 내용은 아니지만,<br>
IP 주소체계, DNS, BGP를 포함하여 지금까지 살펴본 많은 프로토콜과 개념을 한데 모은다.<br><br><br>작은 회사를 설립했다고 가정하다.<br>회사에는 회사의 제품과 서비스를 설명하는 공개 웹 서버, 메일 서버, DNS 서버를 포함한 많은 서버가 있다.<br><br><br>
<br>먼저 지역 ISP와 계약하여 인터넷 연결을 해야 한다.

<br>회사는 게이트웨이 라우터를 갖게 될 텐데, 이는 지역 ISP의 라우터에 연결될 것이다.
<br>지역 ISP는 특정 범위의 IP 주소를 제공한다. (e.g., 256개의 주소를 포함하는 /24 주소 범위)
<br>물리적 연결과 IP 주소 범위를 가지면<br>
회사의 웹 서버, 메일 서버, DNS 서버, 게이트웨이 라우터와 다른 서버 및 네트워킹 장치들에 IP 주소(주소 범위에서)를 할당해야 한다.


<br><br><br>
<br>회사의 도메인 이름(e.g., xanadu.com)을 얻기 위해 인터넷 등록 기관과 계약을 해야 하며, DNS 시스템에 등록해야 한다.

<br>회사의 DNS 서버의 IP 주소를 등록 기관에 제공해야 한다.
<br>그러면 등록 기관은 .com 최상위 도메인 서버에 회사의 DNS 서버(도메인 이름과 해당 IP 주소)를 추가한다.


<br><br><br>
<br>
사람들이 회사의 웹 서버 IP 주소를 검색할 수 있도록<br>
회사의 DNS 서버에 웹 서버의 호스트 이름(e.g., www.xanadu.com)과 IP 주소의 사상 항목을 포함시켜야 한다.<br>
(메일 서버를 포함하여 회사의 공개적으로 사용 가능한 다른 서버들에 대해서도 유사한 항목들을 가져야 한다.)

<br>만일 앨리스라는 사람이 회사의 웹 서버를 방문하기를 원하는 경우,

<br>DNS 시스템은 회사의 DNS 서버에 접촉하여 웹 서버의 IP 주소를 알아낸 후
<br>이를 앨리스에게 제공한다.


<br>이제 앨리스는 회사의 웹 서버에 직접적으로 TCP 연결을 설립할 수 있다.


<br><br><br>
<br>전 세계의 외부인이 회사의 웹 서버에 접근할 수 있도록 하기 위해서는<br>
라우터가 회사 주소 범위에 해당하는 IP 주소 프리픽스 24비트(또는 다른 길이의 엔트리)의 존재를 알고 있어야 한다.

<br>예시 상황

<br>회사의 웹 서버의 IP 주소를 알아낸 앨리스가 그 IP 주소로 IP 데이터그램(e.g., TCP SYN 세그먼트)을 보낸다.
<br>이 데이터그램은 인터넷을 통해 라우팅되어 여러 자율 시스템의 라우터들을 연속적으로 거친 후 마침내 웹 서버에 도착하게 된다.

<br>라우터들 각각은 이 데이터 그램을 수신하면,<br>
어느 출력 포트로 내보내야 하는지 결정하기 위해 자신의 포워딩 테이블에서 해당 엔트리를 찾는다.




<br>이는 BGP를 통해서 이루어지게 된다.

<br>회사가 지역 ISP와 계약하고 주소 프리픽스(즉, 주소 범위)를 할당 받을 때,<br>
지역 ISP는 BGP를 사용하여 자신과 연결되어 있는 ISP들에게 회사의 주소 프리픽스를 알린다.
<br>연결된 ISP들 역시 BGP를 활용하여 이 알림 정보를 전파한다.




]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.4-인터넷-서비스-제공업자(isp)-간의-라우팅_-bgp\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.4 인터넷 서비스 제공업자(ISP) 간의 라우팅_ BGP/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 18 Jun 2024 01:05:15 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/213658057-4bb81f7c-590e-4f60-ac3d-2e2bca19d361.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/213658057-4bb81f7c-590e-4f60-ac3d-2e2bca19d361.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.5 소프트웨어 정의 네트워크(SDN) 제어 평면]]></title><description><![CDATA[ 
 <br><br>이 절에서는 4.4절에서 사용한 SDN 용어들을 다시 채택하여<br>
네트워크의 포워딩 장비들은 ‘패킷 스위치’ 또는 그냥 ‘스위치’라고 부를 것이다.<br>이 스위치들에서의 포워딩 결정은 네트워크 계층에서의 출발지/목적지 주소, 링크 계층에서의 출발지/목적지 주소 외에도<br>
트랜스포트 계층, 네트워크 계층, 링크 계층 패킷 헤더의 다른 많은 값에 기반하여 이루어진다.<br><br><br><br><br>
SDN으로 제어되는 스위치들에서의 패킷 전달은 트랜스포트 계층, 네트워크 계층, 또는 링크 계층 헤더의 어떤 값을 기반으로 하든 이루어질 수 있다.
<br>이는 앞 절에서 살펴본,<br>
IP 데이터그램의 포워딩이 온전히 데이터그램의 목적지 주소를 기반으로 이루어지는 전통적인 라우터 기반 포워딩과는 매우 대조적인 특성이다.<br><br><br>
💡 SDN에서는 모든 네트워크 스위치의 플로우 테이블 항목들을 계산하고 관리, 설치하는 일이 모두 SDN 제어 평면의 임무다.
<br><br><br><br><br>
<br>네트워크의 스위치들로 구성된다. (이들은 상대적으로 단순하지만 빠른 장치들)
<br>자신들의 플로우 테이블 내용을 기반으로 ‘매치 플러스 액션’을 수행한다.
<br><br><br><br>
<br>서버와 스위치들의 플로우 테이블을 결정, 관리하는 소프트웨어로 이루어진다.
<br><br><br><br>SDN 제어 평면은 소프트웨어로 구현되어 있으며, 네트워크 스위치로부터 멀리 떨어진 별도의 서버에서 수행된다.<br><br><br>아래의 그림에서 볼 수 있듯, 제어 평면은 2개의 구성요소로 이루어진다.<br>
<br>SDN 컨트롤러(또는 네트워크 운영체제)
<br>SDN 네트워크 제어 애플리케이션들의 집합
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213711658-f229ca35-e7a3-4818-b85f-ac2276e417e5.png" alt="SDN의 구성요소" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br>SDN 컨트롤러는<br>
<br>정확한 상태정보(e.g., 원격 링크와 스위치, 호스트들의 상태)를 유지하고,
<br>이 정보를 네트워크 제어 애플리케이션들에 제공하며,
<br>애플리케이션들이 하부 네트워크 장치들을 모니터하고 프로그램하고 제어까지 할 수 있도록 수단을 제공한다.
<br><br><br>그림에서의 컨트롤러는 단일 중앙 서버의 형태이지만, 실제로 컨트롤러는 논리적으로만 중앙 집중 형태다.<br>(일반적으로는 협업 능력과 확장성, 높은 이용성을 갖도록 몇 개의 서버에 구현)<br><br><br><br>제어 평면에서 수행 중인 네트워크 제어 애플리케이션을 통해 네트워크를 프로그램할 수 있다.<br>이 애플리케이션들은 SDN 컨트롤러가 제공하는 API를 이용하여 네트워크 장치들에 있는 데이터 평면을 명세하고 제어한다.<br>e.g.,<br>
라우팅 네트워크 제어 애플리케이션은 SDN 컨트롤러가 갖고 있는 노드 상태 및 링크 상태 정보에 기반한 다익스트라 알고리즘을 수행하여<br>
출발지와 목적지 사이의 종단 간 경로를 결정한다.<br><br>
<br><br><br>: SDN 컨트롤러와 SDN 네트워크 제어 애플리케이션<br><br><br><br>컨트롤러의 기능은 크게 3개의 계층으로 구성된다.<br>
<br>네트워크 제어 애플리케이션 계층과의 인터페이스
<br>네트워크 전역 상태 관리 계층
<br>통신 계층
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213711664-270bb750-0349-4109-aaca-cc97627caee1.png" alt="SDN 컨트롤러 구성요소" referrerpolicy="no-referrer" style="width: 580px; max-width: 100%;"><br><br>
<br><br><br>
💡 제어받는 장치들과의 통신
<br>
<br>SDN 컨트롤러가 원격의 SDN 기능이 가능한 장치들의 동작을 제어하려면 컨트롤러와 그 장치들 사이에 정보를 전달하는 프로토콜이 필요하다.
<br>장치는 주변에서 관찰한 이벤트를 컨트롤러에 알려, 네트워크 상태에 대한 최신의 정보를 제공해야 한다.
<br>컨트롤러와 제어받는 장치들 간의 통신은 ‘사우스바운드(southbound)’라고 알려진 컨트롤러 인터페이스를 넘나든다.<br>이 통신 기능을 제공하는 구체적 프로토콜은 OpenFlow이며, 이는 모두는 아니지만 대부분의 SDN 컨트롤러에 구현되어 있다.<br><br><br><br>
💡 네트워크 전역에 분산되고 견고한 상태 관리
<br>SDN 제어 평면의 궁극적인 제어 결정을 위해서는<br>
컨트롤러가 네트워크 호스트와 링크, 스위치, 그리고 SDN으로 제어되는 다른 장치들에 대한 최신 정보를 알아야 한다.<br>제어 평면의 궁극적인 목적은 다양한 제어 장치들의 플로우 테이블을 결정하는 것이므로 컨트롤러도 이 테이블들의 복사본을 유지해야 할 것이다.<br>스위치의 플로우 테이블이 가지는 카운터들과 같은 이러한 정보 조각들은 모두 SDN 컨트롤러가 유지하는 네트워크 전역 ‘상태’의 예들이다.<br><br><br><br>
💡 네트워크 제어 애플리케이션들을 위한 인터페이스와 추상화
<br>컨트롤러는 ‘노스바운드(northbound)’ 인터페이스를 통해 네트워크 제어 애플리케이션과 상호작용한다.<br>이 API는 네트워크 제어 애플리케이션이 상태 관리 계층 내의 네트워크 상태 정보와 플로우 테이블을 읽고 쓸 수 있도록 해준다.<br><br><br><br><br><br>SDN 컨트롤러는 외부에서 볼 때 ‘논리적으로 중앙 집중된’, 잘 짜여진 하나의 서비스로 보일 수 있지만,<br>이 서비스들과 상태 정보를 보관하기 위한 데이터베이스는<br>
장애 허용성(fault tolerance)과 높은 가용성, 또는 다른 성능상의 이유로 실제로는 분산된 서버의 집합에 구현된다.<br><br><br>근래의 컨트롤러는 논리적으로는 중앙 집중 형태이나 물리적으로는 분리된 컨트롤러 플랫폼 구조이다.<br>이런 구조는 제어되는 장치와 네트워크 제어 애플리케이션에게 늘어나는 장치 수에 따라 확장 가능한 서비스와 높은 가용성을 제공한다.<br><br>
<br><br><br>
<br>OpenFlow 프로토콜은 SDN 컨트롤러와 SDN으로 제어되는 스위치 또는 OpenFlow API를 구현하는 다른 장치와의 사이에서 동작한다.
<br>OpenFlow 프로토콜은 TCP상에서 디폴트 포트 번호 6653을 가지고 동작한다.
<br><br><br>컨트롤러가 제어되는 스위치로 전달하는 중요한 메시지는 다음과 같다.<br>
<br>
설정 : 이 메시지는 컨트롤러가 스위치의 설정 파라미터들을 문의하거나 설정할 수 있도록 한다.

<br>
상태 수정 : 이 메시지는 컨트롤러가 스위치 플로우 테이블의 엔트리를 추가/제거 또는 수정하거나 스위치 포트의 특성을 설정하기 위해 사용한다.

<br>
상태 읽기 : 이 메시지는 컨트롤러가 스위치 플로우 테이블과 포트로부터 통계 정보와 카운터값을 얻기 위해 사용한다.

<br>
패킷 전송 : 이 메시지는 컨트롤러가 제어하는 스위치의 지정된 포트에서 특정 패킷을 내보내기 위해 사용한다.<br>
이 메시지 자체는 페이로드 부분에 보낼 패킷을 포함한다.

<br><br><br>SDN으로 제어되는 스위치에서 컨트롤러로 전달되는 주요 메시지는 다음과 같다.<br>
<br>플로우 제거 : 이 메시지는 컨트롤러에게 어떤 플로우 테이블 엔트리가 시간이 만료되었거나 상태 수정 메시지를 수신한 결과로 삭제되었음을 알린다.
<br>포트 상태 : 이 메시지는 스위치가 컨트롤러에게 포트의 상태 변화를 알리기 위해 사용된다.
<br>패킷 전달

<br>4.4절에서 스위치 포트에 도착한 패킷 중에서 플로우 테이블의 어떤 엔트리와도 일치하지 않는 패킷은 처리를 위해 컨트롤러에게 전달된다고 했다.
<br>어떤 엔트리와 일치한 패킷 중에서도 일부는 그에 대한 작업을 수행하기 위해 컨트롤러에게 보내지기도 한다.<br>
이 메시지는 그러한 패킷을 컨트롤러에게 보내기 위해 사용한다.


<br><br>
<br><br><br>아래 그림은 SDN의 제어를 받는 스위치와 SDN 컨트롤러 간의 상호작용에 대한 것이다.<br>
<br>
여기서는 다익스트라 알고리즘이 최단 경로를 결정하기 위해 사용되는데,<br>
다익스트라 알고리즘은 패킷 스위치 외부에서 별도의 애플리케이션으로 수행된다.

<br>
패킷 스위치들이 링크 갱신 정보를 서로 간이 아닌 SDN 컨트롤러에게 전송한다.

<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213711666-386f50a2-908c-4aad-b862-92b868626000.png" alt="SDN 컨트롤러 시나리오" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br><br>
<br><br>
<br>최단 경로 알고리즘이 사용되고 있다.
<br>스위치 s1과 s2 사이의 링크가 단절되었다고 가정해보자.

<br>따라서 s1, s3, s4로 들어오고 나가는 플로우 포워딩 규칙은 변경되었으나, s2의 동작은 바뀌지 않았다고 가정한다.


<br>통신 계층 프로토콜로는 OpenFlow가 사용된다.
<br>제어 평면은 링크 상태 라우팅 외의 기능은 수행하지 않는다.
<br><br><br>
<br>
스위치 s2와의 링크 단절을 감지한 s1은 OpenFlow의 포트 상태 메시지를 사용하여 링크 상태의 변화를 SDN 컨트롤러에게 알린다.

<br>
링크 상태 변화를 알리는 OpenFlow 메시지를 받은 SDN 컨트롤러는 링크 상태 관리자에게 알리고,<br>
링크 상태 관리자는 링크 상태 데이터베이스를 갱신한다.

<br>
다익스트라 링크 상태 라우팅을 담당하는 네트워크 제어 애플리케이션은 링크 상태의 변화가 있을 경우 알려달라고 이전에 등록해두었다.<br>
이 애플리케이션이 링크 상태의 변화에 대한 알림을 받게 된다.

<br>
링크 상태 라우팅 애플리케이션이 링크 상태 관리자에게 요청하여 갱신된 링크 상태를 가져온다.

<br>이 작업은 상태 관리 계층에 있는 다른 구성 요소의 도움이 필요할 수도 있다.
<br>그 후 새로운 최소 비용 경로를 계산한다.


<br>
링크 상태 라우팅 애플리케이션은 갱신되어야 할 플로우 테이블을 결정하는 플로우 테이블 관리자와 접촉한다.

<br>
플로우 테이블 관리자는 OpenFlow 프로토콜을 사용하여 링크 상태 변화에 영향을 받는 스위치들의 플로우 테이블을 갱신한다.

<br>이 예에서는 s1, s2, s4가 이에 해당한다.
<br>s1 : 이제부터 s2를 목적지로 하는 패킷을 s4로 보낸다.
<br>s2 : 이제부터 s1로부터의 패킷을 중간 스위치 s4를 통해 받는다.
<br>s4 : s1에서 s2로 가는 패킷을 전달해야 한다.


<br><br><br>
💡 컨트롤러가 플로우 테이블을 마음대로 변경할 수 있기 때문에<br>
단순히 애플리케이션 제어 소프트웨어를 바꿈으로써 원하는 어떤 형태의 포워딩 방식도 구현할 수 있다.
<br><br>
<br><br><br><br>SDN이 많은 관심을 받게 된 것은 비교적 최근의 현상이지만,<br>
SDN의 기술적인 뿌리, 특히 데이터와 제어 평면의 분리를 상당히 거슬러 올라간다.<br><br><br>
<br>
2004년에 [Feamster 2004, Lakshman 2004, RFC 3746]은 모두 네트워크 데이터와 제어 평면의 분리를 주장했다.

<br>
에탄(Ethane) 프로젝트[Casado 2007]는<br>
(1) ‘매치 플러스 액션’ 플로우 테이블이 있는 간단한 플로우 기반 이더넷 스위치,<br>
(2) 플로우 수용 및 라우팅을 관리하는 중앙 집중식 컨트롤러,<br>
(3) 그리고 플로우 테이블의 어떤 엔트리와도 일치하지 않는 패킷을 스위치에서 컨트롤러로 전달하는 개념을 개척했다.
 <br>

<br>300개 이상의 에탄 스위치로 구성된 네트워크가 2007년에 운영되었다.
<br>에탄은 OpenFlow 프로젝트로 빠르게 진화했다.


<br><br><br><br>SDN 혁명은 ‘단순한 상용 스위칭 하드웨어와 정교한 소프트웨어 제어 평면’으로<br>
’모든 기능이 하나로 통합된 스위치와 라우터(데이터 및 제어 평면 모두)’를 교체해나가고 있다.<br>네트워크 기능 가상화(network functions virtualization, NFV)로 알려진 SDN의 일반화는 단순한 상용 서버, 스위칭 및 저장소를 가지고<br>
복잡한 미들박스(전용 하드웨어 및 미디어 캐싱/서비스를 위한 고유의 소프트웨어를 가진 미들박스)를 혁신적으로 교체하는 것을 목표로 한다.<br><br><br>연구의 중요한 두 번째 영역은 SDN 개념을 AS 내부 설정에서 AS 간 설정으로 확장하려는 것이다.<br><br>
<br><br><br>일부 SDN 컨트롤러는 특정 회사를 위한 고유 제품이다.<br>그러나 더 많은 컨트롤러는 오픈소스이며 다양한 프로그래밍 언어로 구현된다.<br><br><br>가장 최근에는 OpenDaylight 컨트롤러와 ONOS 컨트롤러가 산업계에서 상당한 지지를 얻었다.<br>이 둘은 모두 오픈소스이며, 리눅스 재단(Linux Foundation)과 공동으로 개발 중이다.<br><br><br><br>아래 그림은 ODL(OpenDaylight) 컨트롤러 플랫폼[OpenDaylight 2020, Eckel 2017]의 간략한 구조다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213711668-cf0281bd-cc01-444e-a547-425e81297c10.png" alt="OpenDaylight 컨트롤러" referrerpolicy="no-referrer" style="width: 620px; max-width: 100%;"><br><br>
<br><br>
<br>
ODL의 기본 네트워크 서비스 기능들은 컨트롤러의 핵심부에 있다.

<br>
서비스 추상 계층(Service Abstraction Layer, SAL)

<br>컨트롤러 구성요소와 애플리케이션이 서로의 서비스를 호출하고 그들이 생성한 이벤트에 대한 알림을 받을 수 있도록 한다.
<br>OpenFlow와 SNMP(Simple Network Management Protocol) 및 NETCONF(Network Configuration) 같은,<br>
ODL 컨트롤러와 제어 장치 간 프로토콜들에게 균일한 추상 인터페이스를 제공한다.


<br>
OVSDB(Open vSwitch Database Management Protocol)는 데이터 센터 스위칭을 관리하는 데 사용된다.<br>
(데이터 센터 네트워킹에 대해서는 6장에서 다룸)

<br><br><br>가장 상단의 네트워즈 조정 및 애플리케이션부는<br>
데이터 평면의 포워딩과 방화벽 및 로드 밸런싱 같은 서비스들이 제어 장치에서 어떻게 수행될지를 결정한다.<br><br><br><br>아래 그림은 ONOS 컨트롤러[ONOS 2020]를 간략화한 모습이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213711671-83b1df03-db2f-409b-8870-f750a34af119.png" alt="ONOS 컨트롤러" referrerpolicy="no-referrer" style="width: 620px; max-width: 100%;"><br><br>
<br><br>표준 컨트롤러와 유사하게 3개의 계층을 구분할 수 있다.<br>
<br>
노스바운드 추상화 프로토콜

<br>ONOS는 의도(intent) 프레임워크이다.

<br>이는 애플리케이션이 해당 서비스가 구체적으로 어떻게 구현되는지 몰라도<br>
높은 수준의 서비스(e.g., 어떤 호스트 A와 B 사이의 연결을 설정)를 요청할 수 있게 해준다.


<br>상태 정보가 노스바운드 API를 통과하여<br>
네트워크 제어 애플리케이션에게 동기적(직접 질의를 통해) 또는 비동기적(e.g,. 네트워크 상태가 변화했을 때 알림 기능)으로 제공된다.


<br>
분산 코어

<br>네트워크 링크, 호스트, 장치의 상태는 ONOS의 분산 코어에 유지된다.
<br>ONOS 코어는 서비스 복제와 인스턴스 간 협력 메커니즘을 제공함으로써<br>
상부의 애플리케이션과 하부의 네트워크 장치에게 논리적 중앙 집중형 코어 서비스의 추상화를 제공한다.


<br>
사우스바운드 추상화와 프로토콜

<br>사우스바운드 추상화는 하부의 호스트, 링크, 스위치, 프로토콜의 이질성을 숨겨준다.
<br>따라서 분산 코어가 장치나 프로토콜 종류에 상관없이 동작할 수 있다.
<br>이 추상화 때문에 분산 코어 아래의 사우스 바운드 인터페이스는 표준 컨트롤러나 ODL 컨트롤러보다 논리적으로 높다.


]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.5-소프트웨어-정의-네트워크(sdn)-제어-평면\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.5 소프트웨어 정의 네트워크(SDN) 제어 평면/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:27 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/213711658-f229ca35-e7a3-4818-b85f-ac2276e417e5.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/213711658-f229ca35-e7a3-4818-b85f-ac2276e417e5.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.6 인터넷 제어 메시지 프로토콜(ICMP)]]></title><description><![CDATA[ 
 <br><br>인터넷 제어 메시지 프로토콜(Internet Control Message Protocol, ICMP)은 호스트와 라우터가 서로 간에 네트워크 계층 정보를 주고받기 위해 사용된다.<br><br><br>ICMP는 종종 IP의 한 부분으로 간주되지만, ICMP 메시지가 IP 데이터그램에 담겨 전송되므로 구조적으로는 IP 바로 위에 있다.<br>즉, ICMP 메시지도 IP 페이로드로 전송되며,<br>
호스트가 상위 계층 프로토콜이 ICMP라고 표시된(상위 계층 프로토콜 번호가 1번인) IP 데이터그램을 받으면 ICMP로 내용을 역다중화한다.<br><br><br>ICMP 메시지는 타입(type)과 코드(code) 필드가 있고,<br>
ICMP 메시지의 발생 원인이 된 IP 데이터그램의 헤더와 첫 8바이트를 갖는다.<br>이는 송신자가 오류를 발생시킨 패킷을 알 수 있도록 하기 위해서이다.<br><br>
<br><br>중요한 ICMP 메시지 타입들은 다음과 같다<br>
💡 ICMP 메시지는 오류 상태를 알리기 위해서만 사용되는 것이 아니다.
<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213726337-f62a70cd-a7c6-4384-91e5-c692228d6fa0.png" alt="ICMP 메시지 타입" referrerpolicy="no-referrer" style="width: 400px; max-width: 100%;"><br><br>
<br><br><br>
<br>타입 8, 코드 0인 ICMP 메시지를 특정 호스트에 보낸다.
<br>목적지 호스트는 에코 요청을 보고 나서 타입 0, 코드 0인 ICMP 에코 응답을 보낸다.
<br>대부분의 TCP/IP 구현은 ping 서버를 운영체제에서 직접 지원한다.<br>
(즉, ping 서버는 별도의 프로세스가 아님)<br><br><br><br>이 메시지의 원래 목적은 혼잡 제어를 수행하기 위한 것이다.<br>즉, 혼잡이 발생한 라우터가 호스트의 전송 속도를 늦추도록 ICMP 출발지 억제 메시지를 해당 호스트에 보낸다.<br><br><br>하지만 우리는 앞서 TCP가 ICMP 출발지 억제 메시지와 같은 네트워크 계층의 피드백 없이도<br>
전달 계층에서 동작하는 자신만의 혼잡 제어 메커니즘을 갖고 있음을 보았고, 이에 이 메시지는 실제로는 잘 사용되지 않는다.<br><br><br><br>아래의 방식으로 출발지 호스트는 자신과 목적지 호스트 사이에 있는 라우터들의 수와 정체, 그리고 두 호스트 간의 왕복 시간을 알게 된다.<br><br><br>
<br>
출발지와 목적지 사이의 라우터 이름과 주소를 알아내기 위해<br>
출발지의 Traceroute는 일련의 IP 데이터그램을 목적지에 보낸다.

<br>각각의 데이터그램은 UDP 포트 번호를 가진 UDP 세그먼트를 운반한다.
<br>TTL 값은 첫 번째 데이터그램이 1, 두 번째는 2, 세 번째는 3, 이런 식이다.


<br>
출발지는 각 데이터그램에 대해 타이머를 작동시킨다.

<br>n번째 데이터그램이 n번째 라우터에 도착하면 해당 라우터는 데이터그램의 TTL이 방금 만료되었음을 알게 된다.


<br>
IP 프로토콜 규칙에 따라 라우터는 데이터그램을 폐기하고 ICMP 경고 메시지(타입 11, 코드 0)를 출발지에 보낸다.

<br>이 경고 메시지는 라우터의 이름과 IP 주소를 포함한다.


<br>
이 ICMP 메시지가 출발지에 도착하면, 출발지는<br>
(1) 타이머로부터 왕복 시간(round-trip time, RTT),<br>
(2) ICMP 메시지로부터 n번째 라우터의 주소와 이름을 획득한다.

<br><br>
<br><br>Traceroute 출발지는 UDP 세그먼트 전송을 언제 멈춰야 하는지 어떻게 알까?<br>
<br>
출발지가 자신이 보내는 각 데이터그램마다 차례로 TTL을 1씩 증가시키기 때문에<br>
이들 데이터그램 중 하나는 결국 목적지 호스트에 도착하게 될 것이다.

<br>
이 데이터그램은 없을 것 같은 UDP 포트 번호를 가진 UDP 세그먼트를 포함하고 있으므로,<br>
목적지 호스트는 포트 도달 불가능 ICMP 메시지(타입 3, 코드 3)를 출발지에 보낸다.

<br>
출발지 호스트가 이 ICMP 메시지를 받게 되면 추가적인 탐색 패킷을 보낼 필요가 없음을 알게 된다.

]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.6-인터넷-제어-메시지-프로토콜(icmp)\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.6 인터넷 제어 메시지 프로토콜(ICMP)/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:28 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/213726337-f62a70cd-a7c6-4384-91e5-c692228d6fa0.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/213726337-f62a70cd-a7c6-4384-91e5-c692228d6fa0.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.7 네트워크 관리와 SNMP, NETCONF/YANG]]></title><description><![CDATA[ 
 <br><br>네트워크 관리란 무엇인가?<br><br><br>[Saydam 1996]에는 이에 대해 잘 정리된, 한 문장으로 된 정의가 나온다.<br>
네트워크 관리는 적정한 비용으로 실시간, 운용 성능, 서비스 품질 등의 요구사항을 만족시키기 위해<br>
네트워크와 구성요소 자원을 감시, 테스트, 폴링, 설정, 분석, 평가, 제어하는<br>
하드웨어, 소프트웨어, 인간 요소 등을 배치하고, 통합, 조정하는 것이다.
<br><br><br>이 절에서는 이 광범위한 정의 중에서 네트워크 관리의 기초,<br>
즉 네트워크 관리자가 자신의 일을 수행하는 데 사용하는 구조, 프로토콜, 데이터만을 다룬다.<br><br>
<br><br><br>아래 그림은 네트워크 관리의 핵심 요소들을 나타낸다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213753123-ebbbe96e-5b67-41aa-9d30-058924368adb.png" alt="네트워크 관리의 요소" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>
<br><br><br>
관리 서버는<br>
네트워크 운영 센터(network operations center, NOC)의 중앙 집중형 네트워크 관리 스테이션에서 동작하는,<br>
일반적으로 네트워크 관리자(network managers, 사람)와 상호작용하는 애플리케이션이다.
<br>
<br>네트워크 관리 활동이 일어나는 장소로서 네트워크 관리 정보의 수집, 처리, 분석, 발송을 제어한다.
<br>여기서 네트워크의 피관리 장치를 설정, 감시, 제어하기 위한 작업이 시작된다.
<br>하나의 네트워크는 여러 개의 관리 서버를 가질 수 있다.
<br><br><br><br>
피관리 장치는 관리 대상 네트워크에 존재하는 네트워크 장비(소프트웨어 포함)들이다.
<br>
<br>e.g., 호스트, 라우터, 스위치, 미들박스, 모뎀, 온도계, 그 외 네트워크에 연결된 그 밖에 장치들
<br>이 장치들은 많은 관리 가능한 요소들(e.g,. 네트워크 인터페이스 카드는 호스트나 라우터의 구성요소)과<br>
이러한 하드웨어 및 소프트웨어 요소에 대한 설정 매개변수들(e.g., OSPF와 같은 AS 내부 라우팅 프로토콜)을 갖는다.
<br><br><br><br>
각 피관리 장치는 ‘상태(state)’라고 부르는, 장치와 관련된 데이터를 갖는다.
<br><br><br>데이터의 유형들<br>
<br>
설정 데이터(configuration data)

<br>장치 인터페이스에 관리자가 할당 및 설정한 장치 정보
<br>e.g., IP 주소 또는 인터페이스 속도


<br>
동작 데이터(operational data)

<br>장치가 동작하면서 획득하는 정보
<br>e.g., OSPF 프로토콜의 인접 항목 목록


<br>
장치 통계(device statistics)

<br>장치가 운영되면서 갱신되는 상태 표시기 및 계수기
<br>e.g., 인터페이스에서 삭제된 패킷 수 또는 장치의 냉각 팬 속도


<br><br><br>관리 서버는 네트워크 토폴로지 같은 전체 네트워크와 관련된 데이터뿐만 아니라<br>
관리 대상 장치들의 구성과 운영, 그리고 통계 데이터의 복사본도 유지 관리한다.<br><br><br><br>
네트워크 관리 에이전트는 관리 서버와 통신하는 피관리 장치상의 소프트웨어 프로세스다.
<br>관리 서버의 명령과 제어에 따라 피관리 장치에 국한되는 행동을 취한다.<br><br><br><br>
네트워크 관리 프로토콜은 관리 서버와 피관리 장치들 사이에서 동작하면서<br>
(1) 관리 서버가 피관리 장치의 상태에 대해 질의하고<br>
(2) 에이전트를 통해 피관리 장치에 행동을 취할 수 있도록 해준다.
<br><br><br>에이전트는 예외적인 사건을 관리 서버에게 알리기 위해 네트워크 관리 프로토콜을 사용할 수 있다.<br>
(e.g., 부품의 고장 또는 성능 임계치의 위반)<br><br><br>
💡 네트워크 관리 프로토콜 스스로가 네트워크를 관리하지 않는다.
<br>대신에 네트워크 관리자가 네트워크를 관리(감시, 테스트, 폴링, 설정, 분석, 평가, 제어)할 수 있도록 기능을 제공한다.<br><br><br><br><br><br>네트워크 운영자가 위의 구성요소들을 활용하여 네트워크를 관리할 수 있는, 흔히 사용하는 세 가지 방법이 있다.<br><br><br><br>
네트워크 운영자는 명령줄 인터페이스(Command Line Interaface, CLI)를 통해 장치에 직접 명령을 보낼 수 있다.
<br>이러한 명령은<br>
(1) 운영자가 피관리 장치과 물리적으로 같은 공간에 있는 경우 피관리 장치의 콘솔에 직접 입력하거나<br>
(2) 피관리 장치 사이의 텔넷(Telnet) 또는 SSH(secure shell) 연결을 통해 전달할 수 있다.<br><br><br>이 방법을 통해서는 대체로 오류가 발생하기 쉽고, 대규모 네트워크를 자동화하거나 효율적으로 관리하기 어렵다.<br><br><br><br>
이 방식에서 네트워크 운영자는 SNMP(Simple Network Management Protocol)를 사용하여<br>
장치의 MIB(Management Information Base)에 있는 데이터를 질의하거나 설정할 수 있다.
<br><br><br>일부 MIB 데이터는 장치 및 공급업체에 따라 다르지만,<br>다른 MIB 데이터(e.g., IP 데이터그램 헤더의 오류 때문에 라우터에서 버려지는 IP 데이터그램의 개수, 호스트에서 수신하는 UDP 세그먼트 개수)는<br>
장치에 종속되지 않고 추상성과 일반성을 갖는다.<br><br><br>일반적으로 네트워크 운영자는<br>
<br>이 방식으로 동작 상태 및 장치 통계 정보를 질의 및 모니터링한 다음
<br>명령줄 인터페이스를 사용하여 장치를 실제로 제어하고 설정한다.
<br><br><br>
💡 CLI와 SNMP/MIB 모두 장치를 개별적으로 관리한다.
<br>SNMP/MIB로도 장치 설정 및 대규모 네트워크 관리의 어려움이 존재한다.<br><br><br>이로 인해 NETCONF와 YANG을 사용하는 가장 최근의 네트워크 관리 방식이 나타났다.<br><br><br><br>
이 방식은 네트워크 관리에 대해 좀 더 추상적이고 네트워크 전체를 아우르는 전체론적인 관점을 취하면서도,<br>
정확성의 제약 정도를 구체화하고 여러 장치에 대한 세세한 관리 작업을 제공하는 등 설정 관리에 훨씬 더 중점을 둔다.
<br>
<br>YANG : 설정 및 동작 데이터를 모델링하는 데 사용되는 데이터 모델링 언어
<br>NETCONF 프로토콜 : 원격 장치과 YANG 호환 작업 및 데이터를 주고받거나 원격 장치 간에 통신하는 데 사용됨
<br><br>
<br><br><br><br>
SNMPv3(Simple Network Management Protocol version 3)는<br>
관리 서버와 그 관리 서버를 대표하여 실행되고 있는 에이전트 사이에서 네트워크 관리 제어 및 정보 메시지를 전달하기 위해 사용된다.
<br><br><br><br>이는 SNMP의 가장 흔한 사용 행태이다.<br>
<br>SNMP 관리 서버는 에이전트에게 요청을 송신하고

<br>일반적으로 요청은 피관리 장치과 관련된 MIB 객체 값들을 질의(검색) 또는 수정(설정)하기 위해 이용


<br>이를 받은 SNMP 에이전트는 이를 수행한 후 요청에 대한 응답을 보낸다.
<br><br><br><br>SNMP의 두 번째로 일반적인 사용은<br>
에이전트가 요구받지 않았더라도 트랩 메시지라는 이름의 메시지를 관리 서버에게 전송하는 것이다.<br>트랩 메시지들은 관리 서버들에게<br>
MIB 객체 값들을 변화시킨 예외 사항(e.g., 링크 인터페이스의 활성 또는 비활성)의 발생을 통지하기 위해 이용된다.<br><br><br><br><br><br>아래 표는 SNMPv2에 대한 것이며, 일반적으로 PDU(Protocol Data Unit)으로 알려진 일곱 가지 타입의 메시지를 정의하고 있다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213753140-ac78f753-0be9-4df6-ba9e-4642edef2460.png" alt="SNMPv2 PDU 포맷" referrerpolicy="no-referrer" style="width: 760px; max-width: 100%;"><br><br>
<br><br>
<br>
GetRequest, GetNextRequest, GetBulkRequest PDU들은 모두<br>
에이전트의 피관리 장치 내 하나 이상의 MIB 객체의 값을 요청하기 위해 관리 서버로부터 에이전트로 전송된다.

<br>이들은 데이터 요청들의 정밀도(granularity) 면에서 다르다.
<br>에이전트는 객체 식별자들과 그에 관련된 값들을 Response PDU에 담아 응답한다.


<br>
SetRequest PDU는 관리 서버가 피관리 장치 안의 하나 또는 그 이상의 MIB 객체들의 값을 설정하기 위해 사용한다.

<br>에이전트는 값이 제대로 설정되었음을 알려주기 위해 ‘noError’라는 오류 상탯값을 Response PDU에 담아 응답한다.


<br>
SNMPv2-Trap은 트랩 메시지로, 비동기적으로 발생한다.

<br>즉, 요청을 수신했을 때가 아니라 관리 서버가 통지를 요구한 이벤트가 발생했을 때 발생한다.
<br>수신된 트랩 요청은 관리 서버로부터 어떤 응답도 요구하지 않는다.


<br><br><br>아래 그림은 SNMP PDU의 포맷을 나타낸 것이다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213753145-8adb9a82-8229-4746-8ef0-41027b47f82a.png" alt="SNMP PDU 포맷" referrerpolicy="no-referrer" style="width: 700px; max-width: 100%;"><br><br>
<br><br><br><br><br>
SNMP PDU들이 다른 많은 전송 프로토콜에 의해 운반될 수 있기는 하지만 일반적으로는 UDP 데이터그램의 페이로드 부분에 실린다.
<br><br><br>그러나 UDP는 신뢰성이 보장되지 않는 전송 프로토콜이므로,<br>
요청 또는 그에 대한 응답이 의도한 목적지에 도착한다는 보장이 없다.<br><br><br>따라서 아래처럼 요청 ID 필드는 관리 서버가 요청 또는 응답의 분실을 검출하는 데 이용될 수 있다.<br>
<br>PDU의 요청 ID 필드는 관리 서버가 에이전트에 보내는 요청에 번호를 매기기 위해 사용된다.
<br>에이전트의 응답은 수신된 요청으로부터 요청 ID 값을 취한다.
<br><br>
<br><br><br>MIB 객체는 SMI(Structure of Management Information, 관리 정보 구조)라고 하는 데이터 기술 언어로 명세되는데,<br>
이 이름은 그 기능에 대한 아무런 힌트를 주지 않는 다소 엉뚱한 이름의 네트워크 관리 프레임워크 구성요소다.<br>SMI는 SNMP(네트워크 관리를 위해 관리 정보 및 정보 운반을 위한 프로토콜)에서 관리 정보의 구조를 말하며,<br>
MIB 객체를 정의하는 일반적인 규칙들의 모음이다.<br><br><br><br><br><br>MIB는 망관리 자원 정보를 구조화시킨, 대규모 관리 정보 집합을 말한다.<br>앞에서 SNMP/MIB 방식의 네트워크 관리에서<br>
피관리 장치의 동작 상태 데이터가 해당 장치를 위한 MIB에 수집된 객체들로 표현된다는 사실을 배웠다.<br><br><br>MIB 객체는 다음과 같은 정보일 수도 있다.<br>
<br>IP 데이터그램 헤더의 오류로 인해 라우터에서 버려지는 데이터그램 개수
<br>이더넷 엔터페이스 카드의 반송파 감지 오류 횟수를 세는 카운터
<br>DNS 서버에서 실행되는 소프트웨어 버전과 같은 설명 정보
<br>특정 장치가 올바르게 작동하는지 여부와 같은 상태 정보
<br>어떤 목적지로의 라우팅 경로 같은 프로토콜에 특정된 정보 등..
<br><br><br>관련된 MIB 객체들은 MIB 모듈로 합쳐진다.<br><br>
<br><br><br><br>NETCONF 프로토콜은 관리 서버과 피관리 네트워크 장치 사이에서 동작하면서<br>
<br>피관리 장치의 설정 데이터를 검색, 셋업, 수정하거나
<br>피관리 장치의 동작 데이터 및 통계를 질의하거나
<br>피관리 장치에서 생성된 알림을 구독하기 위한 메시지 전송 기능을 제공한다.
<br><br><br>관리 서버는 피관리 장치를 제어하기 위해 구조화된 XML 문서 형식의 설정 내용을 보내 피관리 장치에서 활성화한다.<br>
<br>NETCONF는 원격 프로시너 호출(remote procedure call, RPC) 패러다임을 사용한다.
<br>XML로 인코딩된 프로토콜 메시지는 TCP상의 TLS(Transport Layer Security) 프로토콜과 같은<br>
안전한 연결 지향 세션을 통해 관리 서버와 피관리 장치 사이에서 교환된다.
<br><br><br>e.g., NETCONF &lt;get&gt; 명령<br>이 명령을 통해 서버는 장치의 설정에 대해 알 수 있다.<br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;rpc message-id="101"
     xmlns="urn:ietf:params:xml:ns:netconf:base:1.0"&gt;
    &lt;get/&gt;
&lt;/rpc&gt;
복사<br><br><br><br><br><br>아래는 NETCONF 세션의 예다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213753150-51b2a371-d411-44a2-bba2-98cd5f379c0a.jpg" alt="NETCONF" referrerpolicy="no-referrer" style="width: 520px; max-width: 100%;"><br><br>
<br><br>
<br>
관리 서버는 피관리 장치와 보안 연결을 설정한다.

<br>
보안 연결이 설정되면 관리 서버와 피관리 장치는 &lt;hello&gt; 메시지를 교환하고,<br>
기본 NETCONF 명세를 보완하는 어떠한 추가 ‘기능’이 있는지를 알린다.

<br>
관리 서버와 피관리 장치 간의 상호작용은 &lt;rpc&gt;와 &lt;rpc-reply&gt; 메시지를 사용하는 원격 프로시저 호출 형식을 갖는다.

<br>이러한 메시지는 장치 설정 데이터와 동작 데이터 및 통계를 검색, 설정, 질의, 수정하고 장치의 알림을 구독하는 데 사용된다.


<br>
&lt;close-session&gt; 메시지로 세션을 종료한다.

<br><br><br>아래 표는 관리 서버가 피관리 장체에서 수행할 수 있는 여러 가지 중요한 NETCONF 작업을 보인다.<br><br><br><img src="https://user-images.githubusercontent.com/86337233/213753157-496114da-51dc-4054-9f6c-569f3f6d36b4.png" alt="주요 NETCONF 작업" referrerpolicy="no-referrer" style="width: 760px; max-width: 100%;"><br><br>
<br><br><br>
YANG은 NETCONF가 사용하는 네트워크 관리 데이터의 구조, 구문 및 의미를 정확하게 표현하는 데 사용되는 데이터 모델링 언어다.
<br>모든 YANG 정의는 모듈에 포함되고, 장치와 해당 기능을 설명하는 XML 문서는 YANG 모듈에서 생성할 수 있다.]]></description><link>중앙대학교-수업\4-1\네트워크응용설계-요약\chapter_5\5.7-네트워크-관리와-snmp,-netconf,-yang\readme.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/네트워크응용설계 요약/Chapter_5/5.7 네트워크 관리와 SNMP, NETCONF, YANG/README.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:29 GMT</pubDate><enclosure url="https://user-images.githubusercontent.com/86337233/213753123-ebbbe96e-5b67-41aa-9d30-058924368adb.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://user-images.githubusercontent.com/86337233/213753123-ebbbe96e-5b67-41aa-9d30-058924368adb.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[넷응설 과제 6]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\4-1\넷응설-과제-6\넷응설-과제-6.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/넷응설 과제 6/넷응설 과제 6.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Sun, 16 Jun 2024 07:51:17 GMT</pubDate></item><item><title><![CDATA[기말 족보]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\기말-족보.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/멀티코어컴퓨팅/기말 족보/기말 족보.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Sun, 16 Jun 2024 07:52:15 GMT</pubDate></item><item><title><![CDATA[2013 기말]]></title><description><![CDATA[ 
 <br><br><img alt="태운이형 통합본_page-0001.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0001.jpg"><br><img alt="태운이형 통합본_page-0002.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0002.jpg"><br><br><br><img alt="세준이형 통합본_page-0001.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\세준이형-통합본_page-0001.jpg"><br><img alt="세준이형 통합본_page-0002.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\세준이형-통합본_page-0002.jpg"><br><br><br><img alt="태운이형 통합본_page-0005.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0005.jpg"><br><img alt="태운이형 통합본_page-0006.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0006.jpg"><br><br><br><img alt="태운이형 통합본_page-0007.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0007.jpg"><br><img alt="태운이형 통합본_page-0008.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0008.jpg"><br><br><br><img alt="태운이형 통합본_page-0009.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0009.jpg"><br><img alt="태운이형 통합본_page-0010.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0010.jpg"><br><img alt="태운이형 통합본_page-0011.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0011.jpg"><br><img alt="태운이형 통합본_page-0012.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0012.jpg"><br><br><br><img alt="태운이형 통합본_page-0013.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0013.jpg"><br><img alt="태운이형 통합본_page-0014.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0014.jpg"><br><img alt="태운이형 통합본_page-0015.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0015.jpg"><br><img alt="태운이형 통합본_page-0016.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0016.jpg"><br><br><br><br>
<img alt="태운이형 통합본_page-0017.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0017.jpg"><br><img alt="태운이형 통합본_page-0018.jpg" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0018.jpg">]]></description><link>중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\기말-족보-공부.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/멀티코어컴퓨팅/기말 족보/기말 족보 공부.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Sun, 16 Jun 2024 08:01:40 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0001.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\멀티코어컴퓨팅\기말-족보\attachments\태운이형-통합본_page-0001.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[강의 ppt]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\강의-ppt.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/멀티코어컴퓨팅/Lec 5-1/강의 ppt/강의 ppt.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:31 GMT</pubDate></item><item><title><![CDATA[Lec 5-1]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\lec-5-1.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/멀티코어컴퓨팅/Lec 5-1/Lec 5-1.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Sun, 16 Jun 2024 07:52:26 GMT</pubDate></item><item><title><![CDATA[Lec 5-1.Pthread-Programming]]></title><description><![CDATA[ 
 <br><img alt="lec 5-1 multicore05_1.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_1.png"><br><img alt="lec 5-1 multicore05_2.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_2.png"><br><br>
<br>OS에 의해 동시에 실행되는 독립적인 instruction stream=
<br>멀티쓰레드 프로그램
<br>
<br><img alt="lec 5-1 multicore05_3.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_3.png"><br><img alt="lec 5-1 multicore05_4.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_4.png"><br><img alt="lec 5-1 multicore05_5.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_5.png"><br><img alt="lec 5-1 multicore05_6.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_6.png"><br><img alt="lec 5-1 multicore05_7.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_7.png"><br><img alt="lec 5-1 multicore05_8.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_8.png"><br><img alt="lec 5-1 multicore05_9.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_9.png"><br><img alt="lec 5-1 multicore05_10.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_10.png"><br><img alt="lec 5-1 multicore05_11.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_11.png"><br><img alt="lec 5-1 multicore05_12.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_12.png"><br><img alt="lec 5-1 multicore05_13.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_13.png"><br><img alt="lec 5-1 multicore05_14.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_14.png"><br><img alt="lec 5-1 multicore05_15.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_15.png"><br><img alt="lec 5-1 multicore05_16.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_16.png"><br><img alt="lec 5-1 multicore05_17.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_17.png"><br><img alt="lec 5-1 multicore05_18.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_18.png"><br><img alt="lec 5-1 multicore05_19.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_19.png"><br><img alt="lec 5-1 multicore05_20.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_20.png"><br><img alt="lec 5-1 multicore05_21.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_21.png"><br><img alt="lec 5-1 multicore05_22.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_22.png"><br><img alt="lec 5-1 multicore05_23.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_23.png"><br><img alt="lec 5-1 multicore05_24.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_24.png"><br><img alt="lec 5-1 multicore05_25.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_25.png"><br><img alt="lec 5-1 multicore05_26.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_26.png"><br><img alt="lec 5-1 multicore05_27.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_27.png"><br><img alt="lec 5-1 multicore05_28.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_28.png"><br><img alt="lec 5-1 multicore05_29.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_29.png"><br><img alt="lec 5-1 multicore05_30.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_30.png"><br><img alt="lec 5-1 multicore05_31.png" src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_31.png">]]></description><link>중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\lec-5-1.pthread-programming.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/멀티코어컴퓨팅/Lec 5-1/Lec 5-1.Pthread-Programming.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:32 GMT</pubDate><enclosure url="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\4-1\멀티코어컴퓨팅\lec-5-1\강의-ppt\lec-5-1-multicore05_1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[결과 보고서 작성 요령]]></title><description><![CDATA[ 
 <br><br><br>
<br>객관성에 입각해 실험값을 분석
<br>실험값의 평균값, 상대오차, 표준 편차 등을 계산
<br><br>
<br>객관성에 입각하여 오차 논의를 한다.
<br><br>
<br>실험을 한 목적에 맞춰 그에 부합하는 결과를 얻었는지를 언급하거나, '결과 분석'을 간략히 요약 정리하는 방법을 취한다.
<br>'결과값에서 오차 논읭에서 설명한 오차들만 배제할 수 있었다면 참값에 준하는 실험 결과를 얻을 수 있었을 것으로 생각된다.' 와 같은 형식으로 결론을 내리는 것도 결론의 한 방법이 되겠다.
]]></description><link>중앙대학교-수업\4-1\일반물리실험\내용-정리\00-1.-실험-시-유의-사항-및-보고서-작성-요령.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/일반물리실험/내용 정리/00-1. 실험 시 유의 사항 및 보고서 작성 요령.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:32 GMT</pubDate></item><item><title><![CDATA[1. 버니어 캘리퍼스(Vernier Calipers)]]></title><description><![CDATA[ 
 <br><br>버니어 캘리퍼스는 1mm 눈금을 20등분한 0.05mm의 매우 작은 길이까지도 정확히 측정할 수 있는 정밀한 기기로 물체의 내경, 외경 두께, 깊이 등을 측정하는 데 사용된다.]]></description><link>중앙대학교-수업\4-1\일반물리실험\내용-정리\00-2.-계측-기기-사용법.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/일반물리실험/내용 정리/00-2. 계측 기기 사용법.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 25 Jun 2024 01:58:26 GMT</pubDate></item><item><title><![CDATA[실험 방법]]></title><description><![CDATA[ 
 <br>]]></description><link>중앙대학교-수업\4-1\일반물리실험\내용-정리\02.-힘의-합성과-분해.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/일반물리실험/내용 정리/02. 힘의 합성과 분해.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Wed, 19 Jun 2024 16:29:47 GMT</pubDate></item><item><title><![CDATA[내용 정리]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\4-1\일반물리실험\내용-정리\내용-정리.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/일반물리실험/내용 정리/내용 정리.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:33 GMT</pubDate></item><item><title><![CDATA[기말고사 정보]]></title><description><![CDATA[ 
 <br>시험 시각: 목요일 15시<br>
시험 장소: <br>시험문제 이론 거의 안냄, 공식유도하고 그러는거 안냄 공식문제에서 유도하는 문제가 나오면 굉장히 쉽고 애초에 공식을 제공함 실험에서 자주했던 행동들 냄 실험기기 다루는거 실험마다 그 실험의 핵심적인 이론, 그 실험을 통해서 어떤것을 얻을 것인지, 예비 레포트에서 30~40% 한실험당 8~10문제 나옴, 암기를 강요하거나 이건좀 내용이많다 싶은것들 빼고하면됨, 책에서 디테일적으로 한거랑 실험 제데로 이해하고있는지에 대해 공부함 예비 레포트한번 풀어보고 10개의 실험에 대해서 어떻게했는지 공부하고. 자기꺼 한번보고하면됨, 실험에 제데로 참여했다면 괜찮음 <br>10분20분내로 풀수있는 문제냄 너무 쉽지도 어렵지도 않음<br>거의 객관식과 단답형, 주관식 서술형 문제는 길게 써봣자 3줄]]></description><link>중앙대학교-수업\4-1\일반물리실험\기말고사-정보.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/일반물리실험/기말고사 정보.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Wed, 19 Jun 2024 15:40:27 GMT</pubDate></item><item><title><![CDATA[일반물리실험]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\4-1\일반물리실험\일반물리실험.html</link><guid isPermaLink="false">중앙대학교 수업/4-1/일반물리실험/일반물리실험.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Thu, 27 Jun 2024 23:54:33 GMT</pubDate></item><item><title><![CDATA[미적분학(1)]]></title><description><![CDATA[ 
 ]]></description><link>중앙대학교-수업\24-s\미적분학(1)\미적분학(1).html</link><guid isPermaLink="false">중앙대학교 수업/24-s/미적분학(1)/미적분학(1).md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 25 Jun 2024 01:59:07 GMT</pubDate></item><item><title><![CDATA[Ch.02]]></title><description><![CDATA[ 
 <br><img alt="Ch2_1.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_1.png"><br>
<br>함수 f가 a 근처에서 정의되면  가 된다
<br><img alt="Ch2_2.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_2.png"><br>
<br>도함수의 기하학적인 의미: 접선의 기울기(  )
<br>tangent line: 
<br><img alt="Ch2_3.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_3.png"><br><img alt="Ch2_4.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_4.png"><br><img alt="Ch2_5.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_5.png"><br>
<br>
<img alt="Ch2_6.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_6.png"><br><img alt="Ch2_7.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_7.png"><br><img alt="Ch2_8.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_8.png"><br><img alt="Ch2_9.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_9.png"><br><img alt="Ch2_10.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_10.png"><br><img alt="Ch2_11.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_11.png"><br><img alt="Ch2_12.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_12.png"><br><img alt="Ch2_13.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_13.png"><br><img alt="Ch2_14.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_14.png"><br><img alt="Ch2_15.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_15.png">]]></description><link>중앙대학교-수업\24-s\미적분학(1)\ch.02.html</link><guid isPermaLink="false">중앙대학교 수업/24-s/미적분학(1)/Ch.02.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Tue, 25 Jun 2024 02:13:17 GMT</pubDate><enclosure url="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch2_1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Ch.06]]></title><description><![CDATA[ 
 <br><img alt="Ch6_1.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch6_1.png" style="width: 500px; max-width: 100%;"><br><img alt="Ch6_2.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch6_2.png" style="width: 500px; max-width: 100%;"><br><img alt="Ch6_3.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch6_3.png"><br><img alt="Ch6_4.png" src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch6_4.png">]]></description><link>중앙대학교-수업\24-s\미적분학(1)\ch.06.html</link><guid isPermaLink="false">중앙대학교 수업/24-s/미적분학(1)/Ch.06.md</guid><dc:creator><![CDATA[dustbox]]></dc:creator><pubDate>Fri, 28 Jun 2024 00:13:39 GMT</pubDate><enclosure url="중앙대학교-수업\24-s\미적분학(1)\attachments\ch6_1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="중앙대학교-수업\24-s\미적분학(1)\attachments\ch6_1.png"&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>